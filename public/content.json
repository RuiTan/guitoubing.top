{"meta":{"title":"Archer","subtitle":"我们梦中见","description":null,"author":"Rui","url":"http://blog.guitoubing.top"},"pages":[{"title":"404 Not Found 该页无法显示","date":"2018-11-05T17:08:58.000Z","updated":"2018-11-05T17:11:24.000Z","comments":true,"path":"/404.html","permalink":"http://blog.guitoubing.top//404.html","excerpt":"","text":""},{"title":"categories","date":"2019-03-11T04:41:37.000Z","updated":"2019-03-11T04:42:18.090Z","comments":true,"path":"categories/index.html","permalink":"http://blog.guitoubing.top/categories/index.html","excerpt":"","text":""},{"title":"关于我","date":"2017-10-20T13:04:41.000Z","updated":"2018-11-06T14:05:46.000Z","comments":true,"path":"about/index.html","permalink":"http://blog.guitoubing.top/about/index.html","excerpt":"","text":"用心写文，用脚上传每日一问 芳芳到底什么时候下班呢？"},{"title":"tags","date":"2018-11-05T17:00:28.000Z","updated":"2019-03-11T04:40:16.421Z","comments":true,"path":"tags/index.html","permalink":"http://blog.guitoubing.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"深入垃圾回收","slug":"深入GC","date":"2019-04-11T02:36:03.000Z","updated":"2019-04-11T02:39:47.809Z","comments":true,"path":"2019/04/11/深入GC/","link":"","permalink":"http://blog.guitoubing.top/2019/04/11/深入GC/","excerpt":"","text":"可达性分析算法算法的基本思路是通过一系列称为GC Roots的对象作为起始点，从这些节点向下搜索，搜索所走过的路径称作引用链。 可作为GC Roots的对象包括下面几种： 虚拟机栈(栈帧中的本地变量表)中引用的对象 方法区中类静态属性引用的对象 方法去中常量引用的对象 本地方法栈中JNI引用的对象 引用强引用程序代码中普遍存在的，类似于Object obj = new Object();这类的引用，只要强引用还存在，GC永远不会回收掉被引用的对象。 软引用用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。可用SoftReference类来实现。 弱引用比软引用强度低，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。可用WeakReference类来实现。 虚引用最弱的引用。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。 再谈finalize()即使在上述可达性分析算法中不可达的对象，也并非是非死不可的。 过程要真正宣告一个对象死亡，至少要经历两次标记过程： 如果对象在进行可达性分析后没有与GC Roots相连接的引用链 进行筛选，条件是对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法以及被调用过，则虚拟机认定没有必要执行，此时才宣判对象已死 再生当有必要执行finalize()方法时，则对象就会有拯救自己的机会，如下： import java.util.concurrent.TimeUnit;public class FinalizeEscapeGC &#123; public static FinalizeEscapeGC SAVE_HOOK = null; public void isAlive() &#123; System.out.println(\"yes, i am still alive.\"); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println(\"finalize method executed!\"); FinalizeEscapeGC.SAVE_HOOK = this; &#125; public static void main(String[] args) throws InterruptedException &#123; SAVE_HOOK = new FinalizeEscapeGC(); // 对象第一次成功拯救自己 SAVE_HOOK = null; System.gc(); // 因为finalize方法优先级很低，所以暂停0.5s以等待它 TimeUnit.MILLISECONDS.sleep(500); if (SAVE_HOOK != null)&#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(\"no, i am dead!\"); &#125; // 下面的代码与上面完全相同，但是此次自救却失败了 SAVE_HOOK = null; System.gc(); TimeUnit.MILLISECONDS.sleep(500); if (SAVE_HOOK != null)&#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println(\"no, i am dead!\"); &#125; &#125;&#125;/**Output:finalize method executed!yes, i am still alive.no, i am dead!**/. 从上述代码及其结果可看到，SAVE_HOOK对象的finalize()方法确实被GC触发过，其本身也在垃圾收集之前成功逃脱了。但是注意，由于一个对象的finalize()只会被执行一遍，因此上述代码中第二次将逃脱失败，无法完成自救。 HotSpot的算法实现 关于GC的几种主流实现方法（简单记忆）： 保守式GC(Conservative GC)：指JVM不记录内存上的某个数据应该被解读为引用类型还是其他类型。 半保守式GC(Conservative with respect to the roots)：让对象带有足够的元数据 准确式GC(Exact GC)：提供特定数据结构保存对象引用 枚举根节点枚举根节点这一过程是必须要停顿所有Java执行线程，即Stop The World。因为要保证这段时间的引用不变性。 Java中使用OopMap来存储对象引用，以实现准确性GC，同时也避免了垃圾回收时需要遍历栈的每个位置。 安全点 SafepointHotspot虚拟机只在到达Safepoint位置暂停，以进行GC。 程序中指令序列复用的指令，例如方法调用、循环跳转、异常跳转等情况，才会产生Safepoint。 在多线程中，有两种中断方案可供选择： 抢先式中断：GC发生时，将所有线程中断，而后让不在安全点上的线程恢复，直到跑到安全点。 主动式中断：设置一个标志，各个线程主动轮询这个标志，发现中断标志为真时就自己中断挂起。 安全区域 Safe Region安全区域是为了解决程序不执行的时候，程序无法进入安全点的情况，例如线程处于Sleep或者Blocked状态时。 安全区域指的是一段代码片段之中，引用关系不会发生变化，因此在这个区域的任何地方开始GC都是安全的。 当线程执行到安全区域的代码中时： 首先标识自己已经进入安全区域，此时JVM发起GC时就无需询问处于安全区域状态的线程了，直接回收 在线程要离开安全区域时，需要检查JVM是否已经完成了根节点枚举，如果完成了则线程继续执行，否则必须要等待直到收到可以安全离开安全区域的信号为止。 垃圾收集器Serial收集器Serial收集器是一个单线程的收集器，它只会使用一个CPU或一条收集线程去完成垃圾收集工作，同时它进行垃圾收集时，必须暂停其他所有工作线程。 ParNew收集器Serial收集器的多线程版本。 目前只有Serial和ParNew能够与CMS收集器配合工作。 Parallel Scavenge收集器此收集器的侧重点放在吞吐量上，吞吐量就是CPU用于运行用户代码与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)。 注意，吞吐量与垃圾收集速度无太大关系。 同时采用此类收集器的虚拟机可根据系统运行状况手机性能监控信息，动态调整参数以提供最合适的停顿时间或最大的吞吐量。 Serial Old收集器Serial收集器的老年代版本，两大用途： 与Parallel Scavenge收集器搭配使用 作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。 Parallel Old收集器Parallel Scavenge收集器的老年代版本。 CMS收集器CMS收集器是一种以获取最短回收停顿时间为目标的收集器。 收集过程CMS收集器收集过程分为4个步骤： 初始标记：需要Stop The World，标记GC Roots能直接关联到的对象，速度很快。 并发标记：不需要Stop The World，进行GC Roots Tracing。 重新标记：需要Stop The World，标记因用户程序继续运作而导致变动的那一部分对象的标记记录。 并发清除：不需要Stop The World，进行清除。 缺点 对CPU资源很敏感，当CPU资源紧张时，用户程序速度下降很明显。 无法处理浮动垃圾，即在标记之后出现的垃圾，只能留到下一次GC时再清理掉。同时使用CMS时，由于需要预留空间给用户线程，因此不能等到老年代几乎全部被填满了再进行收集。此时当CMS预留的内存无法满足程序需要，就会出现一次Concurrent Mode Failure失败，这是就使用后备收集器Serial Old。 标记-清除算法会产生空间碎片。 G1收集器(Garbage First)特点 并行和并发 分代收集 空间整合 可预测的停顿 G1收集器中新生代和老年代不再是物理隔离的，它将整个Java堆划分为多个大小相等的独立区域(Region)。 由于Region之间可能存在相互引用的关系，所以使用Remembered Set来记录从其他Region引用当前Region的引用信息，Remembered Set是一种抽象概念，Card Table是其一种实现方式。 实际上，G1相关算法是个很复杂的过程，见R大的帖子，需要进一步研究。 收集过程 初始标记 并发标记 最终标记 筛选回收 内存分配与回收策略对象优先在Eden分配大多数情况下，对象在新生代Eden区中分配，当Eden区没有足够空间进行分配时，虚拟机发起一次MinorGC。 大对象直接进入老年代大对象指的是需要大量连续内存空间的Java对象，例如很长的字符串以及数组。更糟糕的是产生一群朝生夕灭的短命大对象。 长期存活的对象将进入老年代虚拟机给每个对象定义了一个对象年龄计数器，当年龄增长到阈值时，就可以晋升到老年代。阈值默认为15，也可通过MaxTenuringThredhold参数设置。 动态对象年龄判断当Survivor空间中相同年龄所有对象大小总和大于Survivor空间的一半，年龄大于等于该年龄的对象就直接进入老年代。","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.guitoubing.top/tags/Java/"}]},{"title":"Java类与类加载器","slug":"Java类与类加载器","date":"2019-03-27T15:54:46.000Z","updated":"2019-03-27T15:59:55.169Z","comments":true,"path":"2019/03/27/Java类与类加载器/","link":"","permalink":"http://blog.guitoubing.top/2019/03/27/Java类与类加载器/","excerpt":"","text":"类加载机制类加载机制个人认为是JVM中比较重要的一部分，因此在JVM系统学习之前就先学习了类加载机制的相关细节，以记之。 阶段 其中解析可能会发生在初始化之后，使用可能不会被使用。 上述流程指的是开始时间的顺序，比如说加载未结束可能验证就会开始。 类加载时机虚拟机严格规定了5种情况必须立即对类进行初始化(不是上述流程中的初始化，指的是初始化类对象)： 遇到new、getstatic、putstatic、invokestatic这4条字节码指令时，如果类没有进行初始化则需要先触发其初始化。 对类进行反射调用； 当初始化一个类时，若父类还没有被初始化需要先触发其父类的初始化； 当虚拟机启动时，包含main()方法的那个类需要被初始化； 当使用动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且句柄对应的类没有被初始化。 不会触发类的初始化的可能操作： 通过子类调用父类的静态字段，不会导致子类初始化 通过数组定义来引用类，不会触发该类的初始化 引用类的静态常量域或字段，不会导致该类的初始化 注意，接口也是会有初始化的过程，与类唯一不同的是上述第3点：接口在初始化时，并不要求其父接口全部都完成了初始化(原因应该是接口&lt;clinit&gt;()方法不需要调用父类的&lt;clinit&gt;()方法)，只有在真正使用到父接口的时候(如引用接口中定义的常量时)才会初始化。 加载加载阶段的3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的Class对象，作为方法区这个类的各种数据的访问入口 第1件事情中的二进制字节流不一定是本地文件，可能是从ZIP获取、从网络获取(Applet)、动态代理、JSP生成、数据库读取等。 验证验证主要是为了虚拟机对自身保护的一项重要工作，大致会完成以下4个阶段的检验动作： 文件格式验证：检测字节流是否符合Class文件格式规范 元数据验证：语义分析，保证信息符合Java语言规范的要求，主要是数据类型 字节码验证：最复杂的一部分，主要是对类的方法体进行校验(控制流、跳转等) 符号引用验证：发生在解析阶段，主要是对符号引用进行匹配性校验(能否找到、是否可达等) 准备准备阶段是为类变量(静态变量)分配初始值的过程。 注意两点： 初始值通常情况下是数据类型的零值，比如语句public static int value = 123;会在准备阶段给value初始化为int的零值即0，而123会在后续的初始化阶段被赋值给value； 特殊情况下，常量类型会在准备阶段被赋值，比如语句public static final int value = 123; 解析解析阶段是将常量池内的符号引用替换为直接引用的过程。 符号引用是指以一组符号来描述所引用的目标，符号引用在使用时能无歧义地定位到目标。 直接引用是指可以直接指向目标的指针、相对偏移量或一个句柄。 初始化正式开始执行类中定义的Java代码(或者说是字节码)。记得准备阶段有为变量赋予初始值，这里就会为其赋予程序中制定的初始值。 初始化主要的过程是执行&lt;clinit&gt;()方法。 类与类加载器对于任意一个类，都需要由加载它的类加载器和类本身一同确立其在JVM中的唯一性。 在使用instanceof关键字、Class对象的equal()、isAssignableFrom()、isInstance()方法时，都需要判定上述两方面是否相等。自定义的类加载器和系统自带的类加载器加载的同一个类生成的对象使用相等方法验证是得不到相等结果的。 双亲委派模型类加载器划分： 启动类加载器：负责将&lt;JAVA_HOME&gt;\\lib目录下的能被虚拟机识别的类库加载到虚拟机内存中，程序无法直接引用。 扩展类加载器：负责将&lt;JAVA_HOME&gt;\\lib\\ext目录下的能被虚拟机识别的类库加载到虚拟机内存中，程序可直接使用。 应用程序类加载器：负责加载用户类路径(ClassPath)上的类库，程序可直接使用。 双亲委派模型如下图所示： 其中每一层与其父层关系一般不是继承(Inheritance)而是组合(Composition)来复用父加载器的代码。 工作过程：如果一个类加载器收到了类加载的请求，它首先不会尝试加载这个类，而是把这个请求委派给父类加载器去加载，每个层次都是这样，直到请求被传递到顶层的启动类加载器中；而只有父加载器反馈自己无法完成此请求时，子加载器才回去尝试加载。 双亲委托模型在ClassLoader类中的loadClass()方法中实现。","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.guitoubing.top/tags/Java/"}]},{"title":"深入学习Java（更新中）","slug":"深入学习Java（更新中）","date":"2019-03-06T13:01:30.000Z","updated":"2019-03-27T16:25:32.529Z","comments":true,"path":"2019/03/06/深入学习Java（更新中）/","link":"","permalink":"http://blog.guitoubing.top/2019/03/06/深入学习Java（更新中）/","excerpt":"","text":"垃圾回收器—GC众所周知，Java中的GC负责回收无用对象占用的内存资源，但会有特殊情况：假定对象获得了一块”特殊”的内存区域（不是使用new创建的），由于GC只释放那些经由new分配的内存，所以GC不知道如何释放该对象的这块”特殊”内存区域。 作为应对，Java允许在类中定义finalize()方法，它使得在GC回收该对象内存之前先调用finalize()方法，并在下一次GC回收发生时，真正回收对象内存。举个例子：某个对象创建时会在屏幕上绘出一些图像，当没有明确将其从屏幕擦除时，图像便可能会永远存在在屏幕上，若在finalize()指定擦除的方法，那么在GC回收该对象时将会同时将其图像从屏幕上擦除。 关键点： 对象可能不被垃圾回收 垃圾回收并不等于”析构” 垃圾回收只与内存有关 避免使用finalize() “终结函数无法预料，常常是危险的，总之是多余的。”《Effective Java》，第20页 在Java中一切皆为对象，且创建对象的方法只有new，那么必然存在通过某种创建对象以外的方式为对象分配了存储空间。 Native Method(本地方法)是Java中调用非Java代码的方式，此时非Java代码中可能使用了malloc()等分配内存的函数而未使用free()对其释放，此时GC也不会去管这块内存，这就使得需要指定特定的finalize()方法来实现内存的释放。 可见，finalize()不是进行普遍的清理工作的合适方式，因此需要避免使用。 终结条件的验证但是finalize()有个有趣的用法——终结条件。看如下代码： class Book&#123; // Book类，约定其在被回收前必须被签入。 boolean checkedOut = false; Book(boolean checkedOut)&#123; checkedOut = checkedOut; &#125; void checkIn()&#123; checkedOut = false; &#125; protected void finalize()&#123; // 终结条件，对象未被签入 if (checkedOut) &#123; System.out.println(\"Error: checked out\"); &#125; &#125;&#125;public class Main&#123; public static void main(String[] args)&#123; // 创建一个Book对象-novel Book novel = new Book(true); // 将其签入 novel.checkIn(); // 创建一个Book对象，此时该对象未被签入 new Book(true); // 强制执行垃圾回收，此时会先执行finalize System.gc(); &#125;&#125;/* 输出：Error: checked out*/ 我们约定所有的Book对象在创建之前都必须被签入，但是在main中，由于疏忽有个新创建的对象未执行签入操作，此时执行垃圾回收，finalize()中的终结条件被激活，把错误反馈给使用者。 注意这里使用的System.gc()强制调用垃圾回收器 若没有finalize()将很难实现这种操作。 GC如何工作引用计数（未被使用过）对象创建时便有引用计数，当引用计数变为0时，GC回收该对象内存空间。 缺陷：循环引用不适用，即出现”对象应该被回收，但引用计数不为0”的情况，称作”交互自引用的对象组”。如下所示： public class Main &#123; public static void main(String[] args) &#123; // object1指向的对象引用计数器：1 MyObject object1 = new MyObject(); // object2指向的对象引用计数器：1 MyObject object2 = new MyObject(); // object1指向的对象引用计数器：2 object1.object = object2; // object2指向的对象引用计数器：2 object2.object = object1; // object1指向的对象引用计数器减少为1 object1 = null; // object2指向的对象引用计数器减少为1 object2 = null; &#125;&#125; 我们将object1和object2赋值为null，意即我们已经不需要该对象，但由于此时对象的引用计数器不为0导致这两个对象永远不会被回收。 停止-复制（stop-and-copy）遍历所有引用找到所有”活”的对象，将堆中所有存活的对象复制到另一个堆中，没有被复制的便都是垃圾了。 这种策略避免了上述”交互自引用的对象组”无法回收的情况，因为这两个对象不会被看作是存活的对象，即遍历的过程中根本找不到这两个对象（他们不在从GC Root出发连接所有存活结点构成的图中）。 缺陷：效率低 复制需要在两个堆之间操作，即需要维护多一倍的空间； 当程序进入稳定状态之后，可能只产生少量垃圾，此时此策略仍然需要进行复制操作，很浪费。 针对第2个情况，有另外一种策略，如下。 标记-清扫（mark-and-sweep）同样遍历所有引用找到所有”活”的对象，同时会给该对象进行标记，当全部标记工作完成后，开始进行清理工作。没有被标记的对象将会被释放，因此剩下的堆空间是不连续的，此时GC需要使用其他整理的方法来清理内存碎片，称作”标记-整理”。 注意，上面两种垃圾回收机制都不是在后台进行的，意即进行垃圾回收时会暂停程序。 许多文献中有关于”垃圾回收器是低优先级的后台进程”的说法，事实上早期版本的JVM使用这两种策略时并非如此。当可用内存不足时，垃圾回收器会暂停运行程序，而后开展”停止-复制”或”标记-清扫”工作。 “标记-清扫”方式速度相当慢，但是当垃圾很少时，就很快了。 自适应技术JVM会进行监视，如果所有对象都很稳定，GC的效率降低的话，就切换到”标记-清扫”方式；同样，JVM也会跟踪”标记-清扫”方式，若堆空间出现很多碎片，就会切换回”停止-复制”方式。这就是自适应技术。 这是早期Sun版本的垃圾回收器。 分代垃圾收集（Generational Garbage Collection）上述无论是”停止-复制”、”标记-清扫”还是”标记-整理”对于日益增长的对象列表，效率会逐渐低下。 堆被分为三代： 年轻代(Young Generation) 内存空间：eden:S0:S1 = 8:1:1 S0和S1没有先后顺序，任何一个都可能是From survivor space和To survivor space 年老代(Old Generation) 内存空间：年老代:年轻代 ≈ 2:1 持久代(Permanent Generation) 用于存放静态文件，如Java类、方法等。持久代对垃圾回收没有显著影响。有些应用可能动态生成或者调用一些class，例如Hibernate等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。 下面说明一下对象在分配内存、老化、回收的过程： 首先，任何新对象创建时内存都会分配在年轻代的eden space中，S0和S1两个幸存者空间(survivor space)起初都是空的 当eden space满时，会触发第一次较小的垃圾回收过程(minor garbage collection，minor GC)\u0001 实际上MinorGC不一定要等到eden space满了才触发 eden space中所有存活对象(referenced objects)被复制到S0，其余对象(unreferenced objects)被视作垃圾，随eden space一起被回收 当下一次minor GC被触发时，eden space执行与第3点中相同的步骤，不过此时存活对象会被复制到S1，同时S0中的存活对象也会被复制到S1，此时S0和eden space都被回收。注意到此时S1有不同老化程度的对象\u0001 再当下一次minor GC被触发时，重复上述操作，幸存者空间变为S0，eden和S1中的存活对象都被复制到S0，同时老化，此时S1和eden space都被回收 当minor GC持续触发到对象老化程度达到一个阈值(此处为8)时，这些对象从年轻代提升到年老代 以上过程涵盖了整个年轻代老化的过程，最终，会在年老代触发完全的垃圾回收(major gabarge collector, major GC)，清理并压缩该块内存空间。 major GC被触发的原因： 年老代（Tenured）被写满 持久代（Permanent）被写满 System.gc()被显式调用 上一次GC之后Heap的各域分配策略动态变化 HotSpot JVM的垃圾收集器Serial收集器（复制算法)：新生代单线程收集器，标记和清理都是单线程，优点是简单高效。 Serial Old收集器(标记-整理算法)：老年代单线程收集器，Serial收集器的老年代版本。 ParNew收集器(停止-复制算法)：新生代收集器，可以认为是Serial收集器的多线程版本,在多核CPU环境下有着比Serial更好的表现。 Parallel Scavenge收集器(停止-复制算法)：并行收集器，追求高吞吐量，高效利用CPU。吞吐量一般为99%， 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。 Parallel Old收集器(停止-复制算法)：Parallel Scavenge收集器的老年代版本，并行收集器，吞吐量优先 CMS(Concurrent Mark Sweep)收集器(标记-清扫算法)：高并发、低停顿，追求最短GC回收停顿时间，cpu占用比较高，响应时间快，停顿时间短，多核cpu 追求高响应时间的选择 【参考：深入理解JVM(3)——7种垃圾收集器】 可变参数列表Java中的可变参数列表（JSE5之后）的使用与C的使用类似，如下： public class test&#123; public static void main(String[] args)&#123; Integer a = 1; Integer b = 2; Integer c = 3; Other.main(a, b); Other.main(a, b, c); Other.main(); Other.main(new Object[]&#123;a, b&#125;); Other.main(new Object[]&#123;a, b, c&#125;); &#125;&#125;class Other&#123; public static void main(Object... args)&#123; for (Object s : args)&#123; System.out.println(s + \" \"); &#125; &#125;&#125; 如上所示，当输入不同个数参数时，编译器会自动将其转换成数组，当参数本身就是数组时，编译器又不会进行转换，直接传递给函数。参数为空时编译器便直接传递一个空Object数组。 可变参数列表的重载public class test&#123; static void f(Character... args)&#123; System.out.println(\"first\"); &#125; static void f(String... args)&#123; System.out.println(\"second\"); &#125; public static void main(String[] args)&#123; f('a', 'b'); f(\"a\", \"b\"); f(); &#125;&#125; 如上，函数有f(Character... args)和f(String... args)两种重载方式，此时f(&#39;a&#39;, &#39;b&#39;)和f(&quot;a&quot;, &quot;b&quot;)都可正常调用，但是f()会报错，即两种重载都匹配。 此时可通过为其中一个重载函数添加一个非可变参数（可变参数必须位于参数列表最后）。但这样又会产生新的问题，如下： public class test&#123; static void f(float i, Character... args)&#123; System.out.println(\"first\"); &#125; static void f(Character... args)&#123; System.out.println(\"second\"); &#125; public static void main(String[] args)&#123; f(1, 'a'); f('a', 'b'); &#125;&#125; 如上，编译器也会报错，f(&#39;a&#39;, &#39;b&#39;)可匹配两个函数，(可能是)因为char类型可提升至float类型从而匹配第一个重载函数。 此时可为第二个重载函数也添加一个非可变参数，问题可得到解决。 public class test&#123; static void f(float i, Character... args)&#123; System.out.println(\"first\"); &#125; static void f(char i, Character... args)&#123; System.out.println(\"second\"); &#125; public static void main(String[] args)&#123; f(1, 'a'); f('a', 'b'); &#125;&#125; 这种用法比较奇怪，因此”你应该总是只在重载方法的一个版本上使用可变参数列表，或者压根就不是用它”（《Java编程思想》105页）。 内部类内部类对象对外围类对象的访问当外围类对象创建了一个内部类对象时，此内部类对象必定会秘密地捕获一个指向外围类对象的引用，因此内部类对象可以访问外部类对象的所有成员。 interface Selector &#123; boolean end(); Object current(); void next();&#125;public class Sequence &#123; private Object[] items; private int next = 0; public Sequence(int size) &#123; items = new Object[size]; &#125; public void add(Object x)&#123; if (next &lt; items.length)&#123; items[next++] = x; &#125; &#125; private class SequenceSelector implements Selector &#123; private int i = 0; public boolean end() &#123; return i == items.length; &#125; public Object current() &#123; return items[i]; &#125; public void next() &#123; if(i &lt; items.length) i++; &#125; &#125; public Selector selector()&#123; return new SequenceSelector(); &#125; public static void main(String[] args)&#123; Sequence sequence = new Sequence(10); for (int i = 0; i &lt; 10; i++)&#123; sequence.add(Integer.toString(i)); &#125; Selector selector = sequence.selector(); while(!selector.end())&#123; System.out.print(selector.current() + \" \"); selector.next(); &#125; &#125;&#125; Sequence中的内部类SequenceSelector可以访问Sequence的全部成员，就像SequenceSelector自己拥有这些成员一样。 内部类与静态内部类（嵌套类）创建方法// 内部类：DotNew.javapublic class DotNew &#123; class Inner &#123; Inner()&#123; System.out.println(\"创建内部类\"); &#125; &#125; public static void main(String [] args)&#123; DotNew dn = new DotNew(); DotNew.Inner dni = dn.new Inner(); &#125;&#125;// 静态内部类：DotNewStatic.javapublic class DotNewStatic &#123; static class Inner &#123; Inner() &#123; System.out.println(\"创建静态内部类\"); &#125; &#125; public static void main(String[] args)&#123; DotNewStatic.Inner inner = new DotNewStatic.Inner(); &#125;&#125; 匿名内部类Java支持创建一个继承自某基类的匿名类的对象，通过new表达式返回的引用被自动向上转型为对基类的引用。 匿名内部类可以使用默认构造器生成，也可以使用有参数的构造器。 注意，在匿名内部类中若想使用外部定义的对象，该外部对象的参数引用必须是final，如下： // Destination.javapublic interface Destination&#123; String readLabel();&#125;// Parcel9.javapublic class Parcel9 &#123; public Destination destination(final String dest)&#123;// 外部变量dest被引用时需声明为final，否则产生编译时错误 return new Destination()&#123; private String label = dest; @Override public String readLabel() &#123; return label; &#125; &#125;; &#125; public static void main(String[] args)&#123; Parcel9 p = new Parcel9(); Destination d = p.destination(\"Tasmania\"); System.out.println(d.readLabel()); &#125;&#125; 但是我使用的Java 10中，当dest不声明为final时也不会报错，虽然不会报错，但是当更改dest引用时会报前面所述的编译时错误（Local variable dest defined in an enclosing scope must be final or effectively final）。 为什么匿名内部类访问外部变量必须是final的？ 为了避免外部方法修改引用导致内部类得到的引用值不一致和内部类修改引用而导致外部方法的参数值在修改前和修改后不一致 保证回调函数回调时可访问到变量（待研究） 反编译查看其实现细节： &gt; // 源代码&gt; public interface MyInterface &#123;&gt; void doSomething();&gt; &#125;&gt; public class TryUsingAnonymousClass &#123;&gt; public void useMyInterface() &#123;&gt; final Integer number = 123;&gt; System.out.println(number);&gt; &gt; MyInterface myInterface = new MyInterface() &#123;&gt; @Override&gt; public void doSomething() &#123;&gt; System.out.println(number);&gt; &#125;&gt; &#125;;&gt; myInterface.doSomething();&gt; &gt; System.out.println(number);&gt; &#125;&gt; &#125;&gt; &gt; // 反编译结果&gt; class TryUsingAnonymousClass$1&gt; implements MyInterface &#123;&gt; private final TryUsingAnonymousClass this$0;&gt; private final Integer paramInteger;&gt; &gt; TryUsingAnonymousClass$1(TryUsingAnonymousClass this$0, Integer paramInteger) &#123;&gt; this.this$0 = this$0;&gt; this.paramInteger = paramInteger;&gt; &#125;&gt; &gt; public void doSomething() &#123;&gt; System.out.println(this.paramInteger);&gt; &#125;&gt; &#125;&gt; 注意到，number在实际使用时是作为构造函数的参数传入到匿名内部类的，也就是说匿名类内部在使用外部变量时实际上是做了个”拷贝”或者说“赋值”。若可以更改，则会造成数据不一致。 RTTIRTTI(Run-Time Type Identifier)是Java能在运行时自动识别出某个类型的保证（RTTI在Java运行时维护类的相关信息），是多态的基础，由Class类实现。 Class对象每当编写并且编译一个类时，在与类同名的.class文件中会自动产生一个Class对象。实现此过程的JVM子系统被称作类加载器。 Class对象仅在需要的时候才被加载，也就是所有的类都是只在对其第一次使用时，动态加载到JVM中的。所谓第一次使用指的是对类的非常量静态域的第一次引用。 要注意，类的构造器是隐性非常量静态域，所以使用new操作符生成对象也是产生这样的Class类引用。 与此同时，还可以使用Class.forName(类名)产生Class对象的引用，告诉JVM去加载这个类。当JVM未找到这个类，会抛出异常ClassNotFoundException。比如在JDBC连接数据库时常常用到的Class.forName(&quot;com.mysql.jdbc.Driver&quot;)，就是告诉JVM去加载MySQL驱动。 当已经拥有某个类型的对象（实例）时，可通过调用getClass()方法来获取该类型的Class引用。 另一种方法，使用类字面变量。通过使用类名.class可获取此类的Class对象的引用，但是注意，此时此Class对象还未被初始化，还需要等到上述的对类的非常量静态域的第一次引用这一操作执行时才被初始化。 使用.class方法获取Class对象引用实际包含三个步骤： 加载：类加载器创建Class对象 链接 初始化：如果该类具有超类，则对其初始化，执行静态初始化器和静态初始化块 考虑如下代码： &gt; import java.util.Random;&gt; &gt; class Initable &#123;&gt; static final int staticFinal = 1;&gt; static final int staticFinal2 = ClassInitialization.rand.nextInt(1000);&gt; static &#123;&gt; System.out.println(\"Initializing Initable\");&gt; &#125;&gt; &#125;&gt; &gt; class Initable2 &#123;&gt; static int staticNonFinal = 2;&gt; static &#123;&gt; System.out.println(\"Initializing Initable2\");&gt; &#125;&gt; &#125;&gt; &gt; class Initable3 &#123;&gt; static int staticNonFinal = 3;&gt; static &#123;&gt; System.out.println(\"Initializing Initable3\");&gt; &#125;&gt; &#125;&gt; &gt; public class ClassInitialization &#123;&gt; public static Random rand = new Random(47);&gt; public static void main(String[] args) throws ClassNotFoundException &#123;&gt; // 创建Initable的Class对象的引用，Class对象未初始化&gt; Class initable = Initable.class;&gt; // 仍然未初始化，因Initable.staticFinal是常数&gt; System.out.println(Initable.staticFinal);&gt; // 触发了Initable的Class对象的初始化&gt; System.out.println(Initable.staticFinal2);&gt; // 触发了Initable2的Class对象的初始化&gt; System.out.println(Initable2.staticNonFinal);&gt; // 创建Initable3的Class对象的引用，同时会初始化此Class对象&gt; Class initable3 = Class.forName(\"Initable3\");&gt; // 此时已初始化，无需再次初始化&gt; System.out.println(Initable3.staticNonFinal);&gt; &#125;&gt; &#125;&gt; 另外，当我拥有某个Class对象c的时候，我虽然不知道它确切类型，但是可以使用c.newInstance()来正确地获取c代表的类型的实例。但是此方法要求对应的类。 泛化的Class对象引用Class对象可以通过Class&lt;Type&gt;的方法产生特定类型的类引用，创建了使用类型限定后的Class对象引用不能再赋值给除本身和子类的其他的Class对象。 注意这里的子类指的是Class对象的继承关系，而不是类本身的继承关系，如Integer继承自Number，而Integer Class对象却不是Number Class对象的子类。 使用通配符Class&lt;?&gt;优于平凡的Class（实际上是等价的），而且会免除编译器警告，看图： 一种更好的用法，Class&lt;? extends Type&gt;，这种类型限定比直接Class&lt;Type&gt;好的地方在于他产生的Class对象引用可赋值给Type本身及子类的Class对象，这种继承关系是Type所属的继承关系而不是对应的Class对象的继承关系。 转型语法（不常用）class Building&#123;&#125;class House extends Building &#123;&#125;public class ClassCasts &#123; public static void main(String[] args)&#123; Building b = new Building(); Class&lt;House&gt; houseType = House.class; House h = houseType.cast(b); h = (House) b; &#125;&#125; 如上，使用houseType.cast(b)和(House) b效果一样，但是执行的工作却不同，具体内部实现尚未学习到。 动态的类型检测obj instanceof ClassType返回一个布尔值，告诉我们某个对象是不是某个特定类型的实例。 ClassType.isInstance()返回一个布尔值，告诉我们某个对象的类型是不是可以被强转为某个特定类型。 区别区别主要是后者与前者动态等价，看代码： class Father&#123;&#125;class Son extends Father&#123;&#125;public class DynamicEqual &#123; public static void main(String[] args)&#123; Father father = new Father(); Son son = new Son(); // instanceof关键词后面必须跟类型的名称，意即其必须首先知道类型名称 // if (son instanceof father.getClass())&#123; // ... // &#125; // isInstance()方法是类对象的方法，任何一种类型的类对象的引用都可调用该方法，简言之，其前面的Class类对象是可动态的。 if (father.getClass().isInstance(son))&#123; System.out.println(\"isInstance is Dynamic\"); &#125; &#125;&#125; 优点isInstance()的存在可以替代instanceof，而且可使得代码更简洁。比如说有多个类{A1,A2,A3,…}都继承自A，现有一个A对象实例，要判断其为子类中的哪一个从而产生不同响应时： 使用instanceof时可能需要使用switch-case语句；当需要添加一个子类时，需要修改switch-case内部代码。 而使用isInstance()时，可创建一个列表存储所有的子类类型，主程序只需要使用一个循环检测该实例即可；当需要添加一个子类时，只需要修改子类类型列表而不用修改程序代码。 反射机制反射与RTTI的区别 RTTI：编译器在编译时打开和检查.class文件（获取类的Class类对象信息） 反射：JVM在运行时打开和检查.class文件（编译时可能没有此文件，但是在运行时必须在本地机器或者网络上获取.class文件） 类方法提取器通过Class对象引用：调用getMethods()方法获取该类及其父类的方法列表，调用getConstructors()方法获取该类的构造方法列表。要注意能获得的方法与该类的访问权限有关，一个非public类的非public方法是无法被获取的。 接口与类型信息interface关键字的一种重要目标就是允许程序员隔离构件，进而降低耦合性。 包权限安全吗？直接看例子： // A.javapublic interface A&#123; void f();&#125;// HiddenC.javaclass C implements A&#123; @Override public void f() &#123; System.out.println(\"public C.f()\"); &#125; public void g()&#123; System.out.println(\"public C.g()\"); &#125; void u()&#123; System.out.println(\"package C.u()\"); &#125; protected void v()&#123; System.out.println(\"protected C.v()\"); &#125; private void w()&#123; System.out.println(\"private C.w()\"); &#125;&#125;public class HiddenC &#123; public static A makeA()&#123; return new C(); &#125;&#125;// HiddenImplementation.javaimport java.lang.reflect.Method;public class HiddenImplementation &#123; public static void main(String[] args) throws Exception &#123; A a = HiddenC.makeA(); a.f(); System.out.println(a.getClass().getName()); callHiddenMethod(a, \"g\"); callHiddenMethod(a, \"u\"); callHiddenMethod(a, \"v\"); callHiddenMethod(a, \"w\"); &#125; static void callHiddenMethod(Object a, String methodName) throws Exception&#123; // 获取a中的方法 Method g = a.getClass().getDeclaredMethod(methodName); // 修改该方法的权限 g.setAccessible(true); // 调用该方法 g.invoke(a); &#125;&#125;/* outputpublic C.f()Cpublic C.g()package C.u()protected C.v()private C.w()*///:) 当我知道一个类中有哪些方法时，哪怕是private方法仍然可以在使用setAccessble(true)后被调用。 只发布.class文件也是没办法避免此问题，javap -private命令可以反编译.class文件，-private参数约定显示所有的成员 同样，内部类和匿名内部类也是没办法避免此情况 泛型指定类型有保证吗？ 在泛型代码内部，无法获得任何有关泛型参数类型的信息。 例如对于ArrayList&lt;String&gt;和ArrayList&lt;Integer&gt;，二者的实例调用.getClass()获取的Class对象时相同的，如下： import java.util.ArrayList;public class Erase&#123; public static void main(String[] args)&#123; Class&lt;?&gt; s = new ArrayList&lt;String&gt;().getClass(); Class&lt;?&gt; i = new ArrayList&lt;Integer&gt;().getClass(); System.out.println(s == i); System.out.println(s.getName()); System.out.println(s.getTypeParameters()); &#125;&#125;/* Output:truejava.util.ArrayList[Ljava.lang.reflect.TypeVariable;@68f7aae2*/// 但是，如果在一个ArrayList&lt;String&gt;类型的实例中添加Integer会报编译期错误，这个很容易理解（静态类型检查）。但是上述的Class对象相同有给了我们可乘之机： import java.lang.reflect.Method;import java.util.ArrayList;import java.util.Arrays;class Apple&#123; @Override public String toString()&#123; return \"This is an apple\"; &#125;&#125;public class ReflectAdd&#123; public static void main(String[] args) throws Exception&#123; ArrayList&lt;String&gt; strings = new ArrayList&lt;&gt;(); Class&lt;?&gt; s = strings.getClass(); Method method = s.getMethod(\"add\", Object.class); method.invoke(strings, 1); method.invoke(strings, \"2\"); method.invoke(strings, 3); method.invoke(strings, new Apple()); System.out.println(Arrays.toString(strings.toArray())); for (Object o : strings)&#123; System.out.println(o.getClass()); &#125; &#125;&#125;/* Output:[1, 2, 3, This is an apple]class java.lang.Integerclass java.lang.Stringclass java.lang.Integerclass Apple*/// 我们可以看到上述代码使用反射机制成功的在ArrayList&lt;String&gt;里面添加了Integer，原因在于ArrayList的泛型实现ArrayList&lt;E&gt;使其被擦除为ArrayList&lt;Object&gt;，从而通过反射机制找到其add(E e)方法时，实际上是add(Object o)，而我们代码中的Method method = s.getMethod(&quot;add&quot;, Object.class);恰好可以找到包含这样一个参数列表的add方法，后面也就理所当然的可以添加任意类型(甚至是自定义的Apple类)的实例了。 与C++的区别C++: #include &lt;iostream&gt;using namespace std;template&lt;class T&gt; class Manipulator &#123; T obj;public : Manipulator(T x) &#123; obj = x; &#125; void manipulate() &#123; obj.f(); &#125; void manipulate2() &#123; obj.noF(); &#125;&#125;;class HasF &#123;public: void f()&#123; cout &lt;&lt; \"HasF()::f()\" &lt;&lt; endl; &#125;&#125;;class DontHaveF&#123;public: void noF()&#123; cout &lt;&lt; \"Don't have f()\" &lt;&lt; endl; &#125;&#125;;int main()&#123; HasF hf; Manipulator&lt;HasF&gt; manipulator(hf); manipulator.manipulate(); // manipulator.manipulate2(); 无法编译 DontHaveF dhf; Manipulator&lt;DontHaveF&gt; manipulator2(dhf); // manipulator2.manipulate(); 无法编译 manipulator2.manipulate2();&#125;/* Output:HasF()::f()Don't have f()*/// 模板类Manipulator在编译时期便可以检测到函数f()、noF()是在类型参数中存在的，这是在编译器看到声明Manipulator&lt;HasF&gt; manipulator(hf)和Manipulator&lt;DontHaveF&gt; manipulator2(dhf)所产生的结果。 然而Java中却无法实现这样的操作： Java: // HasF.javapublic class HasF&#123; public void f()&#123; System.out.println(\"HasF.f();\"); &#125;&#125;// Manipulation.javaimport java.lang.reflect.Method;class Manipulator&lt;T&gt; &#123; private T obj; public Manipulator(T x) &#123; obj = x; &#125; public void manipulate()&#123; obj.f() // 会报编译错误 &#125;&#125;public class Manipulation&#123; public static void main(String[] args)&#123; HasF hf = new HasF(); Manipulator&lt;HasF&gt; manipulation = new Manipulator&lt;HasF&gt;(hf); manipulation.manipulate(); &#125;&#125; 由于Java在编译过程中，Manipulator&lt;T&gt;是无法确定其类型参数，只知道他是一个Object实例，因此obj只能调用Object基类所有的公开方法。若想实现C++的操作有两种办法(目前我已知的只有这两种)。 为T限定参数类型（给定边界），即声明时指定其所继承的基类： class Manipulator&lt;T extends HasF&gt;&#123; ...&#125; 使用反射机制调用f() import java.lang.reflect.Method;class Manipulator&lt;T&gt; &#123; private T obj; public Manipulator(T x) &#123; obj = x; &#125; public void manipulate() throws Exception&#123; Class&lt;?&gt; oc = obj.getClass(); Method method = oc.getMethod(\"f\"); method.invoke(obj); &#125;&#125;public class Manipulation&#123; public static void main(String[] args) throws Exception&#123; HasF hf = new HasF(); Manipulator&lt;HasF&gt; manipulation = new Manipulator&lt;HasF&gt;(hf); manipulation.manipulate(); &#125;&#125;/* Output:HasF.f();*/// 擦除带来的问题 擦除的主要正当理由是从非泛化代码到繁华代码的转变过程，以及在不破坏现有类库的情况下，将泛型融入Java语言。 泛型不能用于显式地引用运行时类型的操作之中，例如转型、instanceof、new表达式，因为在静态类型检测之后，泛型就已经被擦除了。 也就是说，需要时刻提醒自己，我只是看起来好像拥有有关参数的类型信息而已。实际上，它只是一个Object！ 边界既然编译器会擦除类型信息，那么擦除发生的地点是在哪儿呢？便是所谓的边界：对象进入和离开方法的地点，也就是编译器在执行类型检查并插入转型代码的地点。 通配符import java.util.Arrays;import java.util.List;class Fruit&#123;&#125;class Apple extends Fruit&#123;&#125;class Jonathan extends Apple&#123;&#125;class Orange extends Fruit&#123;&#125;public class CompilerIntelligence&#123; public static void main(String[] args)&#123; List&lt;? extends Fruit&gt; flist = Arrays.asList(new Apple()); Apple a = (Apple) flist.get(0); // Orange o = (Orange) flist.get(0); 运行时错误 // flist.add(new Fruit()); 编译错误 // flist.add(new Apple()); 编译错误 System.out.println(flist.contains(a)); System.out.println(flist.contains(new Apple())); System.out.println(flist.indexOf(new Apple())); &#125;&#125;/*truefalse-1*/// 对于使用了通配符的List&lt;? extends Fruit&gt; flist来说，其需要用到类型参数的方法例如add()参数也变成了&lt;? extends Fruit&gt;，然而编译器并不能知道这里需要哪一个具体的子类型，于是编译器拒绝了所有对参数列表中涉及到了通配符的方法的调用，除了构造器。 容器完整的容器分类法： HashMapHashMap采用了链地址法，也就是数组+链表的方式。主干是一个Entry数组，链表是为了解决哈希冲突而存在的。HashMap中的链表越少，性能越好。 Entry数组长度为2的次幂 由于在计算key的插入位置时用到了hash &amp; (length-1)，hash是key计算出来的哈希值，想象一下当length不为2的次幂时，length-1的二进制必然有0位，那么意味着该位为0的位置永远不可能被当做插入位置，造成了严重的空间浪费。 由于刚才的原因，数组可以使用的位置比数组长度小了很多，意味着进一步增加了碰撞的几率，意即equal()操作多了起来，效率也就慢了。 resizeHashMap当Entry数组元素超过数组大小*loadFactor时，就会进行数组扩容。loadFactor默认值为0.75。此时Entry数组大小会扩大一倍，保证了2的次幂大小。 扩容的时候所有的key需要重新计算哈希值。 JDK1.8优化由于1.8之前的HashMap在hash冲突很大时，遍历链表将会效率很低，于是1.8中采用了红黑树部分代替链表，当链表长度到达阈值时，就会改用红黑树存储。 HashTableHashTable在结构上与HashMap基本相同，下面总结其不同点： HashMap可有null key，HashTable获取null key会报空指针异常 HashTable有synchronized方法同步，线程安全；HashMap线程不安全 Hash值计算方法不同 HashTable初始大小为11，扩容机制为2*old+1；HashMap初始大小为16，扩容机制为2*old ConcurrentHashMapJDK1.7版本中的ConcurrentHashMap比HashMap多了一层Segment，其中Segment继承于ReentrantLock：一次put操作会调用scanAndLockForPut()方法自旋获取锁；而一次get操作则不需要加锁，value用volatile关键词修饰的，保证了内存可见性，每次获取的必定是新值，由于不用加锁，所以很高效。 JDK1.8版本移除了segment，有一个Node数组相当于HashMap中的Entry数组。同时采用了CAS+synchronized关键字进行put操作。put操作步骤如下： 根据key计算出hashcode； 判断是否需要进行初始化； f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功； 判断是否需要进行扩容； 如果都不满足，则利用 synchronized 锁写入数据； 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 线程Brian Goetz的线程同步规则 如果你正在写一个变量，他可能接下来将被另一个线程读取，或者正在读取一个上一次已经被另一个线程写过的变量，那么必须使用同步，并且，读写线程都必须用相同的监视器锁同步。 ExecutorExecutor用来管理Thread对象，简化了并发编程，允许管理异步任务的执行，而无须显式管理线程的声明周期。 import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class CachedThreadPool &#123; public static void main(String[] args)&#123; ExecutorService exec = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++)&#123; exec.execute(new LiftOff()); &#125; exec.shutdown(); &#125;&#125;/* Output:#4(9).#2(9).#1(9).#2(8).#3(9).#4(8).#0(9).#1(8).#2(7).#3(8).#4(7).#0(8).#1(7).#2(6).#3(7).#4(6).#0(7).#1(6).#2(5).#3(6).#4(5).#0(6).#1(5).#2(4).#3(5).#4(4).#0(5).#1(4).#2(3).#3(4).#4(3).#0(4).#1(3).#2(2).#3(3).#4(2).#0(3).#1(2).#2(1).#3(2).#4(1).#0(2).#1(1).#2(LiftOff!).#3(1).#4(LiftOff!).#0(1).#1(LiftOff!).#0(LiftOff!).#3(LiftOff!).*/// 线程池线程池的作用是限制系统中执行线程的数量，根据系统情况可以自动或手动设置线程数量，达到最佳运行效果。线程池中的线程若出现异常，会自动补充一个新线程以代替。 newSingleThreadExecutor()：创建一个单线程的线程池，所有的任务在等待队列中等待该线程。 newFixedThreadPool()：创建固定大小的线程池。 newCachedThreadPool()：创建一个可缓存的线程池。会根据任务数量自动添加和回收线程，线程池的大小依赖于JVM能够创建的最大线程大小。 newScheduledThreadPool()：创建一个大小无限的线程池，此线程支持定时以及周期性执行任务的需求。 任务的返回值通常实现Runnable接口的类是没有返回值的，要想任务在完成时返回一个值可实现Callable&lt;T&gt;接口，其泛型类型参数表示方法call()的返回值，并且需要使用ExecutorService.submit()方法调用他。 import java.util.ArrayList;import java.util.concurrent.*;class TaskWithResult implements Callable&lt;String&gt; &#123; private int id; public TaskWithResult(int id) &#123; this.id = id; &#125; public String call() &#123; return \"result of TaskWithResult\" + id; &#125;&#125;public class CallableDemo &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); ArrayList&lt;Future&lt;String&gt;&gt; results = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; results.add(exec.submit(new TaskWithResult(i))); &#125; for (Future&lt;String&gt; fs : results) &#123; try &#123; System.out.println(fs.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; System.err.println(e); &#125; finally &#123; exec.shutdown(); &#125; &#125; &#125;&#125;/* Output：result of TaskWithResult0result of TaskWithResult1result of TaskWithResult2result of TaskWithResult3result of TaskWithResult4result of TaskWithResult5result of TaskWithResult6result of TaskWithResult7result of TaskWithResult8result of TaskWithResult9*/// ExecutorService对象的submit()方法会返回一个Future&lt;T&gt;对象，泛型类型参数即是实现Callable&lt;T&gt;的类型参数。get()方法会返回结果，若任务未完成，get()会阻塞。 优先级优先权不会导致死锁，优先级较低的线程仅仅是执行的频率较低。 但是注意优先级高的线程也有几率比优先级底的线程执行的少。 优先级是否起作用也与操作系统及虚拟机版本相关联，会随着不同的线程调度器而产生不同的含义。 Thread.yield()可靠吗？Thread.yield()源码中提及了该方法的效果：当前线程会给线程调度器一个暗示，说明我愿意让出当前资源供你调度，但是线程调度器可自由的选择是否忽略其暗示。意即此处的让步只是一厢情愿，发出让步的线程同样可以继续执行。 后台线程后台线程并不属于程序中不可或缺的部分。当所有的非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程。 执行main()就是一个非后台线程，当main()没有执行结束时，程序就不会终止。 后台线程创建的线程也将是后台线程。 同时要注意在后台线程的run()方法中若有finally子句，其中的语句也不一定会执行。因为随着非后台线程的结束，后台线程会突然终止。 Thread还是Runnable创建多线程任务可以继承Thread类重写其run()方法，也可以实现Runnable接口实现其run()方法。 实际应用中，Runnable还是比较有优势的： 避免了由于Java的单继承体系带来的局限（实际上继承Thread也是可以避免，使用内部类） 多个线程区处理同一资源，而非独立处理（这句话有问题） 注意，一开始在理解这里的时候我出现了误解，什么叫处理同一资源，意思指的是Thread类无法达到资源共享的目的，而Runnable可以。但是在使用线程池的时候，Thread又可以了(待确认)，如下： import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;class TestThread extends Thread &#123; private int val = 10; public void run()&#123; while(true)&#123; System.out.println(Thread.currentThread() + \"-- val: \" + val--); Thread.yield(); if (val &lt;= 0) return; &#125; &#125;&#125;class TestRunnable implements Runnable &#123; private int val = 10; @Override public void run() &#123; while(true)&#123; System.out.println(Thread.currentThread() + \"-- val: \" + val--); Thread.yield(); if (val &lt;= 0) return; &#125; &#125; &#125;public class TestRunnableAndThread &#123; public static void main(String[] args)&#123; Runnable runnable = new TestRunnable(); Thread thread = new TestThread(); // a.只有1个线程处理一个数据 thread.start(); thread.start(); thread.start(); thread.start(); thread.start(); // b.5个不同线程处理不同数据 new TestThread().start(); new TestThread().start(); new TestThread().start(); new TestThread().start(); new TestThread().start(); // c.5个不同线程处理相同数据 new Thread(runnable).start(); new Thread(runnable).start(); new Thread(runnable).start(); new Thread(runnable).start(); new Thread(runnable).start(); // d.5个不同线程处理相同数据 ExecutorService execRun = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) execRun.execute(runnable); // e.5个不同线程处理5个不同数据 ExecutorService execRun2 = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) execRun2.execute(new TestRunnable()); // f.5个不同线程处理相同数据 ExecutorService execThread = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++)&#123; execThread.execute(thread); &#125; // g.5个不同线程处理5个不同数据 ExecutorService execThread2 = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) execThread2.execute(new TestThread()); // i.5个不同线程处理相同数据 ExecutorService execThread2 = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) execThread2.execute(new Thread(runnable)); execRun.shutdown(); execRun2.shutdown(); execThread.shutdown(); execThread2.shutdown(); &#125;&#125; 其中：c、d、i实际上是相同的，b、g是相同的，而a和f看起来相同，但是实际作用却差别很大，待研究。 实际上，a是错误的用法，b、c基本上不用，而且，注意当需要共享数据的时候，通常不会在类中定义共享变量，而需要一个线程安全的外部对象。 共享资源Synchronized冲突是多线程问题必须解决的任务，Java使用synchronized关键字标识访问共享资源的方法，JVM负责跟踪对象被加锁的次数，注意，当对象被解锁（完全释放时）其加锁计数为0，显然此时所有任务都有几率向其加锁，当某一个任务第一次给该对象加锁时，计数变为1，此后只有这个相同的任务能继续给该对象加锁，计数会递增；每当离开一个synchronized方法时，计数递减，直到计数变为0时，对象被解锁。要注意，每个访问该临界资源的方法都必须被同步，否则就不会正确地工作。 通常synchronized关键字标识方法时，是在this上面同步，也可在方法中使用synchronized(synObject){}域，以在特定的对象上同步，因此不同对象上的锁是相互无关的。 LockLock对象必须被显式地创建、锁定和释放。 import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class MutexEvenGenerator &#123; private int currentEvenValue = 0; // 显式声明 private Lock lock = new ReentrantLock(); public int next() &#123; // lock()方法创建临界资源 lock.lock(); try &#123; ++currentEvenValue; Thread.yield(); ++currentEvenValue; // return语句必须出现在try子句中 return currentEvenValue; &#125;finally &#123; // unlock()方法完成清理工作 lock.unlock(); &#125; &#125;&#125; 与synchronize相比，显式的Lock优点在于可以使用finally子句将系统维护在正常的状态，而在使用synchronize关键字时，某些事物失败了就会抛出异常。 import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantLock;public class AttemptLocking&#123; private ReentrantLock lock = new ReentrantLock(); public void untimed() &#123; boolean captured = lock.tryLock(); try &#123; System.out.println(\"untimed - tryLock(): \" + captured); System.out.println(\"untimed - isHeldByCurrentThread(): \" + lock.isHeldByCurrentThread()); &#125; finally &#123; if (captured) lock.unlock(); &#125; &#125; public void timed() &#123; boolean captured = false; try &#123; captured = lock.tryLock(2, TimeUnit.SECONDS); &#125; catch(InterruptedException e)&#123; throw new RuntimeException(e); &#125; try &#123; System.out.println(\"timed - tryLock(2, TimeUnit.SECONDS): \" + captured); System.out.println(\"timed - isHeldByCurrentThread(): \" + lock.isHeldByCurrentThread()); &#125; finally &#123; if (captured) lock.unlock(); &#125; &#125; public static void main(String[] args)&#123; final AttemptLocking al = new AttemptLocking(); al.untimed(); al.timed(); // 匿名内部类创建单独的Thread来获取锁，而未释放 new Thread()&#123; &#123;setDaemon(true);&#125; public void run()&#123; al.lock.lock(); System.out.println(\"acquired\"); System.out.println(\"main - isHeldByCurrentThread(): \" + al.lock.isHeldByCurrentThread()); &#125; &#125;.start(); Thread.yield(); al.untimed(); al.timed(); &#125;&#125;/* Output:untimed - tryLock(): trueuntimed - isHeldByCurrentThread(): truetimed - tryLock(2, TimeUnit.SECONDS): truetimed - isHeldByCurrentThread(): trueacquiredmain - isHeldByCurrentThread(): trueuntimed - tryLock(): falseuntimed - isHeldByCurrentThread(): falsetimed - tryLock(2, TimeUnit.SECONDS): falsetimed - isHeldByCurrentThread(): false*/// 看代码就很容易理解了。 原子性与易变性原子操作有可能无需同步机制，因为操作是不可分的，一次操作进行的时候不会有其他操作的介入，但是实现原子操作是很难的，或者说原子操作是较少存在的。同时，即使操作是原子性的，操作的修改也可能暂时性地存储在本地处理器的缓存中，对于其他任务有可能是不可视的，因此不同的任务对应用状态有不同的视图。 volatile关键字确保了前面提及的可视性，以及当一个域被声明为volatile时，那么只要对这个域产生了写操作，所有的读操作都可以看到这个修改。即使使用了本地缓存，volatile域的修改也会被立即写入到主存中。 所以非volatile域上的原子操作未刷新到主存中去，因此其他读操作未必会看到新值。 因此多个任务在同时访问某个域时，要么使用volatile关键字限定，要么经由同步机制访问，以保证一致性。 import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class AtomicityTest implements Runnable &#123; private int i = 0; public int getValue() &#123; return i; &#125; private void evenIncrement() &#123; i++; i++; &#125; @Override public void run() &#123; while (true) evenIncrement(); &#125; public static void main(String[] args)&#123; ExecutorService exec = Executors.newCachedThreadPool(); AtomicityTest at = new AtomicityTest(); exec.execute(at); while (true)&#123; int val = at.getValue(); if (val%2 != 0)&#123; System.out.println(val); System.exit(0); &#125; &#125; &#125;&#125; 看上面这个例子，程序找到奇数时便终止，理想状态下，通过evenIncrement()加2，i应该始终为偶数，但是由于缺少同步机制，可能导致不稳定的中间状态被读取即获取到奇数，同时i也不是volatile的，因此还存在可视性问题（当然，这里仅仅使用volatile限定i是不够的，因为i++操作不是原子性的）。下面使用Lock显式加锁以实现同步： import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class AtomicityTest implements Runnable &#123; private int i = 0; private Lock lock = new ReentrantLock(); public int getValue() &#123; try &#123; lock.lock(); return i; &#125; finally &#123; lock.unlock(); &#125; &#125; private void evenIncrement() &#123; try &#123; lock.lock(); i++; i++; &#125; finally &#123; lock.unlock(); &#125; &#125; @Override public void run() &#123; while (true) evenIncrement(); &#125; public static void main(String[] args)&#123; ExecutorService exec = Executors.newCachedThreadPool(); AtomicityTest at = new AtomicityTest(); exec.execute(at); while (true)&#123; int val = at.getValue(); System.out.println(val); if (val%2 != 0)&#123; System.out.println(val); System.exit(0); &#125; &#125; &#125;&#125; 原子类上面说到原子操作是较少的，而JSE5引入了AtomicInteger、AtomicLong、AtomicReference等特殊的原子性变量类，这些类的一些方法在某些机器上可以是原子的。通常用在性能调优方面。 ReetrantLockReentrantLock是一个可重入的互斥锁，又被称为”独占锁“。 可重入锁指的是某个线程获取锁之后，在执行相关的代码块时可继续调用加了同样的锁的方法，理解为嵌套锁。反之，不可重入锁称作自旋锁。 独占锁指的是同一时间点锁只能被一个线程获取。 同时ReentrantLock也分为公平锁和非公平锁，它们的区别体现在获取锁的机制是否公平。公平锁通过一个FIFO等待队列管理等待获取该锁的所有进程，而非公平锁不管是否在队列中，都直接获取该锁。 ReentrantReedWriteLock顾名思义，ReentrantReadWriteLock维护了读取锁和写入锁。 读取锁用于只读操作，是共享锁，能被多个线程获取； 写入锁用于写入操作，是独占锁，只能被一个线程获取。 线程状态 新建（new） 就绪（Runnable） 阻塞（Blocked） 调用sleep(milliseconds)方法使任务休眠 调用wait()方法挂起 等待输入输出完成 获取锁失败 死亡（Dead） 线程协作wait()与sleep()和yield()不同，调用wait()时需要释放当前线程获取的锁，由于某个条件不成立使得当前线程进入阻塞状态，直到其他修改使得此条件发生了变化调用了notifyAll()方法时，线程被唤醒。 但是要注意，使用wait()的时候需要用while循环包围： 为了检查线程是否被意外唤醒 notifyAll()notifyAll()用来唤醒等待某个锁的所有挂起的任务。等待某个锁指的是某些需要获取共同的锁的线程，notifyAll()可以唤醒这些线程，而不是程序中所有被挂起的线程。 死锁多个并发进程因争夺系统资源而产生相互等待的现象。 四个必要条件： 互斥 占有且等待 不可抢占 循环等待 免锁容器免锁容器的策略是：对容器的修改可以与读取操作同时发生，只要读取者只能看到完成修改的结果即可。修改时在容器数据结构的某个部分的一个单独的副本上执行的，并且这个副本在修改过程中是不可视的。只有当修改完成时，被修改的结构才会自动地与主数据结构进行交换，之后读取者就可以看到这个修改了。 这些容器允许并发的读取和写入，但是在任何修改完成之前，读取者仍然是不能够看到它们的。 乐观锁每次拿数据的时候认为别人不会修改，所以不会上锁，但是在更新的时候会判断此期间有没有别人更新这个数据。上述有提到的原子类就是使用了CAS实现的乐观锁。 悲观锁每次拿数据的时候都认为别人会修改，所以每次拿数据的时候都会上锁。synchronized关键字的实现就是悲观锁。 CAS(Compare And Swap)技术CAS是用来实现乐观锁的一种方法，原理见这里。 CAS机制使用3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。 更新一个变量的时候，只有当A和V的实际值相同时，才会将V对应的值修改为B。 缺点： ABA问题：链表的头在变化了两次后恢复了原值，但是不代表链表就没有发生变化 循环时间长开销大 只能保证一个共享变量的原子性 未完~","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.guitoubing.top/tags/Java/"}]},{"title":"数据库与内存数据库实验报告","slug":"数据库与内存数据库实验报告","date":"2019-03-05T12:34:59.000Z","updated":"2019-03-05T12:38:38.160Z","comments":true,"path":"2019/03/05/数据库与内存数据库实验报告/","link":"","permalink":"http://blog.guitoubing.top/2019/03/05/数据库与内存数据库实验报告/","excerpt":"","text":"一、实验前准备机器配置 时间计算标准SQL执行过程首先，本实验的目的是优化数据库，减少数据库语句执行的时间，在此之前，我们要明白一点数据库执行时间这句话包含了哪些东西。我们从数据库执行一条SQL语句的过程来看，对于MySQL、Oracle、TimesTen这些具有内部优化的数据库来说，一般的执行步骤是： 而我们的关注点应放在语句执行这一步骤上。 语句执行步骤进一步深入MySQLMySQL的执行时间为以下项目的加和： State Desription 1. Checking permissions 检查用户的权限 2. Opening tables 打开表 3. Init 初始化过程 4. System lock 获取锁 5. Optimizing 优化SQL语句 6. Statistics 分析SQL语句 7. Preparing 准备执行条件 8. Executing 执行SQL语句 9. Sending data 进行磁盘的IO以及数据的发送返回 10. End 执行结束 11. Closing tables 关闭表 12. Freeing items 释放资源 13. Cleaning up 清理缓存以及临时空间 Oracle一条SQL语句在进入语句执行这一步骤之后，若不在高速缓存中，数据库会从数据文件中把所在位置移动到高速缓存中而后返回给客户端。这也就意味着，同一条语句在以后的执行中都只从高速缓存取数据（前提是高速缓存未被清除）。这样想的话，我们要做的优化应该是一条SQL语句在第一次进入数据库时数据库作出的应答。 那么，我们通过数据库工具来查看执行的SQL语句的时间应该是不准的：因为我们不知道这条语句是不是第一次执行，或者说我们不知道高速缓存中有没有我们需要的数据。这里我们选择使用Oracle的执行计划来看SQL语句的准确的执行过程以及其开销。如下图： 我们的关注点在上图中的COST，cost是Oracle里判定效率的唯一标准，Oracle的优化器会计算当前SQL语句的最低cost方案，而后为其选择执行计划。Oracle中定义了语句的一次执行开销cost = CPU cost + IO cost，对于cost，我们可以理解为一次过程所需要访问的Block数量，那么执行时间就是t = Block数量 * Block处理时间。 后续实验过程中的Oracle部分我们都是通过执行计划及cost来做对比。为此我们写了一个procedure来记录一条语句执行计划中记录的cost： -- 计算query的costcreate or replace procedure calc_cost(query_ varchar2, func_ number, desc_ varchar2) is cpu_cost number := 0; io_cost number := 0; cost_ number := 0; -- 一条SQL语句的唯一标识 hash_v number := 0; -- 获取上述标识 select_v_sql varchar2(255) := &apos;select hash_value into :x from v$sql a where a.SQL_TEXT like &apos;&apos;:y&apos;&apos;&apos;; -- 获取cost select_v_sql_plan varchar2(255) := &apos;select max(cpu_cost) , max(io_cost) into :x :y from V$SQL_PLAN a where hash_value=:z&apos;; -- 结果保存 insert_result varchar2(255) := &apos;insert into t_cost_record values(:x,:y,:z,:a,:b,:c)&apos;;begin execute immediate select_v_sql using hash_v, query_; execute immediate select_v_sql_plan using cpu_cost, io_cost, cost_; execute immediate insert_result using id_seq.nextval, func_, cpu_cost, io_cost, cost_, desc_;end; TimesTen对于TimesTen来说，不如Oracle的优化器来的智能，它完全靠速度制胜。Oracle中我们讨论了执行时间t = Block数量 * Block处理时间，TimesTen就是在Block处理时间上有很大的优势。遗憾的是TimesTen中没有作为本身的高速缓存这一说，这也就意味着一条SQL语句进入TimesTen时都要经过SQL Prepare -&gt; SQL Execution -&gt; SQL Fetch这一完整的过程，如下： 二、MySQL实验过程功能：查询电影评论平均分排行前一百的电影 SQL语句select m.name_, sum(c1.score) as movie_avg_comment_scorefrom movie m , comment_1 c1where m.id_ = c1.movie_idgroup by m.name_order by movie_avg_comment_score desclimit 100; 仅有主键索引执行之后得到如下的时间消耗： 这个时间相比其他数据库慢得多（oracle 约4s)，不符合预期的耗时，且在执行时mysqld的cpu占用率非常高。于是根据以下步骤查看sql执行慢的原因。 MySQL进程表使用show processlist命令查看正在执行的sql语句列表： 可以看到当前执行的语句就是我们的目标语句，并且没有其他语句在与当前查询语句竞争资源，所以应该把语句执行过慢点原因定位到查询语句本身。 解释执行计划通过查看process list得知对应语句有问题之后，使用describe命令查看当前SQL语句的执行计划，MySQL的执行计划与其他相关参数： 可以看到在执行计划中，movie表有可选的主码索引，但是在这个场景中mysql并没有选择使用主码索引，没有使用索引是导致时间过慢点一个原因，于是可以考虑在电影名字字段上建立索引。 执行过程为了进一步查看SQL语句具体的系统能耗分布，我们选择使用profiling来分析我们SQL语句的执行过程，在没有创建其他索引的情况下我们得到如下的时间消耗分析： 我们可以看到其中能耗占比最高的是 Sending data项，查看官方文档相关解释： The thread is reading and processing rows for a SELECT statement, and sending data to the client. Because operations occurring during this state tend to perform large amounts of disk access (reads), it is often the longest-running state over the lifetime of a given query. 该线程正在读取和处理SELECT语句的行，并将数据发送到客户端。 由于在此状态期间发生的操作往往会执行大量磁盘访问（读取），因此它通常是给定查询生命周期中运行时间最长的状态 所以这个与我们的磁盘IO的速度以及网络的传输速度有关，磁盘的IO除了受到硬件本身的限制之外还会与数据库的索引有关，更换性能更好的磁盘或者建立适当的索引以减少磁盘IO数量都可以提高查询语句的执行速度。 建立索引根据以上分析过程得到的结论，我们在电影表的名字字段上建立合适的索引，我们在mysql中选择了B-Tree索引。 建立索引之后再查看相同SQL语句的执行计划： key字段上的值从原来的null 变成了我们刚刚创建的索引。 执行该SQL语句，并在结束后使用Profiling查看优化后的执行时间： sending data: 从磁盘读取数据，将数据返回，表示磁盘IO create index：使用临时表来处理select语句 可以看到Sending data的值明显小于优化前，总的执行时间也变为优化前的1/5，所以增加索引能够在很大程度上加快查询的速度。 实验结论综合其他实验，在大数据的处理上MySQL数据库的性能远不如ORACLE及TIMESTEN数据库，有数十倍的耗时差距，而且MySQL作为一个轻量级的数据库，支持的索引类型也少于其他两个数据库，在SQL语句的优化方面也不如ORACLE数据库那般强大。所以在当前的实验环境下我们更倾向于使用ORACLE数据库与TIMESTEN数据库进行对比。 三、Oracle实验过程实验1：SQL各子句条件顺序对查询效率的影响查询语句SELECT T_MOVIE.NAME_, T_MOVIE.YEAR_ FROM T_MOVIE,T_MOVIE_REGION,T_REGIONWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_ID AND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_IDAND T_REGION.NAME_='美国' AND T_MOVIE.SCORE_&gt;6; 实验方式通过对MySQL、Oracle、TimesTen中SQL语句中select、from、where子句的排序顺序进行调换，观察执行计划的改变 实验结果 SELECT子句中，结果集的排序方式不会影响执行计划 FROM子句中，各个表的排序方式不会影响执行计划 WHERE子句中，各个条件的排序方式不会影响执行计划，优化器会首先将筛选条件应用于表进行过滤，最后逐次执行表的连接。 分析自Oracle6以来，一直采用RBO（Rule-Based Optimization 基于规则的优化器），其基于一套严格死板的使用规则。由于其对于规则的崇尚性，SQL语句的写法则尤为重要。而自Oracle8以来，Oracle引入了一种新的优化方式，即CBO（Cost-Based Optimization 基于代价的优化器），从Oracle 10g开始RBO被完全舍弃。使用CBO优化器时，对SQL语句的要求变得没有那么苛刻，优化器会选择开销比较小的方式执行，而不由用户所写的表的顺序、条件的顺序决定。MySQL与TimesTen的优化器也是如此，有其自己的选择。 连接方式和连接顺序连接顺序：连接顺序表明以哪张表为驱动表来连接其他表的先后顺序。即以某张表为基点，根据其中的信息再去访问其他的表。 连接方式：简单来讲，就是两个表获得满足条件的数据时的连接过程。主要有三种表连接方式，嵌套循环（NESTED LOOPS）、哈希连接（HASH JOIN）和排序-合并连接（SORT MERGE JOIN）。 排序-合并连接假设有查询：select a.name, b.name from table_A a join table_B b on (a.id = b.id) 内部连接过程： a) 生成 row source 1 需要的数据，按照连接操作关联列（如示例中的a.id）对这些数据进行排序 b) 生成 row source 2 需要的数据，按照与 a) 中对应的连接操作关联列（b.id）对数据进行排序 c) 两边已排序的行放在一起执行合并操作（对两边的数据集进行扫描并判断是否连接） 延伸： 如果示例中的连接操作关联列 a.id，b.id 之前就已经被排过序了的话，连接速度便可大大提高，因为排序是很费时间和资源的操作，尤其对于有大量数据的表。 故可以考虑在 a.id，b.id 上建立索引让其能预先排好序。不过遗憾的是，由于返回的结果集中包括所有字段，所以通常的执行计划中，即使连接列存在索引，也不会进入到执行计划中，除非进行一些特定列处理（如仅仅只查询有索引的列等）。 排序-合并连接的表无驱动顺序，谁在前面都可以； 排序-合并连接适用的连接条件有： &lt; &lt;= = &gt; &gt;= ，不适用的连接条件有： &lt;&gt; like 嵌套循环内部连接过程： a) 取出 row source 1 的 row 1（第一行数据），遍历 row source 2 的所有行并检查是否有匹配的，取出匹配的行放入结果集中 b) 取出 row source 1 的 row 2（第二行数据），遍历 row source 2 的所有行并检查是否有匹配的，取出匹配的行放入结果集中 c) …… 若 row source 1 （即驱动表）中返回了 N 行数据，则 row source 2 也相应的会被全表遍历 N 次。 因为 row source 1 的每一行都会去匹配 row source 2 的所有行，所以当 row source 1 返回的行数尽可能少并且能高效访问 row source 2（如建立适当的索引）时，效率较高。 嵌套循环的表有驱动顺序，注意选择合适的驱动表。嵌套循环连接有一个其他连接方式没有的好处是：可以先返回已经连接的行，而不必等所有的连接操作处理完才返回数据，这样可以实现快速响应。 应尽可能使用限制条件（Where过滤条件）使驱动表（row source 1）返回的行数尽可能少，同时在匹配表（row source 2）的连接操作关联列上建立唯一索引（UNIQUE INDEX）或是选择性较好的非唯一索引，此时嵌套循环连接的执行效率会变得很高。若驱动表返回的行数较多，即使匹配表连接操作关联列上存在索引，连接效率也不会很高。 哈希连接哈希连接只适用于等值连接（即连接条件为 = ） HASH JOIN对两个表做连接时并不一定是都进行全表扫描，其并不限制表访问方式； 内部连接过程简述： a) 取出 row source 1（驱动表，在HASH JOIN中又称为Build Table） 的数据集，然后将其构建成内存中的一个 Hash Table（Hash函数的Hash KEY就是连接操作关联列），创建Hash位图（bitmap） b) 取出 row source 2（匹配表）的数据集，对其中的每一条数据的连接操作关联列使用相同的Hash函数并找到对应的 a) 里的数据在 Hash Table 中的位置，在该位置上检查能否找到匹配的数据 实验2：B树索引与位图索引的比较sql语句-- 小基数SELECT T_MOVIE.NAME_, T_MOVIE.YEAR_FROM T_MOVIE,T_MOVIE_REGION,T_REGIONWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_IDAND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_IDAND T_REGION.NAME_='美国'AND T_MOVIE.SCORE_&gt;6;-- 大基数SELECT T_MOVIE.NAME_, T_MOVIE.YEAR_FROM T_ACTOR,T_ACT,T_MOVIEWHERE T_ACTOR.NAME_='Tom Byron'AND T_MOVIE.SCORE_&gt;6AND T_ACTOR.ID_=T_ACT.ACTOR_IDAND T_MOVIE.ID_=T_ACT.MOVIE_ID; 索引语句-- B树CREATE INDEX IX_MOVIE_SCORE ON T_MOVIE(SCORE_);CREATE INDEX IX_MOVIE_NAME ON T_MOVIE(NAME_);CREATE INDEX IX_ACTOR_NAME ON T_ACTOR(NAME_);-- BitMapCREATE BITMAP INDEX IXBM_MOVIE_NAME ON T_MOVIE(NAME_);CREATE BITMAP INDEX IXBM_MOVIE_SCORE ON T_MOVIE(SCORE_);CREATE BITMAP INDEX IXBM_ACTOR_NAME ON T_ACTOR(NAME_); 查询消耗B树索引（小基数） 位图索引（小基数） 不加索引（大基数） B树索引（大基数） 位图索引（大基数） 分析即使在字段基数较大的情况下，位图索引依然有比B树索引更好的表现。但是有个问题，创建位图索引时所需的时间更长。此外，由于表中该字段的更改都会导致对位图的修改，所以位图索引不适用于并发的情况。 实验3：Oracle优化器对索引的选择 关于索引索引类型 B树索引（默认的索引） &gt; CREATE INDEX IX_MOVIE_SCORE ON T_MOVIE(SCORE_);&gt; 位图索引：以位图的形式存储每个值对应的的一组rowid &gt; CREATE BITMAP INDEX IXBM_REGION_NAME ON T_REGION(NAME_);&gt; 基于函数的索引：利于对某个字段查询时需要同时使用函数或计算的情景 &gt; CREATE INDEX upper_ix ON employees (UPPER(last_name)); &gt; 分区索引：本地分区索引的分区完全依赖于其索引所在表，而全局分区索引的分区机制和表分区可能一样也可能不一样 range范围分区 &gt; CREATE INDEX cost_ix ON sales (amount_sold)&gt; GLOBAL PARTITION BY RANGE (amount_sold)&gt; (PARTITION p1 VALUES LESS THAN (1000),&gt; PARTITION p2 VALUES LESS THAN (2500),&gt; PARTITION p3 VALUES LESS THAN (MAXVALUE));&gt; hash哈希分区 &gt; CREATE INDEX cust_last_name_ix ON customers (cust_last_name)&gt; GLOBAL PARTITION BY HASH (cust_last_name)&gt; PARTITIONS 4;&gt; list列表分区：一个分区对应指定列的特定的值，以列举的方式进行分区 组合分区（range-hash，range-list） 什么时候用索引对于Oracle的CBO来说，只有在使用索引能提高效率（估算的效率）时才会使用索引。对于程序员自己进行数据库管理的时候，一般有： 需要使用索引来优化查询的情况： 一个属性的值分布非常广，变化的范围跨度很大。 一般来说，常常需要被用在SQL语句的where中的限制条件的属性最好为其建立索引。 表经常被访问且需要访问的数据量仅占一部分。 不适合用索引的情况： 表很小 表经常被更新 属性不经常作为where中的限制条件的属性存在 查询得到的数据占总量的很大部分 对于数据经常更新的情况，DBA要定时进行索引的重构（rebuild）以维持索引的可用性。 影响优化器决策的因素 进行全表扫描需要读取的数据块数量； 进行索引查询需要读取的数据块数量，这主要是基于对WHERE子句谓词返回的记录数目估计； 进行全表扫描时多块读的相关开销，以及为满足索引查询进行的单块读的开销； 内存中对缓存中的索引块和数据块数目的假设。 索引失效的可能原因以下是一些常见的定义了索引当Oracle并未使用的原因： 不等于情况，即“&lt;&gt;” 字符串匹配like中百分号在第一位的情况，即“%XXX” 表没有进行分析更新统计信息 使用复合索引但单独引用且非复合索引的第一属性 对索引进行计算，此时需要建立索引函数 属性为字符串但在where中没有加引号 使用not in，not exists 使用了其他索引 强制使用索引如果想要强制使用索引，则可以在查询语句的select单词后加上/*+index (tablename indexname)*/，这样可以规定Oracle选择使用indexname的索引的执行计划。该方法已在前面实验中使用，不再赘述。 sql语句SELECT T_MOVIE.NAME_, T_MOVIE.YEAR_FROM T_MOVIE,T_MOVIE_REGION,T_REGIONWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_IDAND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_IDAND T_REGION.NAME_='美国'AND T_MOVIE.SCORE_&gt;6; 查询消耗不用索引（不论是B树索引还是位图索引都不使用） 强制使用B树索引 强制使用位图索引 sql语句SELECT T_MOVIE.NAME_, T_MOVIE.YEAR_FROM T_MOVIE,T_MOVIE_REGION,T_REGIONWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_IDAND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_IDAND T_REGION.NAME_='美国'AND T_MOVIE.SCORE_&gt;9; 查询消耗B树索引（未使用） 位图索引 分析由此可见，即使在有索引的情况下，oracle优化器也可能选择不使用索引。CBO优化器会对每种执行计划计算一个COST，并采用COST最小的执行计划。如果一个表有索引或多种索引，其会选择最好的一种索引方式扫描表，或者甚至不用索引而用全局扫描方式。 另外对于符合筛选条件的数据，当占全表的比例越小、数据量越小时，使用索引的可能性越大。如在这次实验中，条件为”T_MOVIE.SCORE_ &gt;9”时会使用索引，而”T_MOVIE.SCORE_ &gt;6”时不会。 此外，由于位图索引导致的COST要小于B树索引，因此在相同的查询中，使用位图索引的可能性比B树索引更大。 实验4：Oracle分区索引sql语句SELECT T_COMMENT.SUMMARY_,T_COMMENT.SCORE_,T_COMMENT.TIME_FROM T_COMMENT,T_MOVIEWHERE T_MOVIE.ID_=T_COMMENT.MOVIE_IDAND T_COMMENT.SCORE_&gt;6AND T_MOVIE.NAME_='Blindsided'; 实验结果 未分区表+无索引 未分区表+B树索引 未分区表+位图索引 分区表+无索引 分区表+全局不分区B树索引 分区表+本地(哈希分区)B树索引 分区表+本地(哈希分区)位图索引 分区表+全局哈希分区索引 分区表+全局范围分区索引 分析 在未建索引时，分区表的COST是未分区表的十倍多。原因是分区所依据的键（字段）不是直接的查询条件——我们以评论表的movie_id字段为依据建哈希分区表，但在查询的时候并不直接以movie_id为查询条件。导致连接表的时候，需要访问多个分区，反而造成COST大大增长。 后来我们重新设计一个以movie_id为查询条件的sql语句，结果显示分区表的COST大约是未分区表的1/4（一共分了4个区），证明在以分区依据的字段为直接查询条件时，分区表能够体现比较好的性能，能够避免对一部分数据的访问。 在分区表上建索引比在未分区表上建索引后的开销更小，不论分区表上的索引是全局还是本地，不论是否是分区索引。在我们的实验场景中，尽管movie_id不是直接的查询条件而是join表的条件，但是在添加索引后，依然能够大大减少join表的开销从而提升效率。 在我们的实验场景中，全局的分区索引，不论是哈希分区还是范围分区，COST是一样的。 本地索引的效率略微比全局索引的效率好。根据查到的资料，本地索引的可维护性好，能够自动维护，不需要人工干预，但因把索引分成多个分区导致每次的索引访问都需要遍历所有索引分区，所以索引访问性能下降。因此比较适合OLAP系统。而全局索引的可维护性差，分区表发生改变时，需要用命令手动更新索引，但索引访问性能比本地分区索引要好。因此比较适合OLTP系统。 实验5：Oracle使用复合索引SQL语句select T_COMMENT_1.SUMMARY_, T_COMMENT_1.SCORE_from T_COMMENT_1, T_MOVIEwhere T_MOVIE.ID_ = T_COMMENT_1.MOVIE_ID and T_COMMENT_1.SCORE_ &gt; 7 and T_MOVIE.NAME_ = 'The Notebook'; 第一次查询：T_COMMENT_1上只有主键的唯一索引。 第二次查询：在MOVIE_ID上建立一个B-tree索引COMMENT_1_MOVIE。 create index COMMENT_1_MOVIE on T_COMMENT_1(MOVIE_ID); 第三次查询：使第二次的索引invisible，在SCORE_上建立一个B-tree索引T_COMMENT_SCORE_INDEX。 alter index COMMENT_1_MOVIE invisible;create index T_COMMENT_SCORE_INDEX on T_COMMENT_1(SCORE_); 第四次查询：将第二次和第三次的索引都保持为visible，在MOVIE_ID和SCORE_上建立一个复合索引COMMENT_1_MOVIE_SCORE。 alter index COMMENT_1_MOVIE visible;create index COMMENT_1_MOVIE_SCORE on T_COMMENT_1(MOVIE_ID, SCORE_); 实验结果第一次查询： 全表扫描，花销很大 第二次查询： 利用在MOVIE_ID上的索引，在T_COMMENT_1中访问的数据量和花销都大幅度下降。 第三次查询： 如果只有在SCORE_上的索引，根据CBO，Oracle并没有使用这个索引，而是依旧使用全表扫描，可知该索引并没有提升性能。 易知，如果在这个时候将MOVIE_ID上的索引设为visible，Oracle会使用MOVIE_ID上的索引。 第四次查询： Oracle使用了复合索引，尽管在当前问题下COST花销与只有MOVIE_ID的索引差不多，但是其访问的记录数（CARDINALITY）显著减小，体现了复合索引给查询带来的性能提升。 实验6：物化视图对SQL查询性能的提升SQL语句原始查询语句： select T_DIRECTOR.NAME_, T_MOVIE.NAME_ MOVIE_NAME, AVG(T_COMMENT_1.SCORE_) SCOREfrom T_DIRECTOR, T_DIRECT, T_MOVIE, T_COMMENT_1where T_DIRECTOR.ID_ = T_DIRECT.DIRECTOR_ID and T_DIRECT.MOVIE_ID = T_MOVIE.ID_ and T_COMMENT_1.MOVIE_ID = T_MOVIE.ID_ and T_DIRECTOR.NAME_ like '黑泽明%'group by T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_, T_MOVIE.ID_, T_MOVIE.YEAR_ ; 创建一个普通视图： CREATE VIEW DIRECTOR_MOVIE_FAKEASselect T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_ MOVIE_NAME, T_MOVIE.ID_ MOVIE_ID, T_MOVIE.YEAR_, AVG(T_COMMENT_1.SCORE_) SCOREfrom T_DIRECTOR, T_DIRECT, T_MOVIE, T_COMMENT_1where T_DIRECTOR.ID_ = T_DIRECT.DIRECTOR_ID and T_DIRECT.MOVIE_ID = T_MOVIE.ID_ and T_COMMENT_1.MOVIE_ID = T_MOVIE.ID_group by T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_, T_MOVIE.ID_, T_MOVIE.YEAR_; 使用普通视图进行查询： select NAME_, MOVIE_NAME, SCORE from DIRECTOR_MOVIE_FAKE where NAME_ like '黑泽明%'; 创建物化视图： CREATE MATERIALIZED VIEW DIRECTOR_MOVIEBUILD IMMEDIATEREFRESH FORCEON DEMANDENABLE QUERY REWRITEASselect T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_ MOVIE_NAME, T_MOVIE.ID_ MOVIE_ID, T_MOVIE.YEAR_, AVG(T_COMMENT_1.SCORE_) SCOREfrom T_DIRECTOR, T_DIRECT, T_MOVIE, T_COMMENT_1where T_DIRECTOR.ID_ = T_DIRECT.DIRECTOR_ID and T_DIRECT.MOVIE_ID = T_MOVIE.ID_ and T_COMMENT_1.MOVIE_ID = T_MOVIE.ID_group by T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_, T_MOVIE.ID_, T_MOVIE.YEAR_; 设置创建时生成数据，按需要刷新，刷新方式为FORCE。 根据视图进行如上查询： select NAME_, MOVIE_NAME, SCORE from DIRECTOR_MOVIE where NAME_ like '黑泽明%'; 由于物化视图与表类似，可以给其建立索引，以下给导演名建立索引： CREATE BITMAP INDEX DIRECTOR_MOVIE_INAME_INDEX ON DIRECTOR_MOVIE (NAME_); 再次使用物化视图查询： select NAME_, MOVIE_NAME, SCORE from DIRECTOR_MOVIE where NAME_ like '黑泽明%'; 实验结果使用原始查询： 具有极大的花销。 创建视图后的查询： 其执行计划与原始查询一致。 创建物化视图后的查询： 其直接在物化视图中进行查询，执行计划即为简单，花销大幅度减小。 给物化视图创建索引后的查询： 建立索引后通过范围索引扫描该物化视图进行查询，其COST数字小得令人惊奇。 分析1.建立普通视图并不能提升性能。因为普通是虚拟的，对视图的操作实际都转变为了对各表的SQL操作，其与原始查询完全一致。 2.物化视图是一种物理表，对于物化视图的查询是直接的，跟表一样。因此建立物化视图可以大幅度减小花销，但是同时，物化视图也会产生大量的维护成本。因此程序员应该根据实际情况建立物化视图以优化查询。 3.物化视图同样可以增添索引，增加索引后Oracle对物化视图可以通过索引进行扫描，进一步提高效率。 物化视图与普通视图视图只是一种虚拟表。实际上，对视图的查询真正转换成了相应的SQL语句再对各表进行连接查询，因此其性能提升有限，只是方便了使用。 而物化视图是实质化的视图，是物理表，可以像表一样进行查询，建立索引，占用真正的存储空间，需要被刷新。 刷新模式on demand：顾名思义，仅在该物化视图“需要”被刷新了，才进行刷新(REFRESH)，即更新物化视图，以保证和基表数据的一致性; on commit：提交触发，一旦基表有了commit，即事务提交，则立刻刷新，立刻更新物化视图，使得数据和基表一致。一般用这种方法在操作基表时速度会比较慢。 创建物化视图时未作指定，则Oracle按 on demand 模式来创建。 刷新方法完全刷新（COMPLETE）： 会删除表中所有的记录（如果是单表刷新，可能会采用TRUNCATE的方式），然后根据物化视图中查询语句的定义重新生成物化视图。 快速刷新（FAST）： 采用增量刷新的机制，只将自上次刷新以后对基表进行的所有操作刷新到物化视图中去。FAST必须创建基于主表的视图日志。对于增量刷新选项，如果在子查询中存在分析函数，则物化视图不起作用。 FORCE方式： 这是默认的数据刷新方式。Oracle会自动判断是否满足快速刷新的条件，如果满足则进行快速刷新，否则进行完全刷新。 实验7：Oracle In Memory性能分析Sql语句SELECT T_MOVIE.NAME_, SUM(T_COMMENT_2.SCORE_) s FROM T_MOVIE,T_COMMENT_2 WHERE T_MOVIE.ID_=T_COMMENT_2.MOVIE_ID GROUP BY T_MOVIE.NAME_ ORDER BY s DESC; 设置In MemoryALTER TABLE T_MOVIE.NAME_ IN MEMORY; 实验结果原始查询： In Memory查询： 结果分析遗憾的是与想象的不同，Oracle和Oracle In Memory在COST上面结果相同，但是事实上在我们同样的实验环境下测试二者时间时，In Memory确实会比Oracle好很多。其实简单思考一下，这是应该的，前面我们说过执行时间t = Block数量 * Block处理时间，不难知道差距还是出在Block处理时间上。 实验8：Oracle执行计划浅析(Oracle表的访问方式)对T_MOVIE表进行查询，其本身有在其主码(ID_)上的UNIQUE INDEX和LENGTH_上的B-tree INDEX。 根据UNIQUE INDEX（ID_）返回唯一记录select * from T_MOVIE where ID_ = 20050; 使用的是索引唯一扫描 根据ID_返回少部分记录select * from T_MOVIE where ID_ &lt; 10; 使用的是索引范围扫描 根据LENGTH_返回大量数据select * from T_MOVIE where LENGTH_ &lt;100; 全查询MOVIE_和TYPE_返回其ID_全查询MOVIE_： select ID_ from T_MOVIE; 采用的是索引快速扫描（因为数据量较多） 且返回结果无顺序（从578开始，一段有序，即代表是一个索引数据块）。 全查询TYPE_: select ID_ from T_TYPE; 采用的是索引全扫描（因为数据量较小） 返回结果有顺序 执行计划中的访问方式访问方式即分为全表扫描（TABLE ACCESS FULL）和各种类型索引扫描（TABLE INDEX SCAN）。Oracle会根据表和索引的信息，推算执行的SQL语句从表中取多少数据以及这些数据是怎么分布的。 TABLE ACCESS FULL（全表扫描）Oracle会读取表中所有的行，并检查每一行是否满足SQL语句中的 where限制条件。全表扫描时可以使用多块读（即一次I/O读取多块数据块）操作来提升吞吐量。数据量太大的表不建议使用全表扫描，除非本身需要取出的数据较多，占到表数据总量的 5% ~ 10% 或以上。 TABLE ACCESS ROWID（通过ROWID的表存取）ROWID是由Oracle自动加在表中每行最后的一列伪列，表中并不会物理存储ROWID的值。程序员可以像使用其它列一样使用它，但不能对该列的值进行增、删、改操作。一旦一行数据插入后，则其对应的ROWID在该行的生命周期内是唯一的，即使发生行迁移，该行的ROWID值也不变。 ROWID可以被视为每条记录的“指针”。它指出了该行所在的数据文件、数据块以及行在该块中的位置，所以通过ROWID可以快速定位到目标数据上，这也是Oracle中存取单行数据最快的方法。 TABLE ACCESS BY INDEX SCAN（索引扫描）在索引块中，既存储每个索引的键值，也存储具有该键值的行的ROWID。因此索引扫描其实分为两步：扫描索引得到对应的ROWID；通过ROWID定位到具体的行读取数据。 索引扫描主要分为以下几种： INDEX UNIQUE SCAN 索引唯一扫描对应UNIQUE INDEX（唯一性索引）的扫描方式，其只会应用在返回一条记录的情况下。该点在之前的实验中已经描述。 INDEX RANGE SCAN 索引范围扫描主要是使用在需要返回多行记录的情况下，常见为以下三种： 在唯一索引列上使用了范围操作符（如：&gt; &lt; &lt;&gt; &gt;= &lt;= between） 在组合索引上，只使用部分列进行查询（查询时必须包含前导列，否则会走全表扫描） 对非唯一索引列上进行的任何查询 如果在查询的过程中需要访问的记录数很多，分布很广，这个时候Oracle会根据CBO原则认为使用索引的花销可能比全表扫描大，会使用全表扫描。 INDEX FULL SCAN 索引全扫描进行全索引扫描时，查询出的数据都必须从索引中可以直接得到。其常发生在要查询的列包含唯一索引且需要对表中的所有数据都要查询。索引全扫描返回的结果有顺序。 INDEX FAST FULL SCAN 索引快速全扫描索引快速全扫描与索引全扫描类似，只是其在查找索引时会用一种更为快速的方式（简单来说是根据索引块的物理顺序而省去较为繁琐的逻辑顺序），其更适合于数据量大的表进行全查询，其一个特点就是返回的记录不按照顺序。 四、TimesTen实验过程实验概述调用自己改写的 AliTT11.sql，查看 SQLPrepare，SQLExecute，FetchLoop 的查询时间； 所有实验中，查询时间分为增加索引前、增加索引后、按照 timesten 建议添加索引三类，针对每一类时间分别有第一次执行时间和之后的平均查询时间两种； 在首次执行查询语句时，timesten首先需要对语句进行预编译，因此首次执行的 SQLPrepare 时间相比之后的时间较长，之后的准备时间就相应缩短了很多。 实验1实验内容某地区评分6以上的所有电影的名字和上映时间 查询语句SELECT DBIM.T_MOVIE.NAME_, DBIM.T_MOVIE.YEAR_FROM DBIM.T_MOVIE, DBIM.T_MOVIE_REGION, DBIM.T_REGIONWHERE DBIM.T_REGION.ID_ = DBIM.T_MOVIE_REGION.REGION_IDAND DBIM.T_MOVIE.ID_ = DBIM.T_MOVIE_REGION.MOVIE_IDAND DBIM.T_REGION.NAME_ = '美国'AND DBIM.T_MOVIE.SCORE_ &gt; 6; 添加的索引 表明 列名 索引类型 是否唯一 Movie id_ hash unique Movie score_ range Region id_ hash unique Movie_region region_id hash Movie_region movie_id hash 查询时间 时间类型 Before1 Before2 After1 After2 建议1 建议2 提高百分比 SQLPrepare 0.001845 0.000059 0.000878 0.000054 0.000807 0.000055 SQLExecute 0.075809 0.061819 0.000037 0.000025 0.000034 0.000025 99.96% FetchLoop 0.000004 0.000002 0.000002 0.000001 0.000003 0.000002 执行计划 (before) 执行计划 (after) 原因分析添加索引后速度大大提升，因为在 region 表中指定了查询条件，添加索引后可以快速从表项中匹配到指定条件的项；在添加之前，timesten 自动帮我们在 movie 表上的 id 字段上添加了临时哈希索引，除此之外，我们额外为几个 where 条件语句的查询字段都增加了索引， 因此提高了效率。 执行计划 before 在两层嵌套循环中，顺序执行在region表中的查询、region表与联系表的join，循环结束后生成一个指定地区内的所有电影联系表；内层嵌套完成后，通过散列索引匹配movie表与内存循环生成的联系表，join筛选后生成结果列表 after 添加索引之后，过程与添加之前相同，但由于内层循环内使用散列索引而不是顺序执行，因此查询速度比较快，加上没有临时创建索引的时间开销，所以相比之下大大提高了查询效率。 实验2实验内容所有地区全部电影的平均评分排行榜（前100） 查询语句SELECT * FROM (SELECT DBIM.T_REGION.NAME_, SUM(DBIM.T_MOVIE.SCORE_) sFROM DBIM.T_REGION, DBIM.T_MOVIE_REGION, DBIM.T_MOVIEWHERE DBIM.T_MOVIE.ID_ = DBIM.T_MOVIE_REGION.MOVIE_IDAND DBIM.T_REGION.ID_ = DBIM.T_MOVIE_REGION.REGION_IDGROUP BY DBIM.T_REGION.NAME_ORDER BY s DESC) WHERE ROWNUM &lt; 101; 添加的索引 表明 列名 索引类型 是否唯一 Movie id_ hash unique Movie score_ range Region name_ hash unique Region id_ hash unique Movie_region region_id hash Movie_region movie_id hash 查询时间 时间类型 Before(1) Before(2) After(1) After(2) 建议(1) 建议(2) 提高百分比 SQLPrepare 0.001253 0.000081 0.001004 0.000054 0.000985 0.000056 SQLExecute 0.353111 0.335902 0.337983 0.313458 0.313004 0.312695 7% FetchLoop 0.000045 0.000020 0.000018 0.000018 0.000018 0.000017 执行计划 (before) 执行计划 (after) 原因分析添加索引之前，timesten 自动在 movie 和 region 表的 id 字段上都设置了相应的哈希索引，而我们添加索引后与添加之前的执行计划中的索引项没有差别，因此效率几乎没有变化，加上 sum 聚合操作、group by、order by 操作都要进行费时间的全表扫描，所以需要较长时间完成查询。 实验1和2分析总结指定条件的查询： 建立索引之前 timesten在某个相对较小的表上建立临时索引（散列索引或范围索引），在其他表上进行顺序扫描，执行查询语句中的条件匹配，建立索引的过程会造成时间上的消耗； 建立索引之后 自己建立的索引覆盖timesten优化建立的索引，由于索引提前建立，因此没有建立索引带来的额外时间开销，而且在此类查询中我们在所有查询涉及字段上都建立了索引（tt自身优化通常只在一个表上建立索引），所以与建立索引之前相比有极大的性能提升。 聚合查询： 执行计划Before： 先顺序扫描关系表act的记录字段id，利用临时HASH索引 actor.id_，将act表中对应记录与act的记录通过字段相连；对(这些/该)拼接记录逐条利用临时HASH索引 movie.id ,接上movie表中符合条件的记录字段。 执行计划After： 先顺序扫描关系表movie的记录字段id ，利用HASH索引 act.id_，将act表中对应记录与act的记录通过字段相连；针对第一次hash检索出的 act.id，再对(这些/该)拼接记录逐条利用临时HASH索引 actor.id ,接上actor表中符合条件的记录字段。 主要原因在于：第一次顺序扫描的关系表act，外码引用actor表的主码(1:1)，movie表(1:1)，hash索引查询唯一记录快；第二次顺序扫描的表为movie表，将对应多条act表里的记录（1:many），对应多个演员(1:many)。 实验3：AWT创建 AWT 直写缓存组 缓存表 t_moive t_comment_1 选择理由 动态缓存组适用于不从 oracle 中预加载数据的场景 Movie 表和评论表体量较大，不需要从 oracle 中提前加载 测试 AWT 修改数据 修改电影评论表 修改语句 UPDATE DBIM.T_COMMENT_1SET SUMMARY_=&apos;A&apos;WHERE DBIM.T_COMMENT_1.SCORE_&gt;8AND DBIM.T_COMMENT_1.MOVIE_ID = 1; 踩坑 update语句指定修改的表名后，set字段不需要再次声明表名（否则报错） 修改数据前要开启 replication agent 执行update语句后要提交事务 实验4：查看不同数据类型对查询效率的影响表字节大小 表名 行数 字节大小 有数据类型映射的字节大小 节约百分比 Movie 292352 47301232（nomapping） 26293000（optimal） 45% Comment 9805336 2528884600（nomapping） 404967952（optimal） 84% 压缩设置 数据类型映射结果 表 字段 noMapping standardMapping aggressive Region id_ NUMBER(11,0) TT_BIGINT TT_SMALINT Region name_ VARCHAR(255 BYTE) VARCHAR(255 BYTE) VARCHAR(80 BYTE) 结果分析 对相同的表来说，从 oracle 导入 timesten 中如果不进行压缩（nomapping），与进行最优化数据类型映射+aggressive mapping + optimal compression 相比，大约浪费了45%的空间； 对于不同数量级的表来说，千万数量级的 comment 表不进行压缩时浪费84%所有的空间，比十万数量级的 movie 表浪费的空间多了接近一倍。 实验5：根据优化建议建立索引SQL语句Command&gt; call ttIndexAdviceCaptureOutput(0);&lt; 6, create index T_MOVIE_i1 on DBIM.T_MOVIE(ID_); &gt;&lt; 7, create index T_COMMENT_1_i2 on DBIM.T_COMMENT_1(MOVIE_ID,SCORE_); &gt;2 rows found. 实验对象 实验3.2语句 实验结果 Before：自己建立索引后的查询时间 After：根据 timesten 查询优化建议建立索引后的查询时间 时间类型 Before(1) Before(2) After(1) After(2) 提高百分比 SQLPrepare 0.001527 0.000049 0.000822 0.000049 SQLExecute 4.139655 3.556375 3.301318 3.302092 7.18% FetchLoop 0.000047 0.000027 0.000018 0.000017","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://blog.guitoubing.top/tags/Oracle/"},{"name":"Timesten","slug":"Timesten","permalink":"http://blog.guitoubing.top/tags/Timesten/"}]},{"title":"数据仓库期末项目文档","slug":"数据仓库期末项目文档","date":"2018-12-31T09:32:45.000Z","updated":"2019-03-11T04:56:31.454Z","comments":true,"path":"2018/12/31/数据仓库期末项目文档/","link":"","permalink":"http://blog.guitoubing.top/2018/12/31/数据仓库期末项目文档/","excerpt":"简介本项目我们基于Stanford University中的Amazon Movie Comment数据，利用爬虫技术爬取了数十万的电影信息数据以及数百万计的电影评论数据，并通过搭建Neo4j图数据库、MySQL关系型数据库、Influx时序数据库及Hive分布式数据库对数据进行存储、分析及实现功能，同时对于部分功能需求针对这4种数据库进行效率对比分析。","text":"简介本项目我们基于Stanford University中的Amazon Movie Comment数据，利用爬虫技术爬取了数十万的电影信息数据以及数百万计的电影评论数据，并通过搭建Neo4j图数据库、MySQL关系型数据库、Influx时序数据库及Hive分布式数据库对数据进行存储、分析及实现功能，同时对于部分功能需求针对这4种数据库进行效率对比分析。 系统架构Neo4j 操作系统：macOS Mojave 10.14.1 硬件：Core i5 &amp; 16GB RAM 软件：Neo4j Desktop Version 1.1.10 (1.1.10.436) 选择理由： 高性能：Neo4j以图的遍历算法来帮助查询数据，查询时从一个节点开始，根据其连接的关系，快速和方便地找出它的邻近节点。这种查找数据的方法并不受数据量的大小所影响，因为邻近查询始终查找的是有限的局部数据，不会对整个数据库进行搜索。所以，Neo4j具有非常高效的查询性能，相比于RDBMS可以提高数倍乃至数十倍的查询速度。而且查询速度不会因数据量的增长而下降。 灵活性：图数据结构的自然伸展特性及其非结构化的数据格式让Neo4j的数据库设计可以具有很大的伸缩性和灵活性，使其可以随着需求的变化而增加的节点、关系及其属性并不会影响到原来数据的正常使用，因此在项目后期的推进中，我们也可以不断的快速修改neo4j数据库中的内容来满足我们的查询需求。 直观性：图数据库使用图的形式作为数据库最主要的展现形式，可以更清楚的帮助我们理解整个数据库中数据之间的联系，Cypher语言的灵活性也帮助我们更轻松的操控数据库 存储模型简介： 本项目中主要建立了Neo4j的两个不同的库，一个库是围绕电影的相关信息，我们在其中存储了和电影有关的所有信息，包括导演，制片人，演员，类别，语言，字幕，编剧等等，节点与节点之间通过不同的关系相连接。第二个库针对合作关系，分别存储了导演，演员，以及类别，通过节点与节点之间的关系，记录他们彼此的合作次数，类别的引入也帮助我们分析导演的执导风格。 存储模型：图 性能对比分析： 数据存储：Neo4j对于图的存储自然是经过特别优化的。不像传统数据库的一条记录一条数据的存储方式，Neo4j的存储方式是：节点的类别，属性，边的类别，属性等都是分开存储的，这将大大有助于提高图形数据库的性能。在Neo4j 中属性，关系等文件是以数组作为核心存储结构；同时对节点，属性，关系等类型的每个数据项都会分配一个唯一的ID，在存储时以该ID 为数组的下标。这样，在访问时通过其ID作为下标，实现快速定位。 数据读写：在Neo4j中，存储节点时，每个节点都有指向其邻居节点的指针，可以让我们在O(1)的时间内找到邻居节点。另外，按照官方的说法，在Neo4j中边是最重要的,是”first-class entities”，所以单独存储，这有利于在图遍历的时候提高速度，也可以很方便地以任何方向进行遍历。邻近查询帮助Neo4j始终查找的是有限的局部数据，不会对整个数据库进行搜索。所以，Neo4j具有非常高效的查询性能，相比于RDBMS可以提高数倍乃至数十倍的查询速度。而且查询速度不会因数据量的增长而下降。 MySQL 操作系统：macOS Mojave 10.14.1 Beta 硬件：Intel(R) Core(TM) i5-3470 CPU @ 3.20GHz/ 4 GB 1600 MHz DDR3 软件：Docker 1.13.1/ MySQL 5.7 选择理由： MySQL是时下使用率最高的几款关系型数据库之一，且其体积相较其他关系型数据库更小巧且性能不输大型关系型数据库。关系型数据库是我们最常接触也是在对数据进行存储时会最先想到的数据库类型。我们想要借助关系型数据库以及行式存储对我们的数据进行存储，并通过对应的数据库操作对存储对数据进行分析/查询，实现我们对应的目的。 存储模型简介： 在本项目中我们选择雪花模型作为我们关系型数据库的存储模型。雪花存储模型使用规范化的数据，数据在数据库内部是组织好的，消除冗余以减少数据量。相比之下，星型模型使用的是反规范化的数据，会在存储时存储大量的冗余数据。规范化存储数据同时也带来查询时间上的消耗，其查询更新速度会慢于星型存储模型。但是考虑到我们项目到数据单表最大12万左右，对于这个数量级到数据星型模型的查询速度相比雪花模型没有非常明显的差距，而雪花模型能够帮助我们减少了很多不必要的冗余数据的存储，所以我们选用了雪花模型。我们的数据库设计了实体表与关系表，各个实体表有自己的唯一的主键，实体表之间的联系使用关系表进行关联，减少了很多实体数据的存储，符合第三范式。 性能分析： 在一开始，我们并没有对每个表建立相应的索引，在这种情况下我们单表的query速度在一个可接受的范围内，但是一旦涉及多表联合查询，如查询每个导演执导的电影数量时，需要关联三张表，在这种情况下查询速度非常的慢，因为其中涉及来表的结合与数据的聚合查询。针对联合查询过慢的速度下，我们为每张实体表以及关系表建立主码索引，并且在常用的搜索字段，如电影的上映日期上建立对应的索引，并且在这种大量数据的情况需要先对表建立索引再将数据导入，因为导入数据之后再建立索引会消耗大量的时间。索引建立之后再进行同样的多表联合查询操作，可以发现速度得到了明显的提升，在当前十万级别的数据量下查询耗时基本在五十毫秒之内。所以在MySQL中建立适当的索引能够在很大程度上提升查询的速度，同时也会牺牲一定的查询/更新效率。 Influx 操作系统：windows10 硬件：Intel(R) Core(TM) i5-6300HQ CPU @2.30GHz &amp; 8GB RAM 软件：influx1.7.1 选择理由：首先，查询场景中有用到对世界特性比较敏感的数据，例如，根据时间查询等，所以使用influxDB。influxDB继承了LSM Tree的顺序写入的特点，所以写入性能很好（先把大量的数据顺序写，然后持久化到磁盘。）时序数据库每次读取数据都是读取固定series的指定时间范围的连续数据，因为是顺序写入，所以这种读取比较快速。 存储模型简介：influxdb中我们主要存 电影id，电影类别，电影语言，电影观看人数，电影上映时间。其中，将电影类别与电影语言当做tag存储，电影id以及电影观看人数当做field存储，其中上映时间就是时间戳存储。 存储模型： 性能对比分析： InfluxDB用于存储大量的时间序列数据，并对这些数据进行快速的实时分析。SQL数据库也可以提供时序的功能，但时序并不是其目的。在InfluxDB中，timestamp标识了在任何给定数据series中的单个点。就像关系型数据库中的主键。InfluxDB考虑到schema可能随时间而改变，因此赋予了其便利的动态能力。但是由于在项目中，时间相关的数据较为固定，因此其性能的体现并不是特别好。 Hive 操作系统：macOS Mojave 10.14.1 硬件：Core i7 &amp; 16GB RAM 软件：Hive 3.1.1 &amp; Hadoop 3.1.1 &amp; MySQL 5.7 选择理由： Hive首先有很多以上数据库所不具有的优点，如扩展性和容错性，本项目我们选择hive来处理一部分数据主要是作为MySQL数据库的对照。针对我们项目的百万级的数据量来对比分析关系型数据库和分布式数据库在数据量较大时的性能优劣性，以此窥见数据仓库对比于数据库的所展现出来的优点。同时对于项目中的部分功能需求组合采用hive与其他数据库分治的方式，来实现复杂的功能需求，以此来学习工程中数据仓库与普通数据库结合的实现方法。而由于数据量及需求的限制，我们只可窥见数据仓库其作用的冰山一角，希望藉此加深我们对数据仓库的理解。 存储模型简介： 在hive中我们存储的数据与MySQL中一样。因此建立了与MySQL完全相同的存储结构。另外针对hive本身自带的不同的存储模型，我们还创建了textfile和ORCfile两种表存储结构。 分布式架构： 性能对比分析： \b\b从我们对于MySQL和Hive这两种比较有可比性的数据库之间的对比来说，MySQL的执行时间基本上是远远快于Hive的执行时间的。首先，考虑我们在这两种数据库中执行的操作，如果对于一开始数据从文件进入数据库中这一过程忽略的话，我们整个项目执行的都是OLAP即联机分析处理操作。Hive作为一个经典的数据仓库工具，本身应该是擅长执行OLAP操作的，因此暂且认为”操作”不是造成二者执行时间差异的原因；其次，Hive官网有句话\b”Hive在大型数据集上会表现出优越的性能”，考虑到我们的项目数据集\b中，最多的数据集是700多万条的用户评论数据，而基本功能的实现都是操作在数据量仅有10万余条的电影数据，我们猜测是数据量限制了Hive体现其\b优越性。因此我们作了如下实验：在等量的数据量变化上，我们比较二者变化前后的执行的时间，得到下表：就时间来说，很显然MySQL更胜一筹，但从增长比例来说，MySQL从9ms增长至271ms增长约为30倍，而\bHive增长约为5倍，由此我们可窥见Hive在大量数据集时性能会更加优越。然而在这过程中，\b我们所使用的Hive所采用的为textfile存储结构，意即内容即文件，表数据完全按照表结构存储成为文本文件，我们创建了t_comment表存储用户评论信息，表数据文件如下：\b从Hive官方文档我们得知Hive有其他更加优越的存储格式，它包含SequenceFile、RCFile、ORCFile，我们采取了所谓最优的ORCFile来Duplicate了用户评论表，想以此对比ORCFile之于TextFile的优点，我们创建了\bt_comment_orc表，并从t_comment中把数据原封不动的导入进来，可见表数据文件如下：不难看到\bORC表文件(260MB)明显比TextFile表文件(705MB)小多了，至于性能，同样对于上述实验，我们添加了ORC表的结果：结果显而易见，当数据达到\b数百万量级时，Hive较优的使用方法下已经要比MySQL要稍显胜势了。通过以上两点以及常识我们不难看出： 限制Hive的效率的因素： 数据量 \b计算框架 Hive在我们项目中使用的是MapReduce框架来执行分布式计算，然而比\b现在已经有很多比MapReduce快得多的计算框架例如Spark等，因此若使用这些框架必定会使 网络通信 由于我们的集群搭建在Docker容器中，其间数据通过程序写定的程序通道传输而非真实的网络通信，因此暂且看不出网络对执行的影响，而真实场景中，这必是一项重要的考虑因素 百万级数据的OLAP场景或者OLTP操作需求较多的场景下，MySQL(关系型数据库)是优选 千万乃至亿万级数据的批处理、分析场景，Hive(数据仓库/分布式数据库)在存储、读取、分析效率上都要更优 其三，上述操作均是在单表查询的前提下，但是在多表查询情况下Hive的效率如何呢？先看测试结果，我们仅在”导演-执导-电影”三表上做了多表查询，执行”某导演执导电影的数量”的操作，执行时间记录如下：此现象引出了数据仓库在实际应用中的一种常见处理方式：为了提高速度而产生数据冗余。Hive中的表是很特殊的，其没有主键、外键同时库中各个表之间的冗余会很明显，这使得\b管理人员方便针对各种功能设计所需的信息表，这也是数据仓库作为大量数据集的OLAP最佳选择的原因之一。 \b性能对比 走势变化： 由图可见，四种数据库中执行时间都是先较多然后减少最后趋于稳定，我们对其分析可能是jdbc在首次连接时需要较多时间进行网络通信，当一次连接建立后，我们并没有关闭该连接，在此基础上程序执行后续的事务才应当是其真实的操作时间。 功能对比： 不同的数据库，在不同的功能需求下各有优劣。举个例子，在查询实体间的关系时，对于完全符合3NF的关系型数据库来说，可能需要多表连接查询，这明显会消耗大量时间，而对于基于relation的数据库例如Neo4j来说，类似查询正是其强项。 总结 本项目使用了JavaWeb框架，并基于sementicUI进行前端开发。 在数据库选择上，我们使用了Mysql，hive，Neo4j以及influxDB四个不同的数据库进行横向纵向比对，通过实现一定的基本功能搜索以及多表联查，统计他们的性能，查询时间等数据并进行相应的分析，对于不同数据库的优劣势有了更为清晰的了解。 在项目过程中，我们将上课学到的知识应用到实践中，尝试了雪花，星型等不同的存储结构，并根据自己的项目实情选择了最适合我们的项目存储结构。针对不同的实验现象，我们也通过网络等资源来进行辅助学习，帮助我们更好的了解不同数据库以及其不同的存储，读取等方式。 项目过程中，特别感谢老师和助教们的帮助，让我们更为深入了解了数据仓库技术，为我们今后的项目实践打下了扎实的基础。","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"大三上笔记","slug":"大三上笔记","permalink":"http://blog.guitoubing.top/tags/大三上笔记/"},{"name":"数据仓库","slug":"数据仓库","permalink":"http://blog.guitoubing.top/tags/数据仓库/"}]},{"title":"云计算期末项目","slug":"云计算期末项目文档","date":"2018-12-31T09:31:32.000Z","updated":"2019-02-26T05:45:39.426Z","comments":true,"path":"2018/12/31/云计算期末项目文档/","link":"","permalink":"http://blog.guitoubing.top/2018/12/31/云计算期末项目文档/","excerpt":"","text":"云计算期末项目文档系统架构集群架构图 集群机器 主机名 内存 IP 软件 运行进程 node0 512MB 192.168.137.200 ZooKeeper QuorumPeerMain node1 512MB 192.168.137.201 ZooKeeper QuorumPeerMain node2 512MB 192.168.137.202 ZooKeeper QuorumPeerMain master 2GB 192.168.137.100 Hadoop,Hive,MySql JournalNode,NameNode,ResourceManager,DFSZKFailoverController,HiveServer2,MySql master1 2GB 192.168.137.10 Hadoop,Hive JournalNode,NameNode,ResourceManager,DFSZKFailoverController,HiveServer2 slave1 1GB 192.168.137.101 Hadoop JournalNode,DataNode,NodeManager slave2 1GB 192.168.137.102 Hadoop DataNode,NodeManager slave3 1GB 192.168.137.103 Hadoop DataNode,NodeManager host 8GB 192.168.137.1 应用服务器 集群搭建简介集群使用VirtualBox创建了8台虚拟机模拟真实环境中的分布式集群(因机器内存不够，特地为此买了内存条及SSD)，虚拟机全部使用CentOS7-x86_64系统，其中3台ZooKeeper集群，5台Hadoop集群（2台Master，3台Slave），Windows本机作为应用程序服务器用于连接此集群。 虚拟机创建此集群中机器的系统基本配置几乎是一样的，只是在后期所担任的角色不同，因此这里我创建了一台虚拟机，而后将环境配好后复制了7台，而后针对其所担任角色进行针对性修改。 首先创建了一台裸机，要解决的第一个问题是虚拟机与主机的网络通信，这里我采用VirtualBox中的Host-Only连接方式，以保证虚拟机与主机之间正常的网络通信，同时需要在主机上共享网络，以保证虚拟机同时还能访问互联网。 在主机网络设置中共享网络： 在VirtualBox中执行以下操作设置主机连接方式： 在虚拟机终端执行以下操作： # 修改虚拟机的IP、子网掩码vim /etc/sysconfig/network-scripts/ifcfg-enp0s3# 修改为以下内容TYPE=EthernetIPADDR=192.168.137.100NETMASK=255.255.255.0# 保存退出# 修改网关地址vim /etc/sysconfig/network# 修改为以下内容NETWORKING=yesGATEWAY=192.168.137.1# 保存退出# 修改主机名为master，后续过程中访问本机只需要主机名而不用敲IPhostnamectl set-hostname master# 关闭并停用防火墙，由于这里使用的是局域网，因此无需太多考虑网络安全systemctl stop firewalldsystemctl disable firewalld# 重启网络服务systemctl restart network# 尝试从虚拟机ping网关以及从主机ping虚拟机hostname或者ip，若都能ping通说明网络配置成功ping 192.168.137.1# 从虚拟机ping外网查看是否可以连接互联网，这里测试百度IP：61.135.169.105ping 61.135.169.105# 修改hosts文件，添加局域网中其他主机的主机名与ip的映射vim /etc/hosts# 修改为以下内容192.168.137.100 master192.168.137.10 master1192.168.137.101 slave1192.168.137.102 slave2192.168.137.103 slave3192.168.137.200 node0192.168.137.201 node1192.168.137.202 node20.0.0.0 localhost# 保存退出 至此，虚拟机网络配置已完成，下面安装Hadoop 2.9.2及Hive 2.3.4（下载、解压步骤省略），并执行一些准备工作： # 首先添加Hadoop和Hive相关环境变量vim /etc/profile# 添加下列内容export HADOOP_MAPRED_HOME=/usr/local/hadoopexport HADOOP_HOME=/usr/local/hadoopexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport HIVE_HOME=/usr/local/hiveexport PATH=$HIVE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH# 保存退出，并使环境变量生效source /etc/profile Hadoop和Hive的配置需放到各台虚拟机上分别执行，因为不同虚拟机所需要的配置不同。 虚拟机复制上述步骤已经创建好了一个虚拟机，下面需要复制出7个，并对每台机器针对性的进行一些修改。 网络配置对于每台虚拟机需要执行以下几个步骤以保证9台机器之间形成一个网络： 修改IP vim /etc/sysconfig/network-scripts/ifcfg-enp0s3 针对集群机器中定义的IP将IPADDR项修改为对应的IP 修改主机名 hostnamectl set-hostname XXX 针对集群机器中定义的主机名执行以上命令修改为特定的主机名 重启网络服务 systemctl restart network ping各个节点测试是否成功 ping masterping master1ping slave1ping slave2ping slave3ping node0ping node1ping node2ping 192.168.137.1ping 61.135.169.105 Hadoop配置修改core-site.xmlvim $HADOOP_HOME/etc/hadoop/core-site.xml 作用：Hadoop集群的核心配置文件 需要修改的机器：master、master1、slave1、slave2、slave3 内容： &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ns&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/var/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zookeeper地址 --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node0:2181,node1:2182,node2:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- 允许访问此hdfs的主机和群组，此处设置为任意 --&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hdfs-site.xmlvim $HADOOP_HOME/etc/hadoop/hdfs-site.xml 作用：hdfs集群配置文件 需要修改的机器：master、master1、slave1、slave2、slave3 内容： &lt;configuration&gt; &lt;!-- 指定dfs文件存储位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/var/hadoop-data&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定文件备份份数 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定机器运行情况检查时间间隔 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbead.recheck-interval&lt;/name&gt; &lt;value&gt;3000000ms&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hdfs的nameservice为ns，和core-site.xml保持一致 --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns&lt;/value&gt; &lt;/property&gt; &lt;!-- NS下面的NameNode --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn1&lt;/name&gt; &lt;value&gt;master:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn1&lt;/name&gt; &lt;value&gt;master:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn2&lt;/name&gt; &lt;value&gt;master1:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn2&lt;/name&gt; &lt;value&gt;master1:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://master:8485;master1:8485;slave1:8485/ns&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/journaldata&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启机器故障自动切换主从机器 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定failover切换的方法(java类的名称) --&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定failover切换的方法，这里使用ssh通信方式交换 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt; sshfence shell(/bin/true) &lt;/value&gt; &lt;/property&gt; &lt;!-- ssh切换方法需要指定私钥文件位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 注意 假设当备份份数为2时，现在有三台DataNode机器，文件被分为2个block，block1位于1和2上，block2位于1和3上，这是若机器3宕机了，hdfs会在设定的dfs.namenode.heartbead.recheck-interval时间间隔内检查出机器3(在此时间间隔内可能会出现文件数量紊乱的现象)，此时block2数量变为1，hdfs会自动将1中的block2复制一份到另外一台可用机器上（此处为2）。当机器3恢复运行时，3中备份的block2会自动删除。 当使用jdbc访问hdfs时，不会使用hdfs-site.xml中的dfs.replication，而会默认使用3，可在java的configuration中配置为指定值 修改slaves文件vim $HADOOP_HOME/etc/hadoop/slaves 作用：为各个master指定为其工作的slave 需要修改的机器：master、master1 内容 slave1slave2slave3 修改yarn-site.xmlvim $HADOOP_HOME/etc/hadoop/yarn-site.xml 作用：yarn集群的核心配置文件 需要修改的机器：master、master1、slave1、slave2、slave3 内容： &lt;configuration&gt; &lt;!-- 启用yarn集群的高可用机制 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定ResourceManager集群id，可为任意字串 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定两台ResourceManager的名称 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定两台ResourceManager的主机名 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;master1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定两台ResourceManager的web端口，正常情况为8088 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt; &lt;value&gt;master1:8088&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定管理集群的Zookeeper集群的地址及对应端口 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;node0:2181,node1:2181,node2:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定jar包路径 --&gt; &lt;property&gt; &lt;name&gt;yarn.application.classpath&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改mapred-site.xml 作用：指定MapReduce操作的基本属性 需要修改的机器：master、master1 内容 &lt;configuration&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 注意： MapReduce是不一定依赖yarn的，但一般使用yarn框架来实现MapReduce 此项若是不配，一些job只会在本机跑，而不会分发给其他机器 修改hive-site.xmlvim $HIVE_HOME/conf/hive-site.xml 作用：hive的基本配置 需要修改的机器：master、master1 内容： 修改hive.server2.webui.host &lt;property&gt; &lt;name&gt;hive.server2.webui.host&lt;/name&gt; &lt;value&gt;$&#123;hostname&#125;&lt;/value&gt; &lt;description&gt;The host address the HiveServer2 WebUI will listen on&lt;/description&gt;&lt;/property&gt; 其中${hostname}需要改成对应的主机名称(master与master1)，或者都改为0.0.0.0 修改hive.server2.bind.host &lt;property&gt; &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt; &lt;value&gt;$&#123;hostname&#125;&lt;/value&gt; &lt;description&gt;Bind host on which to run the HiveServer2 Thrift service.&lt;/description&gt;&lt;/property&gt; 其中${hostname}需要改成对应的主机名称(master与master1)，或者都改为0.0.0.0 修改hive.server2.zookeeper.namespace &lt;property&gt; &lt;name&gt;hive.server2.zookeeper.namespace&lt;/name&gt; &lt;value&gt;hiveserver2&lt;/value&gt; &lt;description&gt;The parent node in ZooKeeper used by HiveServer2 when supporting dynamic service discovery.&lt;/description&gt;&lt;/property&gt; 注意两个hiveserver节点的该值应设置为一样，指定了改值后，每当一个hiveserver节点启动时，在Zookeeper集群中，目录树下的hiveserver2文件夹下就可以看到该节点注册到Zookeeper中。 修改javax.jdo.option.ConnectionURL、javax.jdo.option.ConnectionPassword和javax.jdo.option.ConnectionDriverName &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&amp;amp;allowPublicKeyRetrieval=true&lt;/value&gt; &lt;description&gt; JDBC connect string for a JDBC metastore. To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL. For example, jdbc:postgresql://myhost/db?ssl=true for postgres database. &lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt; 这里两个节点的数据库连接字符串也应该是一样的，需要知道的是这里只有master节点安装并运行了mysql服务，存储hive元数据的均在此mysql数据库中，意即存储元数据信息是与master1无关的，实际上mysql服务器可以在网络上的任意位置(此处我一开始也误解了，以为master和master1节点都需要存储hive的元数据)。 另外，mysql的连接jar包需要下载并复制到hive的lib目录下。 至此整个Hadoop集群已经搭建完毕，却未完，需要使用Zookeeper集群来实现集群的高可用性（HA）。 Zookeeper配置对于剩下的node0、node1、node2三台机器是用于搭建Zookeeper集群的，因此需要安装并配置Zookeeper-3.4.10： vim /usr/local/zookeeper/conf/zoo.cfg# 添加一下内容server.1=192.168.137.200:2888:3888server.2=192.168.137.201:2888:3888server.3=192.168.137.202:2888:3888# 保存并关闭 ssh免密登录配置 作用：保证任何一台机器都可通过ssh免密访问其他机器，这对于使用sshfence策略的failover机制是很必要的 需要修改的机器：所有机器 内容： # 进入用户目录下的`.ssh`目录cdcd .ssh/# 创建公钥私钥对ssh-keygen -t rsa# 将公钥发送给其他所有节点，hostname需对应每一台机器更改为其主机名执行一遍ssh-copy-id $&#123;hostname&#125; 至此，Hadoop集群与Zookeeper集群已搭建完毕，接下来需要启动之。 集群启动初始化数据库在master机器上执行以下操作以初始化数据库： cd $HIVE_HOMEschematool -initSchema -dbType mysql 此命令执行完之后将会在mysql中创建hive的元数据表，以存储hive的表结构及其他属性。 启动集群在master机器上执行以下操作以启动集群： 项目功能需求项目主题超市销售管理系统 功能简介商品进货功能点说明：超市管理员查询供应商，并根据结果输入从该供应商进货的商品信息 数据需求：查询供应商，新增进货记录，新增商品 查询商品功能点说明：超市管理员通过商品名搜索库存中的所有相关商品 数据需求：查询商品 生成订单功能点说明：超市管理员查询相应商品并将其添加至订单中，添加完毕后生成订单 数据需求：查询商品，新增购买记录，新增订单 概念设计基于面向对象的思想，我们在分析数据需求的时候简单地将我们的系统分为两个模块：进货和购买，这两个模块都以商品为核心。因此在构建实体-联系模型时，我们也根据这个思想出发，将E-R图分为了两个模块。 总体E-R图 进货模块E-R图 进货模块主要包含两个实体集，公司（Corporation）和商品（Commodity）。商品中包含着超市库存商品的信息如商品名称、数量、价格，公司类包含供应商的信息如公司名称、地址、国家等。两个实体之间有着关系集供应（Supply），表示某商品从某公司进货。由于一种商品可能从多个公司进货，一个公司也可能供应多种商品，因此他们之间的关系应该是多对多。供应关系集同时还具有属性，表示进货的信息包括数量、成本、时间。 购买模块E-R图 购买模块包含的实体集有商品（Commodity）和订单（Bill）。订单表示一次完整购买的总订单（包含购买的所有商品情况），包含的信息有总价、折扣、实际价格等。商品和订单之间有关系集购买（Purchase），由于一个订单包含多个商品，一个商品也会被多次购买，因此这个关系是多对多的。同时，购买关系还具有属性，表示订单中的每一种商品购买的数量和小计价格。 逻辑设计表设计根据E-R模型的转化，我们生成了5张表，分别是：Corporation（公司），Supply（供应），Commodity（商品），Purchase（购买），Bill（订单）。表的详细设计如下： Commodity表 字段名 数据类型 长度 说明 备注 ID number 10 商品的ID PK name varchar 20 商品名称 quantity decimal 10,2 商品库存量 price decimal 10,2 商品单价 Corporation表 字段名 数据类型 长度 说明 备注 ID number 10 公司的ID PK name varchar 20 公司名称 address varchar 20 公司地址 country varchar 10 公司所在国家 business varchar 10 公司业务 Bill表 字段名 数据类型 长度 说明 备注 ID number 10 订单的ID PK totalprice decimal 10,2 订单总价 discount decimal 10,2 订单折扣 finalprice decimal 10,2 订单实际总价 realpay decimal 10,2 顾客付款 charge decimal 10,2 找钱 Supply表 字段名 数据类型 长度 说明 备注 corID number 10 供应公司的ID PK; FK，参照于Corporation的ID productID number 10 商品的ID PK；FK，参照于Commodity的ID amount decimal 10,2 商品供应数量 totalcost number 6 商品供应总成本 supplydate datetime 0 供应日期 Purchase表 字段名 数据类型 长度 说明 备注 productID number 10 购买商品的ID PK；参照于Commodity的ID billID number 10 订单ID PK；参照于Bill的ID amount decimal 10,2 购买该商品数量 sumprice decimal 10,2 购买该商品小计价格 数据库关系图根据表的设计和之间的外码约束，绘制出数据库的关系图： Hive中的实际存储经过多次尝试与实验，发现Hive中实际上是不支持表间外键联系的，因此我们在实际存储上述的表结构时将所有的外键均去除了。 这引出了数据仓库在实际应用中的一种常见处理方式：为了提高速度而产生数据冗余。Hive中的表结构的特殊性，使得\b使用人员方便针对各种功能设计所需的信息表，而非使用传统的符合3NF或者其他范式的表结构，这也是数据仓库作为大量数据集的OLAP最佳选择的原因之一(其消除了由于大量表间连接时而产生的冗余操作，这是很典型的以空间换取时间的策略)。 项目实现方法整个项目我们使用传统的JavaWeb框架。后端使用Servlet处理数据交互，使用JDBC连接Zookeeper管理的Hiveserver2集群；前端使用Bootstrap框架完成基本的项目展示功能： ​ 图1：查看库存 ​ 图2：查看历史账单 ​ 图3：创建新账单 我们深知本项目重点在分布式集群而非前端展示上，因此我们组将95%的精力放在项目的理论理解、环境搭建、性能提升以及实践使用上。 项目亮点HA的原理理解及实现HA的实现是我们组在搭建集群时遇到的最大的难题，如何协调其主次关系、如何保证网络通信、如何确定哪些进程应该运行在哪些合适的机器上，举个例子：在我们完成集群搭建到了最后启动Hive时，启动了两个Hive客户端进程和两个Hiveserver2服务端进程，而两个Hive客户端又共用了同一个MySQL服务器，导致jdbc在连接Zookeeper时会随机访问到两个Hive客户端，这导致了数据库数据时而一致、时而不一致，后来我们在Hive的配置文件将其连接Hive客户端改为同一个后将其解决了。诸如此类的小问题我们遇到了很多很多，最后都一一得到了解决。 Hive与MySQL的横向对比我们发现Hadoop集群启动后，前端与后端进行数据交互的速度很慢，于是我们使用MySQL与Hive做了简单的对比，结果很让我们困惑：MySQL的执行时间基本上是远远快于Hive的执行时间的。 我们从以下角度进行了思考与实验： 首先，考虑我们在这两种数据库中执行的操作，如果对于一开始数据从文件进入数据库中这一过程忽略的话，我们整个项目执行的都是OLAP即联机分析处理操作。Hive作为一个经典的数据仓库工具，本身应该是擅长执行OLAP操作的，因此暂且认为”操作”不是造成二者执行时间差异的原因； 其次，Hive官网有句话\b”Hive在大型数据集上会表现出优越的性能”，考虑到我们的项目数据集\b中，最多的数据集是数百万条的商品库存数据，我们猜测是数据量限制了Hive体现其\b优越性。因此我们作了如下实验：将数据量从10W变化到1000W，然后观察在等量的数据量变化上，二者执行时间的变化，得到下表： 数据库类型 10W数据 1000W数据 MySQL 9ms 271ms Hive(textfile) 1428ms 5100ms 就时间来说，很显然MySQL更胜一筹，但从增长比例来说，MySQL从9ms增长至271ms增长约为30倍，而\bHive增长约为5倍，由此我们可窥见Hive在大量数据集时性能会更加优越。 然而在这过程中，\b我们所使用的Hive所采用的为textfile存储结构，意即内容即文件，表数据完全按照表结构存储成为文本文件。\b从Hive官方文档我们得知Hive有其他更加优越的存储格式，它包含SequenceFile、RCFile、ORCFile，因此我们采取了所谓最优的ORCFile来Duplicate了用户评论表，想以此对比ORCFile之于TextFile的优点。存储中源数据文件大小为872MB，当使用textfile格式存储时，Hive会将我们导入的文件原封不动的移动到hdfs的Hive数据文件目录下，而使用ORCFile格式存储时文件大小只有260MB大小，这是其优点之一：文件压缩。至于性能，我们执行了上述同样的实验： 数据库类型 10W数据 1000W数据 MySQL 9ms 271ms Hive(textfile) 1428ms 5100ms Hive(ORC) 110ms 126ms 结果显而易见，当数据达到\b数百万量级时，Hive在存储模式较优的使用方法下已经要比MySQL要稍显胜势了。 通过以上两点我们不难总结出以下几点： 限制Hive的效率的因素： 数据量 在百万数据量以下时，Hadoop是很难发挥出其优点的 \b计算框架 Hive在我们项目中使用的是MapReduce框架来执行分布式计算，然而比\b现在已经有很多比MapReduce快得多的计算框架例如Spark等，因此若使用这些框架必定会使Hive执行效率更上一层 网络通信 由于我们的集群搭建在虚拟机中，其间数据通过真实的网络通信传输，虽然少了中间光纤传递的过程，但是在建立连接到发送数据到取消连接这一过程所耗费的时间都是很难被忽略的，因此生产环境下的Hadoop集群对网络带宽的要求是很高的 百万级数据的OLAP场景或者OLTP操作需求较多的场景下，MySQL(关系型数据库)是优选 千万乃至亿万级数据的批处理、分析场景，Hive(数据仓库/分布式数据库)在存储、读取、分析效率上都要更优","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://blog.guitoubing.top/tags/Hadoop/"},{"name":"云计算","slug":"云计算","permalink":"http://blog.guitoubing.top/tags/云计算/"},{"name":"大三上笔记","slug":"大三上笔记","permalink":"http://blog.guitoubing.top/tags/大三上笔记/"}]},{"title":"Hadoop-Tags","slug":"Hadoop-Tags","date":"2018-12-11T16:33:02.000Z","updated":"2019-03-11T04:43:12.437Z","comments":true,"path":"2018/12/12/Hadoop-Tags/","link":"","permalink":"http://blog.guitoubing.top/2018/12/12/Hadoop-Tags/","excerpt":"更新中……","text":"更新中…… Hadoop TagsHDFS NameNode内存要求较高，存储文件系统元结构（文件目录结构、分块情况、每块位置、权限等） 文件分块默认最小块128M jps命令查看NameNode/DataNode是否启动 jps在jdk8u191中好像不适用，暂未找到解决方法 ip:9870利用web界面查看Hadoop节点信息（Mac上端口号为50070） 进入用户目录下的.ssh目录，执行ssh-keygen -t rsa创建公钥私钥，使用ssh-copy-id ${hostname}将公钥传给每个节点（NameNode和DataNode都需要） 使用hadoop fs -ls /查看Hadoop上所有文件，使用hadoop fs -put ${filename} /上传文件… hdfs-site.xml中修改dfs.replication配置可修改文件备份份数（默认为3），修改dfs.namenode.heartbead.recheck-interval指定Hadoop检查机器运行情况的时间间隔（默认3000000ms） 注意： 例如当备份份数为2时，现在有三台DataNode机器，文件被分为2个block，block1位于1和2上，block2位于1和3上，这是若机器3宕机了，hdfs会在设定的dfs.namenode.heartbead.recheck-interval时间间隔内检查出机器3，此时block2数量变为1，hdfs会自动将1中的block2复制一份到另外一台可用机器上（此处为2）。当机器3恢复运行时，3中备份的block2会自动删除。 当使用java访问hdfs时，不会使用hdfs-site.xml中的dfs.replication，而会默认使用3，可在java的configuration中配置为指定值 分鱼展:分块、冗余、可扩展 Yarn ResourceManage NodeManage一般与DataNode放一起 Yarn逻辑上与HDFS完全分离，但一般绑定HDFS一起使用 yarn-site.xml的配置 注意：master与slaves都需要进行配置。 &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt;&lt;/property&gt; mapred-site.xml的配置 注意： 仅NameNode需要配置 MapReduce不一定需要Yarn 若不配MapReduce，其会仅在单机跑 &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; Hive 创建Hive、Hadoop环境变量，方便敲命令 修改hive-site.xml hive的conf目录下刚初始化时没有\bhive-site.xml，需要将hive-default.xml.template复制一份更名为hive-site.xml 将hive-site.xml中所有的(4个)${system:java.io.tmpdir}替换为/usr/local/hive/tmp，将所有的(4个)${system:user.name}替换为root 进入hive根目录，执行 schematool -initSchema -dbType derby 上述命令执行完毕后会在对应目录下新建metastore_db目录，用于存储数据目录 derby是hive自带的小数据库，后续需要将derby更换成mysql(TODO) \b在该目录下启动\b执行hive 注意： hive命令执行时，必须与metastore_db在同一目录下 hive启动前需要将hdfs也启动，不然会报错 hive连接mysql 关于\b虚拟机安装了mysql数据库，主机无法连接的问题如下： mysql&gt; use mysql;Database changedmysql&gt; select &apos;host&apos; from user where user=&apos;root&apos; -&gt; ;+------+| host |+------+| localhost |+------+1 row in set (0.00 sec)mysql&gt; update user set host = &apos;%&apos; where user =&apos;root&apos;;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; flush privileges;Query OK, 0 rows affected (0.01 sec)mysql&gt; select &apos;host&apos; from user where user=&apos;root&apos;;+------+| host |+------+| % |+------+1 row in set (0.00 sec) 解决jdbc连接hive时出现Open Session Error &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; hive表存储格式 TextFile SequenceFile RCFile ORCFile HA的实现集群环境 Hadoop 2.9.2 \bHive 2.3.4 MySQL 5.7 Zookeeper 3.4.10 JDK 8u191 集群结构图 共9台机器，其中3台ZooKeeper集群，5台Hadoop集群（2台Master，3台Slave），1台应用服务器 主机名 IP 软件 运行进程 node0 192.168.137.200 ZooKeeper QuorumPeerMain node1 192.168.137.201 ZooKeeper QuorumPeerMain node2 192.168.137.202 ZooKeeper QuorumPeerMain master 192.168.137.100 Hadoop,Hive,MySql JournalNode,NameNode,ResourceManager,DFSZKFailoverController,HiveServer2,MySql master1 192.168.137.10 Hadoop,Hive JournalNode,NameNode,ResourceManager,DFSZKFailoverController,HiveServer2 slave1 192.168.137.101 Hadoop JournalNode,DataNode,NodeManager slave2 192.168.137.102 Hadoop DataNode,NodeManager slave3 192.168.137.103 Hadoop DataNode,NodeManager host 192.168.137.1 应用服务器 集群启动步骤# 在三台zookeeper上启动zkServerzkServer.sh start# master上执行hdfs和yarn集群的启动start-dfs.shstart-yarn.sh# master1上的ResourceManager不知道为何不会自动启动，因此手动yarn-daemon.sh start resourcemanager# master和master1上\b都要启动hiveserver2hiveserver2 关于二级缓存的若干事宜在集群启动完毕之后，我在master的hive中使用create table test(...)语句创建了一个表并导入了一些数据，而后通过应用执行该表的相关查询后，发现时不时提示表test不存在，通过hive查看master和master1的表结构，发现master1中竟然没有表test，查阅资料后看到一篇博文《hive datanucleus cache 不一致问题》，是关于hive中的DataNucleus二级缓存的设置，datanucleus.cache.level2.type的设置(none,soft,weak)直接影响二级缓存是否启用，关于二级缓存的具体机制我还没弄清楚，之后我又在Hortonworks的文档中看到下面的话： Important:Hortonworks recommends that deployments disable the DataNucleus cache by setting the value of the datanucleus.cache.level2.type configuration parameter to none. The datanucleus.cache.level2 configuration parameter is ignored, and assigning a value of none to this parameter does not have the desired effect. 可能是\bHiveserver2本身在HA的层面就不建议修改库、表结构，因此若要更改表结构或者创建新表同时实现数据同步，我试了以下两种方式均可实现： 第一种关闭并重新初始化集群，启动master和所有的DataNode，在master上执行建库建表导入数据，而后启动master1将其作为standby初始化，这时master1会同步master的数据，最后启动master和master1的hiveserver2 第二种是同时在master和master1的hive客户端上执行同样的建表语句，而后在master(或者master1)上执行load命令加载数据，即可同步数据 \b第二种方法又出现了个有趣的问题：导入数据完成后，在两台机器上分别执行count操作会发现由于加载数据的机器count正常，另一台机器count结果为0，但是执行select *又确实能发现数据存在，就很玄学。 TODO List 安全与权限（kerberos） Secondary NameNode（check point NameNode） HA（High Ability）实现 Federation，超大规模数据中心","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://blog.guitoubing.top/tags/Hadoop/"},{"name":"云计算","slug":"云计算","permalink":"http://blog.guitoubing.top/tags/云计算/"}]},{"title":"Best Practice","slug":"Practice","date":"2018-11-24T06:18:44.000Z","updated":"2019-02-26T05:48:07.858Z","comments":true,"path":"2018/11/24/Practice/","link":"","permalink":"http://blog.guitoubing.top/2018/11/24/Practice/","excerpt":"Oracle专家的三次授课。","text":"Oracle专家的三次授课。 Lesson 1创建用户并分配权限创建测试schema，命名为testcreate user test identified by test; 分配连接资源grant connect,resource to test;grant execute on dbms_lock to test;grant execute on UTL_FILE to test; 为test用户创建external_data目录以及分配权限create directory external_data as &apos;/home/oracle/data&apos;;grant read,write on directory external_data to test; 要注意oracle用户必须拥有对这里的external_data路径读写的权限。 分配表空间权限我们知道oracle中没有库的概念，取而代之的是表空间（Tablespace），在oracle初次被安装时，数据库中只有系统本身内置的表空间： SYSTEM - 存储数据字典 SYSAUX - 存储辅助应用程序的数据 TEMP - 存储数据库临时对象 USERS - 存储各个用户创建的对象 UNDOTBS - 存储不一致数据，用于事物回滚、数据库恢复、读一致性、闪回查询 …… 而当第一次通过管理员创建一个用户且未为其创建并指定表空间时，数据库系统会为其指定默认的表空间为SYSTEM，而他并没有使用SYSTEM表空间的权限，因此该用户无法完成建表等操作，可通过执行以下操作： -- DBA下执行：-- 查看数据库中的所有表空间select * from v$tablespace;-- 查看当前用户所在的表空间(注意oracle系统表中存储的用户名字段都是大写，要注意这与“oracle中不区分大小写”这一概念区分开来)select username,default_tablespace from dba_users where username=&apos;TEST&apos;;-- 为用户赋予当前表空间下的权限alter user test quota unlimited on users;-- 或者制定用户可用大小：alter user test quota 50M on users; 连接用户，建表，跑存储过程和函数连接test用户-- 在系统命令下连接cd $ORACLE_HOME/bin./sqlplus test/test -- 在进入sqlplus后的连接conn test/test 创建表create table t_mobiles(f_id number(6),f_mobile_head varchar2(50),f_province varchar2(50),f_city varchar2(50),f_platform varchar2(50),f_tel_head varchar2(50),f_zipcode varchar2(50),primary key(f_id));COMMENT ON COLUMN T_MOBILES.F_ID IS &apos;主键&apos;;COMMENT ON COLUMN T_MOBILES.F_MOBILE_HEAD IS &apos;手机号段&apos;;COMMENT ON COLUMN T_MOBILES.F_PROVINCE IS &apos;省份地区&apos;;COMMENT ON COLUMN T_MOBILES.F_CITY IS &apos;城市&apos;;COMMENT ON COLUMN T_MOBILES.F_PLATFORM IS &apos;运营商&apos;;COMMENT ON COLUMN T_MOBILES.F_TEL_HEAD IS &apos;固话区号&apos;;COMMENT ON COLUMN T_MOBILES.F_ZIPCODE IS &apos;邮政编码&apos;;COMMENT ON TABLE T_MOBILES IS &apos;号段表&apos;;create table t_records(f_id number(6),f_no varchar2(50),f_begin_time date,f_end_time date,f_duration number(10,0),f_province VARCHAR2(50), f_platform varchar2(50), f_mobile NUMBER(1) DEFAULT -1);--*注：因f_id导入时缺少数据，所有先不设置为PK.COMMENT ON COLUMN T_RECORDS.F_ID IS &apos;主键&apos;;COMMENT ON COLUMN T_RECORDS.F_NO IS &apos;通话号码&apos;;COMMENT ON COLUMN T_RECORDS.F_BEGIN_TIME IS &apos;开始时间&apos;;COMMENT ON COLUMN T_RECORDS.F_END_TIME IS &apos;结束时间&apos;;COMMENT ON COLUMN T_RECORDS.F_DURATION IS &apos;通话时长&apos;;COMMENT ON COLUMN T_RECORDS.F_PROVINCE IS &apos;省份地区&apos;;COMMENT ON COLUMN T_RECORDS.F_PLATFORM IS &apos;运营商&apos;;COMMENT ON COLUMN T_RECORDS.F_MOBILE IS &apos;手机号码标志&apos;;COMMENT ON TABLE T_RECORDS IS &apos;通话清单表&apos;; 创建ctl文件导入csv数据进入external_data路径下并创建以下文件： $ cd /home/oracle/data$ vi control_mobiles.ctl$ vi control_records.ctl control_mobiles.ctl: LOAD DATACHARACTERSET UTF8INFILE &apos;/home/oracle/data/mobiles.csv&apos;TRUNCATE INTO TABLE t_mobilesFIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&apos;TRAILING NULLCOLS( F_ID, F_MOBILE_HEAD, F_PROVINCE, F_CITY, F_PLATFORM, F_TEL_HEAD, F_ZIPCODE) control_records.ctl: LOAD DATACHARACTERSET UTF8INFILE &apos;/home/oracle/data/records.csv&apos;TRUNCATE INTO TABLE t_recordsFIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&apos;TRAILING NULLCOLS( F_NO, F_BEGIN_TIME DATE &quot;YYYY-MM-DD HH24:MI:SS&quot;, F_END_TIME DATE &quot;YYYY-MM-DD HH24:MI:SS&quot;, F_DURATION INTEGER EXTERNAL) 在该路径下执行导入操作： $ $ORACLE_HOME/bin/sqlldr userid=test/test control=control_mobiles.ctl$ $ORACLE_HOME/bin/sqlldr userid=test/test control=control_records.ctl 教程中命令为： &gt; $ sqlldr userid=test/test@orcl control=control_mobiles.ctl&gt; 即在导入时指定连接字符串（这里的orcl实际上是连接字符串的别名），其在$ORACLE_HOME/network/admin/tnsname.ora中被声明，但是默认状态下oracle中并没有配置该连接字符串，意味着我们在连接时不需要为其指定值。 既然如此，应用程序该如何在未进行上述配置的情况下连接到该字符串呢？这里就是连接字符串和服务名的区别，oracle有个默认服务名XE，实际上oracle中还有多个备用服务，当XE服务崩掉的时候会自动切换到备用服务。连接字符串如下： &gt; jdbc:oracle:thin:@localhost:1521:XE&gt; 那么没有配置连接字符串别名时，sqlplus如何通过此方法连接呢？如下直接将连接字符串全部写全： &gt; # 命令格式：sqlplus username/password@host:port/service_name&gt; $ sqlplus tanrui/tanrui@127.0.0.1:1521/xe&gt; 数据预处理-- 1、创建序列seq_records_pk用于生成通话记录表t_records的主键create sequence seq_records increment by 1 start with 1 ;-- 2、修补通话记录表t_records的主键数据，并把f_id改为主键update t_records set f_id=seq_records.nextval;alter table t_records add constraint t_records_pk primary key (f_id);-- 3、创建并初始化同步锁表，用于多线程同步控制CREATE TABLE T_LOCK(F_NAME VARCHAR2(30),F_INDEX NUMBER(20,0),PRIMARY KEY(F_NAME));COMMENT ON COLUMN T_LOCK.F_NAME IS &apos;锁名&apos;;COMMENT ON COLUMN T_LOCK.F_INDEX IS &apos;锁的当前值&apos;;COMMENT ON TABLE T_LOCK IS &apos;同步锁表&apos;;insert into T_LOCK values(&apos;_RECORD_INDEX&apos;,0);-- 4、在电话号段表中创建唯一性索引，提高号段检索速度create unique index uniq_mobile_head on t_mobiles(f_mobile_head);update t_mobiles set f_province = &apos;内蒙古&apos; where f_province = &apos;内蒙&apos;;-- 5、创建日志表，用于记录程序执行过程中的日志信息。create table t_log(f_time date, f_head varchar2(20), f_content varchar2(500));COMMENT ON COLUMN T_LOG.F_TIME IS &apos;日志时间&apos;;COMMENT ON COLUMN T_LOG.F_HEAD IS &apos;日志类型标志&apos;;COMMENT ON COLUMN T_LOG.F_CONTENT IS &apos;日志内容&apos;;COMMENT ON TABLE T_LOG IS &apos;日志表&apos;; 创建函数和存储过程声明函数和存储过程 函数is_mobile，判断通话号码是否为手机号码 --函数：判断通话号码是否为手机号码CREATE OR REPLACE FUNCTION is_mobile(phone VARCHAR2) RETURN BOOLEAN IS v_phone VARCHAR2(20); v_head VARCHAR2(2);BEGIN --检查参数func IF phone IS NULL THEN RETURN FALSE; END IF; --去除前后空格 v_phone := TRIM(phone); --去除号码前面的0 IF substr(v_phone,0,1) = &apos;0&apos; THEN v_phone := substr(v_phone, 2); END IF; --检查手机号码长度 IF substr(v_phone,0,1) &lt;&gt; &apos;1&apos; OR LENGTH(v_phone) &lt;&gt; 11 THEN RETURN FALSE; END IF; --截取号码前两位 v_head := substr(v_phone,1,2); IF v_head = &apos;13&apos; OR v_head = &apos;14&apos; OR v_head =&apos;15&apos; OR v_head =&apos;17&apos; OR v_head = &apos;18&apos; THEN RETURN TRUE; ELSE RETURN FALSE; END IF;END;/ 存储过程init，清空t_log，同时t_lock置零 --存储过程：初始化测试数据CREATE OR REPLACE PROCEDURE init IS CURSOR job_cursor IS SELECT JOB FROM user_jobs;BEGIN --重置处理位置为0 EXECUTE IMMEDIATE &apos;update t_lock set f_index=0&apos;; --清除日志表中的记录 EXECUTE IMMEDIATE &apos;truncate table t_log&apos;; --重置话单表中的记录 EXECUTE IMMEDIATE &apos;update t_records set f_province = NULL,f_platform=NULL, f_mobile=-1&apos;; COMMIT; FOR tmp_job IN job_cursor LOOP dbms_job.broken(tmp_job.JOB,TRUE,sysdate); dbms_job.REMOVE(tmp_job.JOB); END LOOP;END;/ 存储过程print，打印日志，存到T_LOG表中 --存储过程：打印日志CREATE OR REPLACE PROCEDURE print(prefix VARCHAR2, content VARCHAR2) ISBEGIN --dbms_output.put_line(to_char(&apos;yyyy-mm-dd hh24:mi:ss&apos;)||&apos;,&apos;||prefix||&apos;,&apos;||content); INSERT INTO t_log VALUES(sysdate,prefix, content); COMMIT;EXCEPTION WHEN OTHERS THEN dbms_output.put_line(&apos;Error code: &apos;||SQLCODE); dbms_output.put_line(&apos;Error mesg: &apos;||sqlerrm);END;/ 存储过程show，显示当前处理情况 --存储过程：显示当前处理情况CREATE OR REPLACE PROCEDURE show IS --待处理记录总数 v_record_count NUMBER; --当前日志表记录总数 v_log_count NUMBER; --当前数据处理位置 v_current_index NUMBER; --用户Job表游标 CURSOR job_cursor IS SELECT * FROM user_jobs;BEGIN SELECT COUNT(1) INTO v_log_count FROM t_log; SELECT f_index INTO v_current_index FROM t_lock; SELECT COUNT(1) INTO v_record_count FROM t_records; dbms_output.put_line(&apos;log count: &apos;||v_log_count); dbms_output.put_line(&apos;record count: &apos;||v_record_count); dbms_output.put_line(&apos;current index: &apos;||v_current_index); --清除用户job记录 FOR tmp_job IN job_cursor LOOP dbms_output.put_line(&apos;job:&apos;||tmp_job.JOB||&apos;,broken:&apos;||tmp_job.broken||&apos;,total_time:&apos;||tmp_job.total_time||&apos;,failures:&apos;||tmp_job.failures||&apos;,interval:&apos;||tmp_job.INTERVAL||&apos;,last_sec:&apos;||tmp_job.last_sec||&apos;,next_sec:&apos;||tmp_job.next_sec); END LOOP;END;/ 存储过程process_data，提交一个job处理数据 共享锁和排它锁: 当某事务对数据添加共享锁时，此时该事务只能读不能写，其他事务只能对该数据添加共享锁，而不能添加排它锁 当某事务对数据添加排它锁时，此时该事务既能读又能写，其他事务不能对该数据添加任何锁 autocommit需要关掉: 假设现在有三个job对T_LOCK表进行并发读写，如下： 步骤如下： 阻塞情况： --存储过程：处理数据CREATE OR REPLACE PROCEDURE process_data(process_no IN NUMBER, batch_size IN NUMBER) IS --定义常量 c_record_index CONSTANT VARCHAR2(20) :=&apos;_RECORD_INDEX&apos;; c_process_prefix CONSTANT VARCHAR2(20) := &apos;[ PROCESS ]&apos;; c_select_record_sql VARCHAR2(100) := &apos;select * from t_records where f_id &gt;= :x and f_id &lt;= :y&apos;; c_select_mobile_sql VARCHAR2(100) := &apos;select * from t_mobiles where f_mobile_head = :x&apos;; c_update_mobile_sql VARCHAR2(100) := &apos;update t_records set f_province = :x, f_platform = :y, f_mobile = 1 where f_id = :z&apos;; c_update_record_sql VARCHAR2(100) := &apos;update t_records set f_mobile = 0 where f_id = :n&apos;; v_record_count NUMBER; v_current_index NUMBER; v_begin_index NUMBER; v_end_index NUMBER; v_id NUMBER; v_phone VARCHAR2(20); v_province VARCHAR2(20); v_platform VARCHAR2(20); --定义动态游标 TYPE ty_record_cursor IS REF CURSOR; record_cursor ty_record_cursor; mobile_cursor ty_record_cursor; v_record_row t_records%rowtype; v_mobile_row t_mobiles%rowtype;BEGIN PRINT(c_process_prefix, &apos;process[&apos;||process_no||&apos;], running...&apos;); --获取待处理的记录总数 SELECT COUNT(1) INTO v_record_count FROM t_records; PRINT(c_process_prefix, &apos;process[&apos;||process_no||&apos;], records count: &apos;||v_record_count); LOOP --获取记录锁 SELECT f_index INTO v_current_index FROM t_lock WHERE f_name = c_record_index FOR UPDATE; PRINT(c_process_prefix, &apos;process[&apos;||process_no||&apos;], current index: &apos;||v_current_index); IF v_current_index = v_record_count THEN PRINT(c_process_prefix, &apos;process[&apos;||process_no||&apos;], finished.&apos;); EXIT; END IF; --记录本次处理的开始和结束记录位置 v_end_index := v_current_index + batch_size; IF v_end_index &gt; v_record_count THEN v_end_index := v_record_count; END IF; --提交事务，释放锁 UPDATE t_lock SET f_index = v_end_index WHERE f_name =c_record_index; COMMIT; --计算开始位置 v_begin_index := v_current_index +1; PRINT(c_process_prefix, &apos;process[&apos;||process_no||&apos;], begin index:&apos;||v_begin_index||&apos;, end index:&apos;||v_end_index); --test：dbms_lock.sleep(5); --查询一批记录进行逐个处理 OPEN record_cursor FOR c_select_record_sql USING v_begin_index, v_end_index; LOOP FETCH record_cursor INTO v_record_row; EXIT WHEN record_cursor%notfound; v_id := v_record_row.f_id; v_phone := v_record_row.f_no; IF is_mobile(v_phone) THEN v_phone := TRIM(v_phone); IF substr(v_phone,0,1) = &apos;0&apos; THEN v_phone := substr(v_phone, 2); END IF; --PRINT(c_process_prefix, &apos;process[&apos;||process_no||&apos;], id:&apos;||v_id||&apos;, phone:&apos;||v_phone); --更新话单记录中的省份、运营商以及手机类型标志 OPEN mobile_cursor FOR c_select_mobile_sql USING substr(v_phone,1,7); FETCH mobile_cursor INTO v_mobile_row; v_province := v_mobile_row.f_province; v_platform := v_mobile_row.f_platform; --FETCH mobile_cursor INTO v_province, v_platform; CLOSE mobile_cursor; --更新话单记录的运营商、省份地区信息 EXECUTE IMMEDIATE c_update_mobile_sql USING v_province,v_platform,v_id; ELSE --更新话单记录为非移动号码类型 EXECUTE IMMEDIATE c_update_record_sql USING v_id; END IF; --提交事务 COMMIT; END LOOP; CLOSE record_cursor; PRINT(c_process_prefix, &apos;process[&apos;||process_no||&apos;], processed index: &apos;||v_end_index); END LOOP;EXCEPTION WHEN OTHERS THEN dbms_output.put_line(&apos;Error code: &apos;||SQLCODE); dbms_output.put_line(&apos;Error mesg: &apos;||sqlerrm);END;/ 存储过程generate_csv_report，生成报表 --存储过程：生成报表CREATE OR REPLACE PROCEDURE generate_csv_report IS c_report_prefix CONSTANT VARCHAR2(20) := &apos;[ REPORT ]&apos;; v_report_1 UTL_FILE.FILE_TYPE; v_report_2 UTL_FILE.FILE_TYPE; CURSOR report_1_cursor IS SELECT f_platform,f_province,SUM(f_duration) total FROM t_records WHERE f_mobile=1 GROUP BY f_platform,f_province ORDER BY f_platform ASC,SUM(f_duration) DESC; cursor report_2_cursor is select f_province,f_platform,sum(f_duration) total from t_records where f_mobile=1 group by f_province,f_platform order by f_province asc,sum(f_duration) desc;BEGIN --生成报表1，根据运营商分类汇总各省份地区的通话量 v_report_1 := UTL_FILE.FOPEN( LOCATION =&gt; &apos;EXTERNAL_DATA&apos;, filename =&gt; &apos;report1.csv&apos;, open_mode =&gt; &apos;w&apos;, max_linesize =&gt; 32767); FOR cur_tmp IN report_1_cursor LOOP UTL_FILE.PUT_LINE(v_report_1, cur_tmp.f_platform || &apos;,&apos; || cur_tmp.f_province || &apos;,&apos; || cur_tmp.total); END LOOP; UTL_FILE.FCLOSE(v_report_1); --生成报表2，根据各省份地区汇总各运营商的通话量 v_report_2 := UTL_FILE.FOPEN( LOCATION =&gt; &apos;EXTERNAL_DATA&apos;, filename =&gt; &apos;report2.csv&apos;, open_mode =&gt; &apos;w&apos;, max_linesize =&gt; 32767); FOR cur_tmp IN report_2_cursor LOOP UTL_FILE.PUT_LINE(v_report_2, cur_tmp.f_province || &apos;,&apos; || cur_tmp.f_platform || &apos;,&apos; || cur_tmp.total); END LOOP; UTL_FILE.FCLOSE(v_report_2); PRINT(c_report_prefix, &apos;generated reports.&apos;); EXCEPTION WHEN OTHERS THEN dbms_output.put_line(&apos;Error code: &apos;||SQLCODE); dbms_output.put_line(&apos;Error mesg: &apos;||sqlerrm);END;/ 存储过程analysis，调用上述函数，完成任务逻辑，支持指定任务个数和一批数量 dbms_job: 用于管理job的package oracle限定的job_queue_processes: oracle中有一个对任务可启动进程的数量进行限制的参数： &gt; SQL&gt; show parameter job_queue_processes;&gt; NAME TYPE VALUE&gt; ----------------------------------------------------------&gt; job_queue_processeses integer 10&gt;&gt; SQL&gt; alter system set job_queue_processes=0...1000;&gt; 使用ctrl+c是无法停止job的: 可使用top命令查看当前进程详情，如果需要结束特定job可kill对应job的进程号 CREATE OR REPLACE PROCEDURE analysis (job_count IN NUMBER, batch_size IN NUMBER)IS --定义常量 c_record_index CONSTANT VARCHAR2(20) :=&apos;_RECORD_INDEX&apos;; c_analysis_prefix CONSTANT VARCHAR2(20) := &apos;[ ANALYSIS ]&apos;; --当前处理位置 v_record_index NUMBER; --待处理的记录总数 v_record_count NUMBER; --保存临时创建的job no v_tmp_jobno NUMBER; --开始结束时间 v_begin_time NUMBER; v_process_end_time NUMBER; v_analysis_end_time NUMBER; --异常变量 e_invalid_input EXCEPTION;BEGIN PRINT(c_analysis_prefix, &apos; start analysis...&apos;); --输入参数检查 IF job_count &lt; 1 OR batch_size&lt;1 THEN RAISE e_invalid_input; END IF; PRINT(c_analysis_prefix, &apos; checked input parameters.&apos;); --记录开始时间 v_begin_time := dbms_utility.get_time; --获取待处理的记录总数 SELECT COUNT(1) INTO v_record_count FROM t_records; PRINT(c_analysis_prefix, &apos; records count: &apos;||v_record_count); --开始计算重置为0 UPDATE t_lock SET f_index=0 WHERE f_name=c_record_index; COMMIT; PRINT(c_analysis_prefix, &apos; reset index to zero.&apos;); --提交多个job FOR I IN 1.. job_count LOOP dbms_job.submit(v_tmp_jobno,&apos;begin process_data(&apos;||I||&apos;,&apos;||batch_size||&apos;); end;&apos;); PRINT(c_analysis_prefix, &apos; submitted new job, no: &apos;||v_tmp_jobno); END LOOP; PRINT(c_analysis_prefix, &apos; created &apos;||job_count||&apos; jobs.&apos;); --定时检查处理进度 LOOP SELECT f_index INTO v_record_index FROM t_lock WHERE f_name = c_record_index; PRINT(c_analysis_prefix, &apos; current index: &apos;||v_record_index); IF v_record_index = v_record_count THEN PRINT(c_analysis_prefix, &apos; processed all records, exiting...&apos;); EXIT; ELSE dbms_lock.sleep(5);--暂停等待5秒 END IF; END LOOP; v_process_end_time := dbms_utility.get_time; PRINT(c_analysis_prefix, &apos;process, elapsed time: &apos;||(v_process_end_time-v_begin_time)/100||&apos; seconds.&apos;); dbms_output.put_line(&apos;process, elapsed time: &apos;||(v_process_end_time-v_begin_time)/100||&apos; seconds.&apos;); --分类汇总产生报表 generate_csv_report; --结束时间 v_analysis_end_time := dbms_utility.get_time; PRINT(c_analysis_prefix, &apos;report, elapsed time: &apos;||(v_analysis_end_time-v_process_end_time)/100||&apos; seconds.&apos;); dbms_output.put_line(&apos;report, elapsed time: &apos;||(v_analysis_end_time-v_process_end_time)/100||&apos; seconds.&apos;);--异常捕获部分EXCEPTION WHEN e_invalid_input THEN dbms_output.put_line(&apos;Invalid input values, job_count:&apos;||job_count||&apos;, batch_size:&apos;||batch_size); WHEN OTHERS THEN dbms_output.put_line(&apos;Error code: &apos;||SQLCODE); dbms_output.put_line(&apos;Error mesg: &apos;||sqlerrm);END;/ 存储过程mul_analysis，循环调用analysis，指定不同的任务个数和批数量，并将运行时间存入T_RESULT中 -- 调用多次analysis，指定不同的job数和批数create or replace procedure mul_analysis is -- 最小job数 v_begin_job_no NUMBER := 3; -- 最大job数 v_end_job_no NUMBER := 8; -- 每次增长的batch数量 v_range NUMBER := 2000; -- 最小batch数量 v_begin_range NUMBER := 1000; -- 最大batch数量 v_end_range NUMBER := 10000; -- 当前range range NUMBER; begin for I in v_begin_job_no..v_end_job_no LOOP range := v_begin_range; LOOP -- 清洗表 init(); -- 分析 analysis(I, range); range := range+v_range; -- range增长到10000则停止 if range &gt; v_end_range then exit; end if; end loop; end loop; end;/ 执行函数和存储过程 在sqlplus中执行函数和存储过程之前需先打开serveroutput，即： &gt; SQL&gt; set serveroutput on;&gt; 这是因为存储过程中用到了dbms_output.put_line，上述语句是相当于告诉pl/sql引擎将dbms_output.put_line传递到缓冲区的内容输出到主控制台上。 call init();call analysis(4,1000); 结果分析通过执行mul_analysis()对一系列job和batch组合值进行测试，结果如下： Lesson 2创建用户并分配权限创建用户create user audittest identified by audittest; 分配权限grant connect,resource to audittest;grant execute on dbms_lock to audittest;alter user audittest quota unlimited on users;conn audittest/audittest; 创建表及其他对象创建表 注意： 这里在创建表时添加了ENABLE限制条件，oracle中对表和列的约束有Enable/Disable(启用/禁用)和Validate/NoValidate(验证/不验证) 举两个例子： 需更改的错误： &gt; -- 创建表，对name字段添加唯一性约束&gt; drop table T_TEST;&gt; create table T_TEST(&gt; id int primary key ,&gt; name varchar2(10) constraint unique_name unique disable&gt; );&gt; -- 由于某些错误，添加的记录违反了唯一性约束，但添加不会报错&gt; begin&gt; insert into T_TEST values (1, &apos;tan&apos;);&gt; insert into T_TEST values (2, &apos;rui&apos;);&gt; insert into T_TEST values (3, &apos;tan&apos;);&gt; end;&gt; select * from T_TEST;&gt; -- 修改掉违反唯一性约束的值&gt; update T_TEST set name=&apos;chen&apos; where id=3;&gt; -- 使得唯一性约束生效&gt; alter table T_TEST modify constraint unique_name enable;&gt; select * from T_TEST;&gt;&gt; 需保留的错误： &gt; -- 创建表，无约束&gt; drop table T_TEST;&gt; create table T_TEST(&gt; id int primary key ,&gt; name varchar2(10)&gt; );&gt; -- 一些old的记录本身可能存在重复数据&gt; begin&gt; insert into T_TEST values (1, &apos;tan&apos;);&gt; insert into T_TEST values (2, &apos;rui&apos;);&gt; insert into T_TEST values (3, &apos;tan&apos;);&gt; end;&gt; select * from T_TEST;&gt; -- 对name列创建非唯一性索引&gt; create index i_name on T_TEST(name);&gt; -- 新要求需要对name添加唯一性约束unique_name，但保留旧值，注意这里一定要使用非唯一性索引&gt; alter table T_TEST add constraint unique_name unique(name) using index i_name ENABLE NOVALIDATE ;&gt; -- 此时无法插入name相同的数据了&gt; insert into T_TEST values (4, &apos;tan&apos;);&gt; --部门表CREATE TABLE &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_CODE&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_PARENT_ID&quot; NUMBER(6,0), &quot;F_MANAGER&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_REMARK&quot; VARCHAR2(200 BYTE), CONSTRAINT &quot;T_DEPARTMENT_PK&quot; PRIMARY KEY (&quot;F_ID&quot;)) ;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot;.&quot;F_NAME&quot; IS &apos;部门名称&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot;.&quot;F_CODE&quot; IS &apos;部门编号&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot;.&quot;F_PARENT_ID&quot; IS &apos;上级部门ID&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot;.&quot;F_MANAGER&quot; IS &apos;部门经理&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON TABLE &quot;AUDITTEST&quot;.&quot;T_DEPARTMENT&quot; IS &apos;部门表&apos;;--用户表CREATE TABLE &quot;AUDITTEST&quot;.&quot;T_USER&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_DEPT_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_CODE&quot; VARCHAR2(20 BYTE), &quot;F_SEX&quot; VARCHAR2(5 BYTE) DEFAULT NULL, &quot;F_MOBILE&quot; VARCHAR2(20 BYTE), &quot;F_TELEPHONE&quot; VARCHAR2(20 BYTE), &quot;F_EMAIL&quot; VARCHAR2(50 BYTE), &quot;F_REMARK&quot; VARCHAR2(200 BYTE), CONSTRAINT &quot;T_USER_PK&quot; PRIMARY KEY (&quot;F_ID&quot;));COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_DEPT_ID&quot; IS &apos;部门ID&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_NAME&quot; IS &apos;用户名&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_CODE&quot; IS &apos;员工编号&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_SEX&quot; IS &apos;性别&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_MOBILE&quot; IS &apos;手机&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_TELEPHONE&quot; IS &apos;固话&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_EMAIL&quot; IS &apos;邮箱&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_USER&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON TABLE &quot;AUDITTEST&quot;.&quot;T_USER&quot; IS &apos;用户表&apos;;--客户信息表CREATE TABLE &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_CODE&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_FULL_NAME&quot; VARCHAR2(145 BYTE) NOT NULL ENABLE, &quot;F_LINKMAN&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_MOBILE&quot; VARCHAR2(11 BYTE) NOT NULL ENABLE, &quot;F_TELEPHONE&quot; VARCHAR2(20 BYTE), &quot;F_EMAIL&quot; VARCHAR2(60 BYTE), &quot;F_ADDRESS&quot; VARCHAR2(200 BYTE), &quot;F_CITY&quot; VARCHAR2(45 BYTE), &quot;F_BALANCE&quot; NUMBER(10,2) NOT NULL ENABLE, &quot;F_PARTNER&quot; VARCHAR2(45 BYTE), &quot;F_REMARK&quot; VARCHAR2(200 BYTE), &quot;F_SALESMAN&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_DELETED_TAG&quot; NUMBER(1,0) DEFAULT 0 NOT NULL ENABLE, &quot;F_CREATED_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_CREATED_TIME&quot; TIMESTAMP (6) NOT NULL ENABLE, &quot;F_MODIFIED_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_MODIFIED_TIME&quot; TIMESTAMP (6) NOT NULL ENABLE, &quot;F_VERSION&quot; NUMBER(6,0) DEFAULT 1 NOT NULL ENABLE, PRIMARY KEY (&quot;F_ID&quot;));COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_ID&quot; IS &apos;主键&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_CODE&quot; IS &apos;客户编码&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_FULL_NAME&quot; IS &apos;客户全名&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_LINKMAN&quot; IS &apos;联系人&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_MOBILE&quot; IS &apos;联系手机&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_TELEPHONE&quot; IS &apos;联系固话&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_EMAIL&quot; IS &apos;联系邮箱&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_ADDRESS&quot; IS &apos;地址&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_CITY&quot; IS &apos;城市&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_BALANCE&quot; IS &apos;余额&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_PARTNER&quot; IS &apos;所属合作伙伴&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_SALESMAN&quot; IS &apos;业务员&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_DELETED_TAG&quot; IS &apos;删除标志，0：可用，1：已删除&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_CREATED_ID&quot; IS &apos;创建人&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_CREATED_TIME&quot; IS &apos;创建时间&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_MODIFIED_ID&quot; IS &apos;最后修改人&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_MODIFIED_TIME&quot; IS &apos;最后修改时间&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot;.&quot;F_VERSION&quot; IS &apos;版本号&apos;;COMMENT ON TABLE &quot;AUDITTEST&quot;.&quot;T_CUSTOMER&quot; IS &apos;客户信息表&apos;;--CREATE TABLE &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_CODE&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_FULL_NAME&quot; VARCHAR2(145 BYTE) NOT NULL ENABLE, &quot;F_LINKMAN&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_MOBILE&quot; VARCHAR2(11 BYTE) NOT NULL ENABLE, &quot;F_TELEPHONE&quot; VARCHAR2(20 BYTE), &quot;F_EMAIL&quot; VARCHAR2(60 BYTE), &quot;F_ADDRESS&quot; VARCHAR2(200 BYTE), &quot;F_CITY&quot; VARCHAR2(45 BYTE), &quot;F_BALANCE&quot; NUMBER(10,2) NOT NULL ENABLE, &quot;F_PARTNER&quot; VARCHAR2(45 BYTE), &quot;F_REMARK&quot; VARCHAR2(200 BYTE), &quot;F_SALESMAN&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_DELETED_TAG&quot; NUMBER(1,0) DEFAULT 0 NOT NULL ENABLE, &quot;F_CREATED_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_CREATED_TIME&quot; TIMESTAMP (6) NOT NULL ENABLE, &quot;F_MODIFIED_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_MODIFIED_TIME&quot; TIMESTAMP (6) NOT NULL ENABLE, &quot;F_VERSION&quot; NUMBER(6,0) DEFAULT 1 NOT NULL ENABLE, CONSTRAINT &quot;T_CUSTOMER_HISTORY_PK&quot; PRIMARY KEY (&quot;F_ID&quot;, &quot;F_VERSION&quot;));--客户信息历史表COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_ID&quot; IS &apos;主键&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_CODE&quot; IS &apos;客户编码&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_FULL_NAME&quot; IS &apos;客户全名&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_LINKMAN&quot; IS &apos;联系人&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_MOBILE&quot; IS &apos;联系手机&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_TELEPHONE&quot; IS &apos;联系固话&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_EMAIL&quot; IS &apos;联系邮箱&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_ADDRESS&quot; IS &apos;地址&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_CITY&quot; IS &apos;城市&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_BALANCE&quot; IS &apos;余额&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_PARTNER&quot; IS &apos;所属合作伙伴&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_SALESMAN&quot; IS &apos;业务员&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_DELETED_TAG&quot; IS &apos;删除标志，0：可用，1：已删除&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_CREATED_ID&quot; IS &apos;创建人&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_CREATED_TIME&quot; IS &apos;创建时间&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_MODIFIED_ID&quot; IS &apos;最后修改人&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_MODIFIED_TIME&quot; IS &apos;最后修改时间&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot;.&quot;F_VERSION&quot; IS &apos;版本号&apos;;COMMENT ON TABLE &quot;AUDITTEST&quot;.&quot;T_CUSTOMER_HISTORY&quot; IS &apos;客户信息历史表&apos;;--审计表CREATE TABLE &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_TABLE_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_ROW_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NEW_VERSION&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_COLUMN_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_OLD_VALUE&quot; VARCHAR2(200 BYTE), &quot;F_NEW_VALUE&quot; VARCHAR2(200 BYTE), &quot;F_OPERATOR_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_OPERATION_TIME&quot; TIMESTAMP (6) NOT NULL ENABLE, CONSTRAINT &quot;T_AUDIT_PK&quot; PRIMARY KEY (&quot;F_ID&quot;));COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_ID&quot; IS &apos;主键&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_TABLE_NAME&quot; IS &apos;表名&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_ROW_ID&quot; IS &apos;业务数据主键&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_NEW_VERSION&quot; IS &apos;新的版本号&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_COLUMN_NAME&quot; IS &apos;字段&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_OLD_VALUE&quot; IS &apos;原值&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_NEW_VALUE&quot; IS &apos;新值&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_OPERATOR_ID&quot; IS &apos;操作用户&apos;;COMMENT ON COLUMN &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot;.&quot;F_OPERATION_TIME&quot; IS &apos;操作时间&apos;;COMMENT ON TABLE &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot; IS &apos;审计表&apos;; 创建索引、序列-- 创建复合索引CREATE INDEX &quot;AUDITTEST&quot;.&quot;IDX_TABLE_ROWID&quot; ON &quot;AUDITTEST&quot;.&quot;T_AUDIT&quot; (&quot;F_TABLE_NAME&quot;, &quot;F_ROW_ID&quot;) ;-- 创建序列CREATE SEQUENCE SEQ_AUDIT_PK INCREMENT BY 1 START WITH 1; 创建触发器--创建触发器create or replace trigger trg_customer_auditbefore update on t_customerfor each rowdeclare c_insert_sql constant varchar2(100) := &apos;insert into t_audit values(:1,:2,:3,:4,:5,:6,:7,:8,systimestamp)&apos;; c_table_name constant varchar2(20) := &apos;T_CUSTOMER&apos;; v_column_name varchar2(20);begin --记录当前数据到历史表 insert into t_customer_history values(:old.f_id,:old.f_code,:old.f_full_name,:old.f_linkman,:old.f_mobile,:old.f_telephone,:old.f_email,:old.f_address,:old.f_city,:old.f_balance,:old.f_partner,:old.f_remark,:old.f_salesman,:old.f_deleted_tag,:old.f_created_id,:old.f_created_time,:old.f_modified_id,:old.f_modified_time,:old.f_version); --递增记录的版本号 :new.f_version := :old.f_version+1; --判断字段变化 if updating(&apos;F_LINKMAN&apos;) then v_column_name := &apos;联系人&apos;; execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_linkman,:new.f_linkman,:new.f_modified_id; end if; if updating(&apos;F_MOBILE&apos;) then v_column_name := &apos;手机号码&apos;; execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_mobile,:new.f_mobile,:new.f_modified_id; end if; if updating(&apos;F_TELEPHONE&apos;) then v_column_name := &apos;固定电话&apos;; execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_telephone,:new.f_telephone,:new.f_modified_id; end if; if updating(&apos;F_EMAIL&apos;) then v_column_name := &apos;电子邮箱&apos;; execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_email,:new.f_email,:new.f_modified_id; end if; if updating(&apos;F_ADDRESS&apos;) then v_column_name := &apos;联系地址&apos;; execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_address,:new.f_address,:new.f_modified_id; end if; if updating(&apos;F_BALANCE&apos;) then v_column_name := &apos;余额&apos;; execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_balance,:new.f_balance,:new.f_modified_id; end if;end;/--创建过程--过程：重设序列值create or replace PROCEDURE reset_seq( seq_name IN VARCHAR2 )IS v_val NUMBER;BEGIN EXECUTE IMMEDIATE &apos;SELECT &apos; || seq_name || &apos;.NEXTVAL FROM dual&apos; INTO v_val; EXECUTE IMMEDIATE &apos;ALTER SEQUENCE &apos; || seq_name || &apos; INCREMENT BY -&apos; || v_val ||&apos; MINVALUE 0&apos;; EXECUTE IMMEDIATE &apos;SELECT &apos; || seq_name || &apos;.NEXTVAL FROM dual&apos; INTO v_val; EXECUTE IMMEDIATE &apos;ALTER SEQUENCE &apos; || seq_name || &apos; INCREMENT BY 1 MINVALUE 0&apos;;end;/ 创建过程过程reset_seq 将序列为输入参数seq_name的值重置 --过程：重设序列值create or replace PROCEDURE reset_seq( seq_name IN VARCHAR2 )IS v_val NUMBER;BEGIN EXECUTE IMMEDIATE &apos;SELECT &apos; || seq_name || &apos;.NEXTVAL FROM dual&apos; INTO v_val; EXECUTE IMMEDIATE &apos;ALTER SEQUENCE &apos; || seq_name || &apos; INCREMENT BY -&apos; || v_val ||&apos; MINVALUE 0&apos;; EXECUTE IMMEDIATE &apos;SELECT &apos; || seq_name || &apos;.NEXTVAL FROM dual&apos; INTO v_val; EXECUTE IMMEDIATE &apos;ALTER SEQUENCE &apos; || seq_name || &apos; INCREMENT BY 1 MINVALUE 0&apos;;end;/ 过程init truncate(截断)所有表，重设序列，并添加初始值 注意： truncate与delete的区别：delete通常用于删除表中的某些行或者所有行，且delete支持回滚，删除掉的记录的物理空间在commit前并不会被回收。truncate只能删除表的所有行且不支持回滚，删除掉的记录的物理空间也会被立刻回收。 truncate的好处在于当需要删除所有行它比delete要快，尤其在包含大量触发器、索引和其他依赖项的情况下；且它不会改变表结构、表依赖等关系，这一特性又使得它比重建表更有效，删除和重建表会使得表的依赖关系断开，因此需要重新创建依赖、创建约束、赋予权限等等操作。 但是truncate也有不好的地方，比如说当被truncate的表被依赖时，举例： &gt; -- 创建表，f_id字段引用T_TEST的主码id&gt; drop table T_TEST2;&gt; create table T_TEST2(&gt; id1 int primary key ,&gt; f_id int,&gt; constraint fk&gt; foreign key (f_id)&gt; references T_TEST(id) on delete cascade&gt; );&gt; select *&gt; from T_TEST2;&gt; insert into T_TEST2 values(1, 1);&gt; -- 可级联删除&gt; delete from T_TEST;&gt; -- 将外码置为禁用&gt; alter table T_TEST2 modify constraint fk disable validate ;&gt; -- 可截断（当不禁用外码时无法截断）&gt; truncate table T_TEST;&gt; 可见，可通过禁用约束来完成truncate，但是这些主外键约束应是创建数据库时的我们定义的强制关系，上述方法可能会使得这种强制关系紊乱，因此需做好取舍决策。 --过程：数据初始化create or replace procedure init isbegin --清除数据 execute immediate &apos;truncate table t_audit&apos;; execute immediate &apos;truncate table t_customer_history&apos;; execute immediate &apos;truncate table t_customer&apos;; execute immediate &apos;truncate table t_user&apos;; execute immediate &apos;truncate table t_department&apos;; --重调序列 reset_seq(&apos;seq_audit_pk&apos;); --插入部门 insert into t_department values(1,&apos;销售部&apos;,&apos;D01&apos;,NULL,&apos;李明&apos;,&apos;备注1...&apos;); insert into t_department values(2,&apos;销售部-北京分部&apos;,&apos;D0101&apos;,1,&apos;赵军&apos;,&apos;备注2...&apos;); insert into t_department values(3,&apos;销售部-上海分部&apos;,&apos;D0102&apos;,1,&apos;张华&apos;,&apos;备注3...&apos;); insert into t_department values(4,&apos;销售部-深圳分部&apos;,&apos;D0103&apos;,1,&apos;王兵&apos;,&apos;备注4...&apos;); --插入用户 insert into t_user values(1,1,&apos;仲芳芳&apos;,&apos;U8201&apos;,&apos;女&apos;,&apos;13771234101&apos;,&apos;02131231011&apos;,&apos;use1@samtech.com&apos;,&apos;备注1...&apos;); insert into t_user values(2,1,&apos;李明申&apos;,&apos;U8202&apos;,&apos;男&apos;,&apos;13771234102&apos;,&apos;02131231012&apos;,&apos;use2@samtech.com&apos;,&apos;备注2...&apos;); insert into t_user values(3,2,&apos;张雪&apos;, &apos;U8203&apos;,&apos;女&apos;,&apos;13771234103&apos;,&apos;02131231013&apos;,&apos;use3@samtech.com&apos;,&apos;备注3...&apos;); insert into t_user values(4,2,&apos;王刚&apos;, &apos;U8204&apos;,&apos;男&apos;,&apos;13771234104&apos;,&apos;02131231014&apos;,&apos;use4@samtech.com&apos;,&apos;备注4...&apos;); insert into t_user values(5,3,&apos;赵昌日&apos;,&apos;U8205&apos;,&apos;男&apos;,&apos;13771234105&apos;,&apos;02131231015&apos;,&apos;use5@samtech.com&apos;,&apos;备注5...&apos;); insert into t_user values(6,3,&apos;孙晓华&apos;,&apos;U8206&apos;,&apos;男&apos;,&apos;13771234106&apos;,&apos;02131231016&apos;,&apos;use6@samtech.com&apos;,&apos;备注6...&apos;); insert into t_user values(7,4,&apos;陈亚男&apos;,&apos;U8207&apos;,&apos;女&apos;,&apos;13771234107&apos;,&apos;02131231017&apos;,&apos;use7@samtech.com&apos;,&apos;备注7...&apos;); insert into t_user values(8,4,&apos;刘兵超&apos;,&apos;U8208&apos;,&apos;男&apos;,&apos;13771234108&apos;,&apos;02131231018&apos;,&apos;use8@samtech.com&apos;,&apos;备注8...&apos;); --插入客户 insert into t_customer values(1,&apos;C1808001&apos;,&apos;上海市永辉电子股份有限公司&apos;,&apos;张明升&apos;,&apos;15352678121&apos;,&apos;02135681589&apos;,&apos;ming@google.com&apos;,&apos;上海市静安区城区安泰路1108号&apos;,&apos;上海市&apos;,12082,&apos;上海中远&apos;,&apos;备注...&apos;,&apos;张娜&apos;,0,1,sysdate,1,sysdate,1); commit;end;/ 修改客户信息过程--过程：修改客户地址create or replace procedure modify_address(p_row_id in number,p_address in varchar2, p_operator in number)asbegin --校验参数省略 --... execute immediate &apos;update t_customer set f_address=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3&apos; using p_address,p_operator,p_row_id; commit; dbms_output.put_line(&apos;Updated address successfully.&apos;); --异常捕获省略 --...end;/--过程：修改客户余额create or replace procedure modify_balance(p_row_id in number,p_balance in number, p_operator in number)asbegin --校验参数省略 --... execute immediate &apos;update t_customer set f_balance=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3&apos; using p_balance,p_operator,p_row_id; commit; dbms_output.put_line(&apos;Updated balance successfully.&apos;); --异常捕获省略 --...end;/--过程：修改客户电子邮箱create or replace procedure modify_email(p_row_id in number,p_email in varchar2, p_operator in number)asbegin --校验参数省略 --... execute immediate &apos;update t_customer set f_email=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3&apos; using p_email,p_operator,p_row_id; commit; dbms_output.put_line(&apos;Updated email successfully.&apos;); --异常捕获省略 --...end;/--过程：修改客户联系人create or replace procedure modify_linkman(p_row_id in number,p_linkman_name in varchar2, p_operator in number)asbegin --校验参数省略 --... execute immediate &apos;update t_customer set f_linkman=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3&apos; using p_linkman_name,p_operator,p_row_id; commit; dbms_output.put_line(&apos;Updated linkman name successfully.&apos;); --异常捕获省略 --...end;/--过程：修改客户联系人信息create or replace procedure modify_linkman_info(p_row_id in number,p_linkman_name in varchar2,p_mobile in varchar2, p_telephone in varchar2,p_email in varchar2,p_operator in number)asbegin --校验参数省略 --... execute immediate &apos;update t_customer set f_linkman=:1, f_mobile=:2, f_telephone=:3, f_email=:4, f_modified_id=:5, f_modified_time=sysdate where f_id=:6&apos; using p_linkman_name,p_mobile,p_telephone,p_email,p_operator,p_row_id; commit; dbms_output.put_line(&apos;Updated linkman info successfully.&apos;); --异常捕获省略 --...end;/--过程：修改联系手机create or replace procedure modify_mobile(p_row_id in number,p_mobile in varchar2,p_operator in number)asbegin --校验参数省略 --... execute immediate &apos;update t_customer set f_mobile=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3&apos; using p_mobile,p_operator,p_row_id; commit; dbms_output.put_line(&apos;Updated mobile successfully.&apos;); --异常捕获省略 --...end;/--过程：修改联系固话create or replace procedure modify_telephone(p_row_id in number,p_telephone in varchar2,p_operator in number)asbegin --校验参数省略 --... execute immediate &apos;update t_customer set f_telephone=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3&apos; using p_telephone,p_operator,p_row_id; commit; dbms_output.put_line(&apos;Updated mobile successfully.&apos;); --异常捕获省略 --...end;/ 执行-- 初始化call init();-- 更改客户信息begin modify_linkman(1,&apos;李明顺&apos;,1); dbms_lock.sleep(1); modify_mobile(1,&apos;13771083211&apos;,2); dbms_lock.sleep(1); modify_balance(1,20020,3); dbms_lock.sleep(1); modify_address(1,&apos;中国上海市嘉定区xxx路&apos;,4); dbms_lock.sleep(1); modify_email(1,&apos;test1@163.com&apos;,5); dbms_lock.sleep(1); modify_telephone(1,&apos;02183652145&apos;,6); dbms_lock.sleep(1); modify_linkman_info(1,&apos;张雨轩&apos;,&apos;15332892301&apos;,&apos;02188881111&apos;,&apos;zhangyx@gmail.com&apos;,7);end;/-- 审计select * from T_AUDIT;-- 回滚客户信息-- 方法1：update t_customer aset(a.f_full_name,a.f_linkman,a.f_mobile,a.f_telephone,a.f_email,a.f_address,a.f_city,a.f_balance,a.f_partner,a.f_remark,a.f_salesman,a.f_deleted_tag,a.f_modified_id,a.f_modified_time)=(select b.f_full_name,b.f_linkman,b.f_mobile,b.f_telephone,b.f_email,b.f_address,b.f_city,b.f_balance,b.f_partner,b.f_remark,b.f_salesman,b.f_deleted_tag,5,sysdatefrom t_customer_history b where b.f_id=a.f_id and b.f_version=3)where a.f_id=1;-- 方法2：merge into t_customer a using t_customer_history b on (a.f_id=1 and a.f_id=b.f_id and b.f_version=3)when matched thenupdate set a.f_full_name=b.f_full_name,a.f_linkman=b.f_linkman,a.f_mobile=b.f_mobile,a.f_telephone=b.f_telephone,a.f_email=b.f_email,a.f_address=b.f_address,a.f_city=b.f_city,a.f_balance=b.f_balance,a.f_partner=b.f_partner,a.f_remark=b.f_remark,a.f_salesman=b.f_salesman,a.f_deleted_tag=b.f_deleted_tag,a.f_modified_id=5,a.f_modified_time=sysdate;-- 查看验证数据select * from t_customer where f_id=1unionselect * from t_customer_history where f_id=1 and f_version=3; Lesson 3创建用户并分配权限创建用户create user permission identified by permission; 分配权限grant connect,resource to permission;alter user permisson quota unlimited on users;conn permission/permission; 创建表及其他对象方案一 方案一在T_CUSTOMER表中存放创建人员ID，以查询该客户的直接负责人，在T_USER表中存放直属领导的ID，用于查询某领导所有下属的客户。 创建表--方案一--部门表CREATE TABLE T_DEPARTMENT( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_PARENT_ID&quot; NUMBER(6,0), &quot;F_MANAGER_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_REMARK&quot; VARCHAR2(200 BYTE), CONSTRAINT &quot;T_DEPARTMENT_PK&quot; PRIMARY KEY (&quot;F_ID&quot;)) ;COMMENT ON COLUMN &quot;T_DEPARTMENT&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT&quot;.&quot;F_NAME&quot; IS &apos;部门名称&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT&quot;.&quot;F_PARENT_ID&quot; IS &apos;上级部门ID&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT&quot;.&quot;F_MANAGER_ID&quot; IS &apos;部门经理&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON TABLE &quot;T_DEPARTMENT&quot; IS &apos;部门表&apos;;--用户表CREATE TABLE &quot;T_USER&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_DEPT_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_SEX&quot; VARCHAR2(5 BYTE) DEFAULT NULL, &quot;F_MOBILE&quot; VARCHAR2(20 BYTE), &quot;F_EMAIL&quot; VARCHAR2(50 BYTE), &quot;F_REMARK&quot; VARCHAR2(200 BYTE), CONSTRAINT &quot;T_USER_PK&quot; PRIMARY KEY (&quot;F_ID&quot;));COMMENT ON COLUMN &quot;T_USER&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;T_USER&quot;.&quot;F_DEPT_ID&quot; IS &apos;部门ID&apos;;COMMENT ON COLUMN &quot;T_USER&quot;.&quot;F_NAME&quot; IS &apos;用户名&apos;;COMMENT ON COLUMN &quot;T_USER&quot;.&quot;F_SEX&quot; IS &apos;性别&apos;;COMMENT ON COLUMN &quot;T_USER&quot;.&quot;F_MOBILE&quot; IS &apos;手机&apos;;COMMENT ON COLUMN &quot;T_USER&quot;.&quot;F_EMAIL&quot; IS &apos;邮箱&apos;;COMMENT ON COLUMN &quot;T_USER&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON TABLE &quot;T_USER&quot; IS &apos;用户表&apos;;--客户信息表CREATE TABLE &quot;T_CUSTOMER&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(145 BYTE) NOT NULL ENABLE, &quot;F_LINKMAN&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_MOBILE&quot; VARCHAR2(11 BYTE) NOT NULL ENABLE, &quot;F_EMAIL&quot; VARCHAR2(60 BYTE), &quot;F_ADDRESS&quot; VARCHAR2(200 BYTE), &quot;F_REMARK&quot; VARCHAR2(200 BYTE), &quot;F_CREATED_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_CREATED_TIME&quot; TIMESTAMP (6) NOT NULL ENABLE, PRIMARY KEY (&quot;F_ID&quot;));COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_NAME&quot; IS &apos;客户全名&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_LINKMAN&quot; IS &apos;联系人&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_MOBILE&quot; IS &apos;联系手机&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_EMAIL&quot; IS &apos;联系邮箱&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_ADDRESS&quot; IS &apos;地址&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_CREATED_ID&quot; IS &apos;创建人&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER&quot;.&quot;F_CREATED_TIME&quot; IS &apos;创建时间&apos;;COMMENT ON TABLE &quot;T_CUSTOMER&quot; IS &apos;客户信息表&apos;; 创建过程初始化--过程：数据初始化CREATE OR REPLACE PROCEDURE INIT ISBEGIN --清除数据 EXECUTE IMMEDIATE &apos;TRUNCATE TABLE T_CUSTOMER&apos;; EXECUTE IMMEDIATE &apos;TRUNCATE TABLE T_USER&apos;; EXECUTE IMMEDIATE &apos;TRUNCATE TABLE T_DEPARTMENT&apos;; --插入部门 INSERT INTO T_DEPARTMENT VALUES(1,&apos;公司&apos;,NULL,1,&apos;REMARK...&apos;); INSERT INTO T_DEPARTMENT VALUES(2,&apos;行政部&apos;,1,1,&apos;REMARK...&apos;); INSERT INTO T_DEPARTMENT VALUES(3,&apos;销售部&apos;,1,2,&apos;REMARK...&apos;); INSERT INTO T_DEPARTMENT VALUES(4,&apos;电销组&apos;,3,3,&apos;销售部电销组&apos;); INSERT INTO T_DEPARTMENT VALUES(5,&apos;推销组&apos;,3,6,&apos;销售部推销组&apos;); --插入用户 INSERT INTO T_USER VALUES(1,1,&apos;管理员&apos;,&apos;男&apos;,&apos;13771234101&apos;,&apos;USE1@SAMTECH.COM&apos;,&apos;系统管理员&apos;); INSERT INTO T_USER VALUES(2,3,&apos;李明申&apos;,&apos;男&apos;,&apos;13771234102&apos;,&apos;USE2@SAMTECH.COM&apos;,&apos;销售部经理&apos;); INSERT INTO T_USER VALUES(3,4,&apos;张雪&apos;, &apos;女&apos;,&apos;13771234103&apos;,&apos;USE3@SAMTECH.COM&apos;,&apos;销售部电销组主管&apos;); INSERT INTO T_USER VALUES(4,4,&apos;王刚&apos;, &apos;男&apos;,&apos;13771234104&apos;,&apos;USE4@SAMTECH.COM&apos;,&apos;销售部电销组业务员1&apos;); INSERT INTO T_USER VALUES(5,4,&apos;赵昌日&apos;,&apos;男&apos;,&apos;13771234105&apos;,&apos;USE5@SAMTECH.COM&apos;,&apos;销售部电销组业务员2&apos;); INSERT INTO T_USER VALUES(6,5,&apos;孙晓华&apos;,&apos;男&apos;,&apos;13771234106&apos;,&apos;USE6@SAMTECH.COM&apos;,&apos;销售部推销组主管&apos;); INSERT INTO T_USER VALUES(7,5,&apos;陈亚男&apos;,&apos;女&apos;,&apos;13771234107&apos;,&apos;USE7@SAMTECH.COM&apos;,&apos;销售部推销组业务员3&apos;); INSERT INTO T_USER VALUES(8,5,&apos;刘兵超&apos;,&apos;男&apos;,&apos;13771234108&apos;,&apos;USE8@SAMTECH.COM&apos;,&apos;销售部推销组业务员4&apos;); INSERT INTO T_USER VALUES(9,3,&apos;陈彬&apos;,&apos;女&apos;,&apos;13771234109&apos;,&apos;USE9@SAMTECH.COM&apos;,&apos;销售部业务员X1&apos;); INSERT INTO T_USER VALUES(10,3,&apos;王军&apos;,&apos;男&apos;,&apos;13771234110&apos;,&apos;USE10@SAMTECH.COM&apos;,&apos;销售部业务员X2&apos;); --插入客户 INSERT INTO T_CUSTOMER VALUES(1,&apos;上海市永辉电子股份有限公司&apos; ,&apos;张明升&apos;,&apos;15352678121&apos;,&apos;MING1@GOOGLE.COM&apos;,&apos;上海市静安区城区安泰路1108号&apos;,&apos;电销组主管创建&apos;,3,SYSDATE); INSERT INTO T_CUSTOMER VALUES(2,&apos;上海博运汽车销售有限公司&apos; ,&apos;朱荣荣&apos; ,&apos;13231289212&apos;,&apos;MING2@GOOGLE.COM&apos;,&apos;上海市徐汇区钦江路256号&apos;,&apos;电销组业务员1创建&apos;,4,SYSDATE); INSERT INTO T_CUSTOMER VALUES(3,&apos;安徽广宏顶管装备制造有限公司&apos; ,&apos;邱阳阳&apos; ,&apos;15328921231&apos;,&apos;MING3@GOOGLE.COM&apos;,&apos;安徽省广德县经济开发区东纬路5号&apos;,&apos;电销组业务员2创建&apos;,5,SYSDATE); INSERT INTO T_CUSTOMER VALUES(4,&apos;上海定丰霖贸易有限公司&apos; ,&apos;赵兰&apos; ,&apos;15532212322&apos;,&apos;MING4@GOOGLE.COM&apos;,&apos;上海市浦东新区东延路112号408室&apos;,&apos;推销组主管创建&apos;,6,SYSDATE); INSERT INTO T_CUSTOMER VALUES(5,&apos;上海东俊科技有限公司&apos; ,&apos;张军&apos; ,&apos;15367823660&apos;,&apos;MING5@GOOGLE.COM&apos;,&apos;上海市长宁区王安路135号&apos;,&apos;推销组业务员1创建&apos;,7,SYSDATE); INSERT INTO T_CUSTOMER VALUES(6,&apos;中科创客（深圳）智能工业设备公司&apos;,&apos;李明&apos; ,&apos;17723180234&apos;,&apos;MING6@GOOGLE.COM&apos;,&apos;深圳市龙岗区富民工业园致康路301号&apos;,&apos;推销组业务员2创建&apos;,8,SYSDATE); INSERT INTO T_CUSTOMER VALUES(7,&apos;南宁云讯科技有限公司&apos; ,&apos;王永成&apos;,&apos;13568932166&apos;,&apos;MING7@GOOGLE.COM&apos;,&apos;广东省深圳市福田区长川路102号&apos;,&apos;销售部业务员X1创建&apos;,9,SYSDATE); INSERT INTO T_CUSTOMER VALUES(8,&apos;沈阳优速家政服务有限公司&apos; ,&apos;李东升&apos;,&apos;13392312343&apos;,&apos;MING8@GOOGLE.COM&apos;,&apos;辽宁省沈阳市铁西区北二路青年易居东门32号&apos;,&apos;销售部业务员X2创建&apos;,10,SYSDATE); COMMIT;END;/ 执行初始化set serveroutput on;exec init; 查询自己的客户SELECT * FROM t_customer A WHERE A.f_created_id=&amp;id; &amp;id是所查询人员的ID 查询某领导下属人员的所有客户select * from t_user a where exists(SELECT 1 FROM t_department bWHERE a.f_dept_id=b.f_id and b.f_manager_id=&amp;idCONNECT BY b.F_PARENT_ID = PRIOR b.F_IDstart with b.F_ID = (select c.f_dept_id from t_user c where c.f_id=&amp;id)); &amp;id是该领导的ID 当部门结构或员工归属调整时，权限编码如何处理？对于方案一，只需要更改员工直属领导ID即可 方案二 方案二取消在T_USER中添加直属领导ID，改为在员工、部门、客户表中添加权限码，查看时直接搜索对应权限码即可 创建表--方案二--部门表CREATE TABLE T_DEPARTMENT_2( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_CODE&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_PARENT_ID&quot; NUMBER(6,0), &quot;F_MANAGER_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_REMARK&quot; VARCHAR2(200 BYTE), CONSTRAINT &quot;T_DEPARTMENT_PK2&quot; PRIMARY KEY (&quot;F_ID&quot;)) ;COMMENT ON COLUMN &quot;T_DEPARTMENT_2&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT_2&quot;.&quot;F_NAME&quot; IS &apos;部门名称&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT_2&quot;.&quot;F_CODE&quot; IS &apos;部门编码&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT_2&quot;.&quot;F_PARENT_ID&quot; IS &apos;上级部门ID&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT_2&quot;.&quot;F_MANAGER_ID&quot; IS &apos;部门经理&apos;;COMMENT ON COLUMN &quot;T_DEPARTMENT_2&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON TABLE &quot;T_DEPARTMENT_2&quot; IS &apos;部门表2&apos;;--用户表CREATE TABLE &quot;T_USER_2&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_DEPT_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_CODE&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_SEX&quot; VARCHAR2(5 BYTE) DEFAULT NULL, &quot;F_MOBILE&quot; VARCHAR2(20 BYTE), &quot;F_EMAIL&quot; VARCHAR2(50 BYTE), &quot;F_REMARK&quot; VARCHAR2(200 BYTE), CONSTRAINT &quot;T_USER_PK2&quot; PRIMARY KEY (&quot;F_ID&quot;));COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_DEPT_ID&quot; IS &apos;部门ID&apos;;COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_NAME&quot; IS &apos;用户名&apos;;COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_CODE&quot; IS &apos;用户编码&apos;;COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_SEX&quot; IS &apos;性别&apos;;COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_MOBILE&quot; IS &apos;手机&apos;;COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_EMAIL&quot; IS &apos;邮箱&apos;;COMMENT ON COLUMN &quot;T_USER_2&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON TABLE &quot;T_USER_2&quot; IS &apos;用户表2&apos;;--客户信息表CREATE TABLE &quot;T_CUSTOMER_2&quot;( &quot;F_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_NAME&quot; VARCHAR2(145 BYTE) NOT NULL ENABLE, &quot;F_LINKMAN&quot; VARCHAR2(45 BYTE) NOT NULL ENABLE, &quot;F_MOBILE&quot; VARCHAR2(11 BYTE) NOT NULL ENABLE, &quot;F_EMAIL&quot; VARCHAR2(60 BYTE), &quot;F_ADDRESS&quot; VARCHAR2(200 BYTE), &quot;F_REMARK&quot; VARCHAR2(200 BYTE), &quot;F_ACCESS_CODE&quot; VARCHAR2(50 BYTE) NOT NULL ENABLE, &quot;F_CREATED_ID&quot; NUMBER(6,0) NOT NULL ENABLE, &quot;F_CREATED_TIME&quot; TIMESTAMP (6) NOT NULL ENABLE, PRIMARY KEY (&quot;F_ID&quot;));COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_ID&quot; IS &apos;PK&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_NAME&quot; IS &apos;客户全名&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_LINKMAN&quot; IS &apos;联系人&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_MOBILE&quot; IS &apos;联系手机&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_EMAIL&quot; IS &apos;联系邮箱&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_ADDRESS&quot; IS &apos;地址&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_REMARK&quot; IS &apos;备注信息&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_ACCESS_CODE&quot; IS &apos;权限编码&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_CREATED_ID&quot; IS &apos;创建人&apos;;COMMENT ON COLUMN &quot;T_CUSTOMER_2&quot;.&quot;F_CREATED_TIME&quot; IS &apos;创建时间&apos;;COMMENT ON TABLE &quot;T_CUSTOMER_2&quot; IS &apos;客户信息表2&apos;;-- 创建人员更改历史表CREATE TABLE T_USER_HISTORY( ID NUMBER(6,0) PRIMARY KEY , F_ID NUMBER(6,0) , O_DEP_ID NUMBER(6,0) , O_ACCESS_CODE VARCHAR2(50 BYTE) , N_DEP_ID NUMBER(6,0), N_ACCESS_CODE VARCHAR2(50 BYTE), TIME DATE);COMMENT ON COLUMN T_USER_HISTORY.ID IS &apos;PK&apos;;COMMENT ON COLUMN T_USER_HISTORY.F_ID IS &apos;修改的人员ID&apos;;COMMENT ON COLUMN T_USER_HISTORY.O_DEP_ID IS &apos;旧的部门&apos;;COMMENT ON COLUMN T_USER_HISTORY.O_ACCESS_CODE IS &apos;旧的权限&apos;;COMMENT ON COLUMN T_USER_HISTORY.N_DEP_ID IS &apos;新的部门&apos;;COMMENT ON COLUMN T_USER_HISTORY.N_ACCESS_CODE IS &apos;新的权限&apos;;COMMENT ON TABLE T_USER_HISTORY IS &apos;用户权限更改历史&apos;; 创建过程初始化--过程：数据初始化CREATE OR REPLACE PROCEDURE INIT2 ISBEGIN --清除数据 EXECUTE IMMEDIATE &apos;TRUNCATE TABLE T_CUSTOMER_2&apos;; EXECUTE IMMEDIATE &apos;TRUNCATE TABLE T_USER_2&apos;; EXECUTE IMMEDIATE &apos;TRUNCATE TABLE T_DEPARTMENT_2&apos;; EXECUTE IMMEDIATE &apos;TRUNCATE TABLE T_USER_HISTORY&apos;; --插入部门 INSERT INTO T_DEPARTMENT_2 VALUES(1,&apos;公司&apos;,&apos;1&apos;,NULL,1,&apos;REMARK...&apos;); INSERT INTO T_DEPARTMENT_2 VALUES(2,&apos;行政部&apos;,&apos;101&apos;,1,1,&apos;REMARK...&apos;); INSERT INTO T_DEPARTMENT_2 VALUES(3,&apos;销售部&apos;,&apos;102&apos;,1,2,&apos;REMARK...&apos;); INSERT INTO T_DEPARTMENT_2 VALUES(4,&apos;电销组&apos;,&apos;10201&apos;,3,3,&apos;销售部电销组&apos;); INSERT INTO T_DEPARTMENT_2 VALUES(5,&apos;推销组&apos;,&apos;10202&apos;,3,6,&apos;销售部推销组&apos;); --插入用户 INSERT INTO T_USER_2 VALUES(1,1,&apos;管理员&apos;,&apos;1&apos;,&apos;男&apos;,&apos;13771234101&apos;,&apos;USE1@SAMTECH.COM&apos;,&apos;系统管理员&apos;); INSERT INTO T_USER_2 VALUES(2,3,&apos;李明申&apos;,&apos;102&apos;,&apos;男&apos;,&apos;13771234102&apos;,&apos;USE2@SAMTECH.COM&apos;,&apos;销售部经理&apos;); INSERT INTO T_USER_2 VALUES(3,4,&apos;张雪&apos;, &apos;10201&apos;, &apos;女&apos;,&apos;13771234103&apos;,&apos;USE3@SAMTECH.COM&apos;,&apos;销售部电销组主管&apos;); INSERT INTO T_USER_2 VALUES(4,4,&apos;王刚&apos;, &apos;1020101&apos;, &apos;男&apos;,&apos;13771234104&apos;,&apos;USE4@SAMTECH.COM&apos;,&apos;销售部电销组业务员1&apos;); INSERT INTO T_USER_2 VALUES(5,4,&apos;赵昌日&apos;,&apos;1020102&apos;,&apos;男&apos;,&apos;13771234105&apos;,&apos;USE5@SAMTECH.COM&apos;,&apos;销售部电销组业务员2&apos;); INSERT INTO T_USER_2 VALUES(6,5,&apos;孙晓华&apos;,&apos;10202&apos;,&apos;男&apos;,&apos;13771234106&apos;,&apos;USE6@SAMTECH.COM&apos;,&apos;销售部推销组主管&apos;); INSERT INTO T_USER_2 VALUES(7,5,&apos;陈亚男&apos;,&apos;1020201&apos;,&apos;女&apos;,&apos;13771234107&apos;,&apos;USE7@SAMTECH.COM&apos;,&apos;销售部推销组业务员3&apos;); INSERT INTO T_USER_2 VALUES(8,5,&apos;刘兵超&apos;,&apos;1020202&apos;,&apos;男&apos;,&apos;13771234108&apos;,&apos;USE8@SAMTECH.COM&apos;,&apos;销售部推销组业务员4&apos;); INSERT INTO T_USER_2 VALUES(9,3,&apos;陈彬&apos;, &apos;10203&apos;,&apos;女&apos;,&apos;13771234109&apos;,&apos;USE9@SAMTECH.COM&apos;,&apos;销售部业务员X1&apos;); INSERT INTO T_USER_2 VALUES(10,3,&apos;王军&apos;, &apos;10204&apos;,&apos;男&apos;,&apos;13771234110&apos;,&apos;USE10@SAMTECH.COM&apos;,&apos;销售部业务员X2&apos;); --插入客户 INSERT INTO T_CUSTOMER_2 VALUES(1,&apos;上海市永辉电子股份有限公司&apos; ,&apos;张明升&apos;,&apos;15352678121&apos;,&apos;MING1@GOOGLE.COM&apos;,&apos;上海市静安区城区安泰路1108号&apos;,&apos;电销组主管创建&apos;,&apos;10201&apos;,3,SYSDATE); INSERT INTO T_CUSTOMER_2 VALUES(2,&apos;上海博运汽车销售有限公司&apos; ,&apos;朱荣荣&apos; ,&apos;13231289212&apos;,&apos;MING2@GOOGLE.COM&apos;,&apos;上海市徐汇区钦江路256号&apos;,&apos;电销组业务员1创建&apos;,&apos;1020101&apos;,4,SYSDATE); INSERT INTO T_CUSTOMER_2 VALUES(3,&apos;安徽广宏顶管装备制造有限公司&apos; ,&apos;邱阳阳&apos; ,&apos;15328921231&apos;,&apos;MING3@GOOGLE.COM&apos;,&apos;安徽省广德县经济开发区东纬路5号&apos;,&apos;电销组业务员2创建&apos;,&apos;1020102&apos;,5,SYSDATE); INSERT INTO T_CUSTOMER_2 VALUES(4,&apos;上海定丰霖贸易有限公司&apos; ,&apos;赵兰&apos; ,&apos;15532212322&apos;,&apos;MING4@GOOGLE.COM&apos;,&apos;上海市浦东新区东延路112号408室&apos;,&apos;推销组主管创建&apos;,&apos;10202&apos;,6,SYSDATE); INSERT INTO T_CUSTOMER_2 VALUES(5,&apos;上海东俊科技有限公司&apos; ,&apos;张军&apos; ,&apos;15367823660&apos;,&apos;MING5@GOOGLE.COM&apos;,&apos;上海市长宁区王安路135号&apos;,&apos;推销组业务员1创建&apos;,&apos;1020201&apos;,7,SYSDATE); INSERT INTO T_CUSTOMER_2 VALUES(6,&apos;中科创客（深圳）智能工业设备公司&apos;,&apos;李明&apos; ,&apos;17723180234&apos;,&apos;MING6@GOOGLE.COM&apos;,&apos;深圳市龙岗区富民工业园致康路301号&apos;,&apos;推销组业务员2创建&apos;,&apos;1020202&apos;,8,SYSDATE); INSERT INTO T_CUSTOMER_2 VALUES(7,&apos;南宁云讯科技有限公司&apos; ,&apos;王永成&apos;,&apos;13568932166&apos;,&apos;MING7@GOOGLE.COM&apos;,&apos;广东省深圳市福田区长川路102号&apos;,&apos;销售部业务员X1创建&apos;,&apos;10203&apos;,9,SYSDATE); INSERT INTO T_CUSTOMER_2 VALUES(8,&apos;沈阳优速家政服务有限公司&apos; ,&apos;李东升&apos;,&apos;13392312343&apos;,&apos;MING8@GOOGLE.COM&apos;,&apos;辽宁省沈阳市铁西区北二路青年易居东门32号&apos;,&apos;销售部业务员X2创建&apos;,&apos;10204&apos;,10,SYSDATE); COMMIT;END;/ 将某员工调换到某部门 -- 更改用户到特定部门CREATE OR REPLACE PROCEDURE CHANGE_TO_DEPARTMENT(C_F_ID IN T_USER_2.F_ID%TYPE, N_DEP_ID IN T_DEPARTMENT_2.F_ID%TYPE) IS -- 旧部门 O_DEP_ID T_DEPARTMENT_2.F_ID%TYPE; -- 旧权限 O_ACCESS_CODE T_USER_2.F_CODE%TYPE; -- 部门权限前缀 DEP_ACCESS_CODE_PREFIX T_DEPARTMENT_2.F_CODE%TYPE; -- 部门当前人数 DEP_USER_COUNT T_USER_2.F_CODE%TYPE; -- 本部门下的部门数 DEP_DEP_COUNT T_DEPARTMENT_2.F_CODE%TYPE; -- 新权限 N_ACCESS_CODE T_USER_2.F_CODE%TYPE; -- 更新该员工权限 C_UPDATE_USER VARCHAR2(100) := &apos;UPDATE T_USER_2 SET F_CODE = :1, F_DEPT_ID = :2 WHERE F_ID = :3&apos;; -- 更新所有该员工的客户的ACCESS权限 C_UPDATE_CUSTOMER VARCHAR2(100) := &apos;UPDATE T_CUSTOMER_2 SET F_ACCESS_CODE = :1 WHERE F_CREATED_ID = :2&apos;; -- 插入一条修改记录 C_INSERT_HISTORY VARCHAR2(100) := &apos;INSERT INTO T_USER_HISTORY VALUES (:1, :2, :3, :4, :5, :6, :7)&apos;; BEGIN -- 旧部门 SELECT F_DEPT_ID INTO O_DEP_ID FROM T_USER_2 WHERE T_USER_2.F_ID=C_F_ID; -- 旧权限 SELECT F_CODE INTO O_ACCESS_CODE FROM T_USER_2 WHERE T_USER_2.F_ID=C_F_ID; -- 新部门权限作为前缀 SELECT F_CODE INTO DEP_ACCESS_CODE_PREFIX FROM T_DEPARTMENT_2 WHERE T_DEPARTMENT_2.F_ID = N_DEP_ID; -- 计算该部门人员数量 SELECT MAX(T_USER_2.F_CODE) INTO DEP_USER_COUNT FROM T_USER_2 WHERE T_USER_2.F_DEPT_ID = N_DEP_ID; -- 计算子部门数量 SELECT MAX(T_DEPARTMENT_2.F_CODE) INTO DEP_DEP_COUNT FROM T_DEPARTMENT_2 WHERE SUBSTR(T_DEPARTMENT_2.F_CODE, 0, LENGTH(DEP_ACCESS_CODE_PREFIX))=DEP_ACCESS_CODE_PREFIX AND LENGTH(T_DEPARTMENT_2.F_CODE)=LENGTH(DEP_ACCESS_CODE_PREFIX)+2; -- 若新部门与旧部门相同，无需更改 IF N_DEP_ID=O_DEP_ID THEN RETURN; END IF; -- 新权限CODE IF DEP_DEP_COUNT &gt; DEP_USER_COUNT THEN N_ACCESS_CODE := TO_CHAR(TO_NUMBER(DEP_DEP_COUNT) + 1); ELSE N_ACCESS_CODE := TO_CHAR(TO_NUMBER(DEP_USER_COUNT) + 1); end if; -- 输出相关变量 dbms_output.put_line(&apos;DEP_USER_COUNT : &apos; || DEP_USER_COUNT); dbms_output.put_line(&apos;DEP_DEP_COUNT : &apos; || DEP_DEP_COUNT); -- 输出相关变量 dbms_output.put_line(&apos;DEP_ACCESS_CODE_PREFIX : &apos; || DEP_ACCESS_CODE_PREFIX); dbms_output.put_line(&apos;C_F_ID : &apos; || C_F_ID); dbms_output.put_line(&apos;O_ACCESS_CODE : &apos; || O_ACCESS_CODE); dbms_output.put_line(&apos;N_DEP_ID : &apos; || N_DEP_ID); dbms_output.put_line(&apos;N_ACCESS_CODE : &apos; || N_ACCESS_CODE); -- 更新该员工权限 EXECUTE IMMEDIATE C_UPDATE_USER USING N_ACCESS_CODE, N_DEP_ID, C_F_ID; -- 更新所有该员工的客户的ACCESS权限 EXECUTE IMMEDIATE C_UPDATE_CUSTOMER USING N_ACCESS_CODE, C_F_ID; -- 插入一条修改记录 EXECUTE IMMEDIATE C_INSERT_HISTORY USING USER_HISTORY.NEXTVAL, C_F_ID, O_DEP_ID, O_ACCESS_CODE, N_DEP_ID, N_ACCESS_CODE, SYSDATE; -- 提交 COMMIT; END; / 创建序列-- 员工部门历史记录主码序列CREATE SEQUENCE USER_HISTORY INCREMENT BY 1 START WITH 1; 执行select * from t_customer_2 where f_access_code like &apos;xxx%&apos;; xxx%指匹配所有以xxx开头的权限码 当部门结构或员工归属调整时，权限编码如何处理？方案二中，调用新增的过程CHANGE_TO_DEPARTMENT即可级联更改权限码。","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"TimesTen","slug":"TimesTen","permalink":"http://blog.guitoubing.top/tags/TimesTen/"},{"name":"内存数据库","slug":"内存数据库","permalink":"http://blog.guitoubing.top/tags/内存数据库/"}]},{"title":"感谢Docker,让我远离环境配置","slug":"使用Docker安装Oracle-12c","date":"2018-11-12T15:26:45.000Z","updated":"2018-11-25T14:17:59.444Z","comments":true,"path":"2018/11/12/使用Docker安装Oracle-12c/","link":"","permalink":"http://blog.guitoubing.top/2018/11/12/使用Docker安装Oracle-12c/","excerpt":"Why Docker自开始用Oracle以来，环境配置一直是让我掉头发的事。而如今也只是在Windows上的安装界面点点点成功安装了Oracle，Linux上就从来没成功过，Mac的话Oracle 11g后好像就没Mac版的了，就很头疼。 这学期上了门内存数据库，老师给了个镜像，RedHat+Oracle+TimesTen究极体镜像，扔到VirtualBox上打开直接登录用户名密码，无需安装组件，无需配置环境，即开即用。自由的气息。 偶然间在网上看到了有关于Docker安装oracle的说法，于是便尝试了一下。真的，简洁，优雅，自由，甚至比虚拟机好用多了。","text":"Why Docker自开始用Oracle以来，环境配置一直是让我掉头发的事。而如今也只是在Windows上的安装界面点点点成功安装了Oracle，Linux上就从来没成功过，Mac的话Oracle 11g后好像就没Mac版的了，就很头疼。 这学期上了门内存数据库，老师给了个镜像，RedHat+Oracle+TimesTen究极体镜像，扔到VirtualBox上打开直接登录用户名密码，无需安装组件，无需配置环境，即开即用。自由的气息。 偶然间在网上看到了有关于Docker安装oracle的说法，于是便尝试了一下。真的，简洁，优雅，自由，甚至比虚拟机好用多了。 正题Docker安装并启动Oracle 12c安装# 在docker中寻找oracle镜像，可看到一条sath89/oracle-12c的镜像，便是我们需要安装的docker search oracledocker pull sath89/oracle-12c# 查看已安装的镜像docker images 由于docker使用的是国外源，在拉取时的速度可能很慢，可参见博客切换国内源以加快拉取速度：Docker切换国内镜像下载源 初始化# 使用log记录oracle启动的容器号log=$(sudo docker run -d -p 8080:8080 -p 1521:1521 -v /Users/tanrui/Oracle/oradata:/u01/app/oracle sath89/oracle-12c)# 显示当前容器初始化进程docker logs -f $log# 显示docker中当前运行的容器(可查看到容器ID)sudo docker ps 正常情况下，第一次创建容器应称之为初始化，而以后创建的容器都应基于上次的历史数据，称作容器的数据持久化，在上述命令中-v后的:之前是当前系统想要存储持久性数据的路径，用户想要共享到容器中的文件也可放入其中，:后面是在容器中想要访问当前系统的共享文件的路径。 因此在初始化完成后，若仍然使用上述命令，会提示数据库未初始化，从而会重新创建持久性数据文件；因此以后的容器创建应该使用以下命令^1^： sudo docker run -it -p 8080:8080 -p 1521:1521 -v /Users/tanrui/Oracle/oradata:/u01/app/oracle sath89/oracle-12c 至于上述的重复初始化是会造成文件覆盖还是文件并存我没有尝试过，猜测应该会是覆盖。 同时，重复执行命令^1^时，还会产生端口冲突。因此如果想创建两个Oracle容器应该执行初始化命令，执行时将持久化数据路径更改到其他地方且需将端口号修改掉。 进入容器# 进入特定的容器，$&#123;ContainerID&#125;为上述查看到的容器ID# env LANG=C.UTF-8 表示当前容器使用支持中文的UTF-8格式(默认为POSIX，不支持中文)sudo docker exec -it $&#123;ContainerID&#125; env LANG=C.UTF-8 /bin/bash 连接oracle数据库root@1386ef844664:/# su oracleoracle@1386ef844664:/$ cd $ORACLE_HOMEoracle@1386ef844664:/u01/app/oracle/product/12.1.0/xe$ bin/sqlplus / as sysdba Oracle数据库设置字符集## 查看数据库编码，结果最下面一行则是目前编码SQL&gt; select * from nls_database_parameters where parameter ='NLS_CHARACTERSET'; ## 关闭数据库SQL&gt; shutdown immediate; ## 启动到 mount状态，oracle分为4个状态，详情请百度SQL&gt; startup mount; ## 设置session ，下同SQL&gt; ALTER SYSTEM ENABLE RESTRICTED SESSION; SQL&gt; ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;SQL&gt; ALTER SYSTEM SET AQ_TM_PROCESSES=0;## 打开oracle到 open状态SQL&gt; alter database open; ## 修改编码为 ZHS16GBKSQL&gt; ALTER DATABASE character set INTERNAL_USE ZHS16GBK; ## 重启oracle ，先关闭，再启动SQL&gt; shutdown immediate; SQL&gt; startup; 升华Docker真的好用！（俗","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.guitoubing.top/tags/Docker/"},{"name":"Oracle","slug":"Oracle","permalink":"http://blog.guitoubing.top/tags/Oracle/"}]},{"title":"记一次Win10+Fedora双系统的小折腾","slug":"记一次Win10-Fedora双系统的小折腾","date":"2018-11-06T13:21:10.000Z","updated":"2019-02-26T05:48:31.567Z","comments":true,"path":"2018/11/06/记一次Win10-Fedora双系统的小折腾/","link":"","permalink":"http://blog.guitoubing.top/2018/11/06/记一次Win10-Fedora双系统的小折腾/","excerpt":"问题描述因课程需要，我在Win10上安装了Fedora双系统，结果出现了奇怪的问题，现Fedora系统可正常进入，Win10也有引导项，但无法进入Win10系统，报错信息见图。我在Google上搜了类似的问题，大多是诸如以下的原因：","text":"问题描述因课程需要，我在Win10上安装了Fedora双系统，结果出现了奇怪的问题，现Fedora系统可正常进入，Win10也有引导项，但无法进入Win10系统，报错信息见图。我在Google上搜了类似的问题，大多是诸如以下的原因： 主板供电不足（我使用的是台式机应该不会有这个问题） BIOS中系统时间不正确（我也未曾修改过该时间） 这些原因可能会造成与我类似的状况，但很显然这些都不是此处的问题所在 问题出现的环境背景及自己尝试过哪些方法系统相关信息：主系统Windows10专业版（安装在100G的SSD中），Fedora29（安装在由1T的HHD分出的50G硬盘中） 尝试过得方法： 曾使用PE系统中的引导修复工具修复Win10引导，无果 在Fedora中安装了grub工具尝试修复Win10引导，grub是用来配置启动时引导的系统，而我这里启动后切换到grub界面是有Win10引导的，因此问题应该不是出在这儿，而是出在Win10的引导文件\\Windows\\System32\\winload.efi上，感觉此方法应该是行不通的（到此处我排除了grub引导出错的可能性） 至此，我想既然问题出在引导文件上，我从我室友电脑上拷贝了一份该文件替换了我的引导文件，然后再使用PE中的引导修复工具修复了一遍，仍然无果 问题截图 如上所示，错误信息提示文件\\Windows\\System32\\winload.efi出错，导致我一直陷入找winload.efi文件错误的怪圈。 问题解决方法鼓捣大半天，我仍然无法解决此问题，便在SegmentFault上提问，希望藉此找到解答。在此要非常感谢解决了我的问题的答主冯恒智，一言点睛。 具体解决方法如下（划重点）：在PE中使用bootice的bcd编辑功能，打开了Win10所在磁盘中的BCD文件（C:\\EFI\\Microsoft\\Boot\\BCD），发现其中的【启动设备】项下的启动磁盘和启动分区项被置空了，我将其填写完毕后（如下图所示）发现Win10就可以正常启动了，我想这应该是我在安装Fedora时的一些不当操作使得BCD文件被修改的缘故而让Win10无法正常启动（Bootice使用方法可参见此博客）。 疑问：我在安装Fedora时应该说，和Win10所在盘是完全分隔开来的，为何Fedora安装好后会影响到Win10的Boot文件呢？更疑惑的是它只影响了配置中的启动磁盘和启动分区两项，而其他都未曾影响？待解…… 就很玄学（挠头11月7日更新SegmentFault上的答主冯恒智又回复了我的问题，如下： 并不是因为你编辑过bcd文件而导致启动磁盘和启动分区项被置空了，而是在win10安完后编辑过磁盘（比如分区啊，改盘符啊，调整容量什么的）导致找不到启动磁盘和启动分区，重新指定一下就行了","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Win10","slug":"Win10","permalink":"http://blog.guitoubing.top/tags/Win10/"},{"name":"Linux","slug":"Linux","permalink":"http://blog.guitoubing.top/tags/Linux/"},{"name":"双系统","slug":"双系统","permalink":"http://blog.guitoubing.top/tags/双系统/"},{"name":"引导修复","slug":"引导修复","permalink":"http://blog.guitoubing.top/tags/引导修复/"}]},{"title":"JavaFX 学习小记","slug":"JavaFX-学习小记","date":"2018-10-27T16:08:25.000Z","updated":"2018-11-13T10:52:26.000Z","comments":true,"path":"2018/10/28/JavaFX-学习小记/","link":"","permalink":"http://blog.guitoubing.top/2018/10/28/JavaFX-学习小记/","excerpt":"JavaFX小记简介 JavaFX JavaFX是由甲骨文(Oracle)公司推出的一系列的产品和技术，主要应用于创建Rich Internet application(RIAs)，它是一个跨平台的桌面应用程序开发框架。","text":"JavaFX小记简介 JavaFX JavaFX是由甲骨文(Oracle)公司推出的一系列的产品和技术，主要应用于创建Rich Internet application(RIAs)，它是一个跨平台的桌面应用程序开发框架。 典型的MVC架构 定义Model，使用javafx.beans封装类型定义属性类型 使用fxml文件创建View，利用SceneBuilder工具进行布局 创建Controller实现动作操作以及Model和View的联系 View 创建FXML文件，利用SceneBuilder工具进行布局 Model 定义Model中的Person类，使用Property和Bind java.beans包中的对象类型不是标准的Java原语，而是新的封装起来的类，它封装了Java原语并添加了一些额外的功能，Property和Bind方便我们实现以下功能：当某个属性如First Name被改变时，会自动收到通知而修改视图，从而保证视图与数据的同步。当然仅仅声明这种类型是不够的，声明只是为后续操作提供类型前提，还需要进一步操作，可参考JavaFX文档。 Person.java package com.tanrui.model;import java.time.LocalDate;import javafx.beans.property.IntegerProperty;import javafx.beans.property.ObjectProperty;import javafx.beans.property.SimpleIntegerProperty;import javafx.beans.property.SimpleObjectProperty;import javafx.beans.property.SimpleStringProperty;import javafx.beans.property.StringProperty;/** * Model class for a Person. */public class Person &#123; private final StringProperty firstName; private final StringProperty lastName; private final StringProperty street; private final IntegerProperty postalCode; private final StringProperty city; private final ObjectProperty&lt;LocalDate&gt; birthday; /** * Default constructor. */ public Person() &#123; this(null, null); &#125; /** * Constructor with some initial data. * * @param firstName * @param lastName */ public Person(String firstName, String lastName) &#123; this.firstName = new SimpleStringProperty(firstName); this.lastName = new SimpleStringProperty(lastName); // Some initial dummy data, just for convenient testing. this.street = new SimpleStringProperty(\"some street\"); this.postalCode = new SimpleIntegerProperty(1234); this.city = new SimpleStringProperty(\"some city\"); this.birthday = new SimpleObjectProperty&lt;LocalDate&gt;(LocalDate.of(1999, 2, 21)); &#125; public String getFirstName() &#123; return firstName.get(); &#125; public void setFirstName(String firstName) &#123; this.firstName.set(firstName); &#125; public StringProperty firstNameProperty() &#123; return firstName; &#125; public String getLastName() &#123; return lastName.get(); &#125; public void setLastName(String lastName) &#123; this.lastName.set(lastName); &#125; public StringProperty lastNameProperty() &#123; return lastName; &#125; public String getStreet() &#123; return street.get(); &#125; public void setStreet(String street) &#123; this.street.set(street); &#125; public StringProperty streetProperty() &#123; return street; &#125; public int getPostalCode() &#123; return postalCode.get(); &#125; public void setPostalCode(int postalCode) &#123; this.postalCode.set(postalCode); &#125; public IntegerProperty postalCodeProperty() &#123; return postalCode; &#125; public String getCity() &#123; return city.get(); &#125; public void setCity(String city) &#123; this.city.set(city); &#125; public StringProperty cityProperty() &#123; return city; &#125; public LocalDate getBirthday() &#123; return birthday.get(); &#125; public void setBirthday(LocalDate birthday) &#123; this.birthday.set(birthday); &#125; public ObjectProperty&lt;LocalDate&gt; birthdayProperty() &#123; return birthday; &#125;&#125; 使用ObservableList管理Person 前一点所述的后续操作便是此处了，JavaFX为了实现上述目的即保持视图和数据的同步，引入了一些新的集合类，这里我们用到的是ObservableList，ObservableList继承了List类、实现了Observable接口，其实现视图和数据同步的方法是在声明ObservableList时为方法传递一个监听器，此监听器需要会通过监听personData的变化同步改变视图中对应的值，可参考ObservableList文档 Main.java: public class Main extends Application &#123; /*......Other variables......*/ /** * * The data of a observable list of Persons */ private ObservableList&lt;Person&gt; personData = FXCollections.observableArrayList(); public ObservableList&lt;Person&gt; getPersonData() &#123; return personData; &#125; public Main()&#123; personData.add(new Person(\"Tan\", \"Rui\")); personData.add(new Person(\"Chen\", \"Chao\")); personData.add(new Person(\"Liang\", \"Chengwei\")); personData.add(new Person(\"Xiao\", \"Xin\")); personData.add(new Person(\"Li\", \"Yang\")); personData.add(new Person(\"Chen\", \"Runqian\")); personData.add(new Person(\"Liang\", \"Yongchao\")); personData.add(new Person(\"Luo\", \"Jihao\")); personData.add(new Person(\"Chen\", \"Zhi\")); personData.add(new Person(\"Fan\", \"Fan\")); &#125; /* ......Other function..... */&#125; ControllerPersonOverviewController.javapackage com.tanrui.view;import javafx.fxml.FXML;import javafx.scene.control.Label;import javafx.scene.control.TableColumn;import javafx.scene.control.TableView;import com.tanrui.Main;import com.tanrui.model.Person;public class PersonOverviewController &#123; @FXML private TableView&lt;Person&gt; personTable; @FXML private TableColumn&lt;Person, String&gt; firstNameColumn; @FXML private TableColumn&lt;Person, String&gt; lastNameColumn; @FXML private Label firstNameLabel; @FXML private Label lastNameLabel; @FXML private Label streetLabel; @FXML private Label postalCodeLabel; @FXML private Label cityLabel; @FXML private Label birthdayLabel; // Reference to the main application. private Main main; /** * The constructor. * The constructor is called before the initialize() method. */ public PersonOverviewController() &#123; &#125; /** * Initializes the controller class. This method is automatically called * after the fxml file has been loaded. */ @FXML private void initialize() &#123; // Initialize the person table with the two columns. firstNameColumn.setCellValueFactory(cellData -&gt; cellData.getValue().firstNameProperty()); lastNameColumn.setCellValueFactory(cellData -&gt; cellData.getValue().lastNameProperty()); &#125; /** * Is called by the main application to give a reference back to itself. * * @param main */ public void setMain(Main main) &#123; this.main = main; // Add observable list data to the table personTable.setItems(main.getPersonData()); &#125;&#125; @FXML注解（Annotation） 使用@FXML注解可以将操作的属性、方法绑定到FXML文件的界面元素，实际上，在属性、方法是非私有的情况下可以不使用@FXML注解，但是比起非私有声明，让他们保持私有并用注解标记的方式会更好！ initialize()方法 initialize()字面意思可知其是用于初始化对应FXML文件中的属性，此方法会在加载FXML文件时被自动执行，此时，所有的FXML属性都应已被初始化 setCellValueFactory(...)方法 我们对表格列上使用setCellValueFactory(...)方法来确定为特定列使用前面Person的某个属性。-&gt;表示使用的是Lambdas特性；另外一种方法是使用PropertyValueFactory(待研究…)。 这里我们之所以可以使用cellData -&gt; cellData.getValue().firstNameProperty()，便是因为之前我们将Person的属性都定义为javafx.beans中的封装属性，firstNameProperty()等方法都会在声明成Beans封装类型时被创建，其遵循了固定的命名规则，这使得我们使用起来特别方便 连接Main和PersonOverviewController showPersonOverview() 方法 Main.java /** * Shows the person overview inside the root layout. */public void showPersonOverview() &#123; try &#123; // Load person overview. FXMLLoader loader = new FXMLLoader(); loader.setLocation(Main.class.getResource(\"view/PersonOverview.fxml\")); AnchorPane personOverview = (AnchorPane) loader.load(); // Set person overview into the center of root layout. rootLayout.setCenter(personOverview); // Give the controller access to the main app. PersonOverviewController controller = loader.getController(); controller.setMain(this); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 将View与Controller绑定我们还需要为FXML文件指定其对应的Controller，以及FXML元素与控制器的属性的对应关系，这是因为FXML文件中的元素只能被对应Controller修改更新，若在其他方法中修改会产生运行时错误。例如：在PersonOverviewController.java中将某个Label返回到Main.java中而后在其中修改该Label的值，意即在非FX线程中执行FX线程相关的任务，则会造成当前的线程阻塞，解决方法之一是使用Platform.runLater()方法，如下所示，括号中的FX线程相关任务便不会阻塞当前进程。 Platform.runLater(() -&gt; &#123; ………相关FX线程代码………&#125;); 当然，最好的选择还是讲FX线程任务和其他任务区分开来，将特定的FXML文件与对应的Controller联系起来，当需要建立联系时可通过之前所说的使用java.beans、ObservableList等方法实现动态更新视图。 为FXML文件指定Controller 在Eclipse中好像有图形化界面直接为FXML文件选择Controller的操作，但是我使用的是IDEA，没有此功能，只能在源代码中指定，如下所示。 PersonOverview.fxml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;AnchorPane maxHeight=\"-Infinity\" maxWidth=\"-Infinity\" minHeight=\"-Infinity\" minWidth=\"-Infinity\" prefHeight=\"300.0\" prefWidth=\"600.0\" xmlns=\"http://javafx.com/javafx/8.0.121\" xmlns:fx=\"http://javafx.com/fxml/1\" fx:controller=\"com.tanrui.view.PersonOverviewController\"&gt; &lt;children&gt; &lt;? ... 内容省略 ... ?&gt; &lt;/children&gt;&lt;/AnchorPane&gt; 如上述代码所述，在顶层节点（此处是AnchorPane）标签中添加属性如下：fx:controller=&quot;com.tanrui.view.PersonOverviewController”，以此为FXML文件指定Controller 为FXML元素指定fx:id，使其绑定对应的控制器属性 如图，选定特定元素，在右侧界面找到Code-&gt;fx:id，将其对应的控制器属性填入即可 Details界面更新 showPersonDetails(Person person)方法 showPersonDetails(Person person)方法用于使用Person实例的数据填写标签。 PersonOverviewController.java /** * Fills all text fields to show details about the person. * If the specified person is null, all text fields are cleared. * * @param person the person or null */private void showPersonDetails(Person person) &#123; if (person != null) &#123; // Fill the labels with info from the person object. firstNameLabel.setText(person.getFirstName()); lastNameLabel.setText(person.getLastName()); streetLabel.setText(person.getStreet()); postalCodeLabel.setText(Integer.toString(person.getPostalCode())); cityLabel.setText(person.getCity()); // TODO: We need a way to convert the birthday into a String! // birthdayLabel.setText(...); &#125; else &#123; // Person is null, remove all the text. firstNameLabel.setText(\"\"); lastNameLabel.setText(\"\"); streetLabel.setText(\"\"); postalCodeLabel.setText(\"\"); cityLabel.setText(\"\"); birthdayLabel.setText(\"\"); &#125;&#125; 监听用户在人员表中的选择 PersonOverviewController.java @FXMLprivate void initialize() &#123; // Initialize the person table with the two columns. firstNameColumn.setCellValueFactory( cellData -&gt; cellData.getValue().firstNameProperty()); lastNameColumn.setCellValueFactory( cellData -&gt; cellData.getValue().lastNameProperty()); // Clear person details. showPersonDetails(null); // Listen for selection changes and show the person details when changed. personTable.getSelectionModel().selectedItemProperty().addListener( (observable, oldValue, newValue) -&gt; showPersonDetails(newValue));&#125; 删除按钮事件我们的界面已经包含了一个删除的按钮 ，但是并没有为其制定实际的响应操作，因此我们定义一个响应函数，如下： PersonOverviewController.java: /** * Called when the user clicks on the delete button. */ @FXML private void handleDeletePerson() &#123; int selectedIndex = personTable.getSelectionModel().getSelectedIndex(); if (selectedIndex &gt;= 0)&#123; personTable.getItems().remove(selectedIndex); &#125; else&#123; new ShowDialog(main.getPrimaryStage(), Alert.AlertType.WARNING, \"No Person Selected\", \"Please select a person in the table.\").ShowSpecificDialog(); &#125; &#125; 错误处理从上述代码可以看到我们使用了条件判断语句来判断selectedIndex的值，当其小于0时，正常情况我们应该会让其抛出ArrayIndexOutOfBoundsException异常，但是我们想尽量简洁明了的将错误或者警告信息展示给用户，因此这里我们使用了controlsfx包，用于弹出各类提示框（可在ControlsFX官网获取）。 controlsfx有两个主要的版本，同时对于不同的版本，二者的用法也不同： 对于Java 8，需要下载ControlsFX 8.40.14包 对于Java 9及以上，需要下载ControlsFX 9.0.0包 我们这里用到的是Java 10，因此使用ControlsFX 9.0.0，使用方法如下： ShowDialog.java: package com.tanrui.util;import javafx.scene.control.Alert;import javafx.stage.Stage;/** * Util to create and show Dialog. * * @author Tan Rui */public class ShowDialog &#123; private Stage stage; private Alert.AlertType type; private String title; private String message; public ShowDialog(Stage stage, Alert.AlertType type, String title, String message)&#123; this.stage = stage; this.type = type; this.title = title; this.message = message; &#125; public void ShowSpecificDialog()&#123; Alert dlg = new Alert(type); dlg.initOwner(stage); dlg.setTitle(title); dlg.getDialogPane().setContentText(message); dlg.show(); &#125;&#125; PersonOverviewController.java /** * Called when the user clicks on the delete button. */ @FXML private void handleDeletePerson() &#123; int selectedIndex = personTable.getSelectionModel().getSelectedIndex(); if (selectedIndex &gt;= 0)&#123; personTable.getItems().remove(selectedIndex); &#125; else&#123; new ShowDialog(main.getPrimaryStage(), Alert.AlertType.WARNING, \"No Person Selected\", \"Please select a person in the table.\").ShowSpecificDialog(); &#125; &#125; 新建和编辑对话框 Tips：创建一个新的界面、新的Stage（承载新的View时），步骤一般都是： 创建FXML文件，使用SceneBuilder编辑界面； 创建对应的Controller，对FXML中的元素指定对应的属性。主要是为展示型元素指定数据、为控制型元素指定动作等； 连接FXML文件和Controller文件、连接FXML中的元素和Controller中的属性； 在Main函数中加载该控制器 为之前的New和Edit按钮添加动作，弹出对话框（新的Stage）。 设计对话框创建PersonEditDialog.fxml，完成弹出对话框的设计： 创建控制器为对话框创建控制器PersonEditDialogController.java。 PersonEditDialogController.java： package com.tanrui.view;import com.tanrui.util.ShowDialog;import javafx.fxml.FXML;import javafx.scene.control.Alert;import javafx.scene.control.TextField;import javafx.stage.Stage;import com.tanrui.model.Person;import com.tanrui.util.DateUtil;/** * Dialog to edit details of a person. * * @author Marco Jakob */public class PersonEditDialogController &#123; @FXML private TextField firstNameField; @FXML private TextField lastNameField; @FXML private TextField streetField; @FXML private TextField postalCodeField; @FXML private TextField cityField; @FXML private TextField birthdayField; private Stage dialogStage; private Person person; private boolean okClicked = false; /** * Initializes the controller class. This method is automatically called * after the fxml file has been loaded. */ @FXML private void initialize() &#123; &#125; /** * Sets the stage of this dialog. * * @param dialogStage */ public void setDialogStage(Stage dialogStage) &#123; this.dialogStage = dialogStage; &#125; /** * Sets the person to be edited in the dialog. * * @param person */ public void setPerson(Person person) &#123; this.person = person; firstNameField.setText(person.getFirstName()); lastNameField.setText(person.getLastName()); streetField.setText(person.getStreet()); postalCodeField.setText(Integer.toString(person.getPostalCode())); cityField.setText(person.getCity()); birthdayField.setText(DateUtil.format(person.getBirthday())); birthdayField.setPromptText(\"dd.mm.yyyy\"); &#125; /** * Returns true if the user clicked OK, false otherwise. * * @return */ public boolean isOkClicked() &#123; return okClicked; &#125; /** * Called when the user clicks ok. */ @FXML private void handleOk() &#123; if (isInputValid()) &#123; person.setFirstName(firstNameField.getText()); person.setLastName(lastNameField.getText()); person.setStreet(streetField.getText()); person.setPostalCode(Integer.parseInt(postalCodeField.getText())); person.setCity(cityField.getText()); person.setBirthday(DateUtil.parse(birthdayField.getText())); okClicked = true; dialogStage.close(); &#125; &#125; /** * Called when the user clicks cancel. */ @FXML private void handleCancel() &#123; dialogStage.close(); &#125; /** * Validates the user input in the text fields. * * @return true if the input is valid */ private boolean isInputValid() &#123; String errorMessage = \"\"; if (firstNameField.getText() == null || firstNameField.getText().length() == 0) &#123; errorMessage += \"No valid first name!\\n\"; &#125; if (lastNameField.getText() == null || lastNameField.getText().length() == 0) &#123; errorMessage += \"No valid last name!\\n\"; &#125; if (streetField.getText() == null || streetField.getText().length() == 0) &#123; errorMessage += \"No valid street!\\n\"; &#125; if (postalCodeField.getText() == null || postalCodeField.getText().length() == 0) &#123; errorMessage += \"No valid postal code!\\n\"; &#125; else &#123; try &#123; Integer.parseInt(postalCodeField.getText()); &#125; catch (NumberFormatException e) &#123; errorMessage += \"No valid postal code (must be an integer)!\\n\"; &#125; &#125; if (cityField.getText() == null || cityField.getText().length() == 0) &#123; errorMessage += \"No valid city!\\n\"; &#125; if (birthdayField.getText() == null || birthdayField.getText().length() == 0) &#123; errorMessage += \"No valid birthday!\\n\"; &#125; else &#123; if (!DateUtil.validDate(birthdayField.getText())) &#123; errorMessage += \"No valid birthday. Use the format dd.mm.yyyy!\\n\"; &#125; &#125; if (errorMessage.length() == 0) &#123; return true; &#125; else &#123; new ShowDialog(dialogStage, Alert.AlertType.ERROR, \"Invalid Fields\", \"Please correct invalid fields\").ShowSpecificDialog(); return false; &#125; &#125;&#125; 关于该控制器的一些事情应该注意： setPerson(…)方法可以从其它类中调用，用来设置编辑的人员。 当用户点击OK按钮时，调用handleOK()方法。首先，通过调用isInputValid()方法做一些验证。只有验证成功，Person对象使用输入的数据填充。这些修改将直接应用到Person对象上，传递给setPerson(…)。 布尔值okClicked被使用，以便调用者决定用户是否点击OK或者Cancel按钮。 连接视图和控制器使用已经创建的视图（FXML）和控制器，需要连接到一起。 使用SceneBuilder打开PersonEditDialog.fxml文件 在左边的Controller组中选择PersonEditDialogController作为控制器类 设置所有TextField的fx:id到相应的控制器字段上。 设置两个按钮的onAction到相应的处理方法上。 在Main中部署该控制器Main.java: /** * Opens a dialog to edit details for the specified person. If the user * clicks OK, the changes are saved into the provided person object and true * is returned. * * @param person the person object to be edited * @return true if the user clicked OK, false otherwise. */public boolean showPersonEditDialog(Person person) &#123; try &#123; // Load the fxml file and create a new stage for the popup dialog. FXMLLoader loader = new FXMLLoader(); loader.setLocation(Main.class.getResource(\"view/PersonEditDialog.fxml\")); AnchorPane page = (AnchorPane) loader.load(); // Create the dialog Stage. Stage dialogStage = new Stage(); dialogStage.setTitle(\"Edit Person\"); dialogStage.initModality(Modality.WINDOW_MODAL); dialogStage.initOwner(primaryStage); Scene scene = new Scene(page); dialogStage.setScene(scene); // Set the person into the controller. PersonEditDialogController controller = loader.getController(); controller.setDialogStage(dialogStage); controller.setPerson(person); // Show the dialog and wait until the user closes it dialogStage.showAndWait(); return controller.isOkClicked(); &#125; catch (IOException e) &#123; e.printStackTrace(); return false; &#125;&#125; 为主界面中New和Edit按钮创建OnAction方法，这些方法将从Main中调用showPersonEditDialog(…)方法。 PersonOverviewController.java: /** * Called when the user clicks the new button. Opens a dialog to edit * details for a new person. */@FXMLprivate void handleNewPerson() &#123; Person tempPerson = new Person(); boolean okClicked = main.showPersonEditDialog(tempPerson); if (okClicked) &#123; main.getPersonData().add(tempPerson); &#125;&#125;/** * Called when the user clicks the edit button. Opens a dialog to edit * details for the selected person. */@FXMLprivate void handleEditPerson() &#123; Person selectedPerson = personTable.getSelectionModel().getSelectedItem(); if (selectedPerson != null) &#123; boolean okClicked = main.showPersonEditDialog(selectedPerson); if (okClicked) &#123; showPersonDetails(selectedPerson); &#125; &#125; else &#123; new ShowDialog(main.getPrimaryStage(), Alert.AlertType.WARNING, \"No Person Selected\", \"Please select a person in the table.\").ShowSpecificDialog(); &#125;&#125; 而后在PersonOverview.fxml中为New和Edit两个按钮绑定对应的OnAction方法： 数据持久化我们有很多种方法来实现应用数据的持久化，例如： 使用数据库存储 使用Json文件存储 使用XML文件存储 …… 这里我们使用XML文件格式存储应用数据。之前的我们应用的数据都只是存在内存中，内存的特性使得关闭应用程序后数据便会丢失，因此我们下面要做的就是： 每次打开应用可加载上一次的用户数据 用户可选择保存当前数据到指定XML文件 用户可选择从指定XML文件加载数据 使用Preferences保存应用状态Java提供了Preferences类来帮助我们存储用户配置（本例中是XML数据文件的路径，用于下次打开从该文件中加载），Preferences类底层对各类操作系统进行了封装（实际上是Windows系统、OS X系统和类Unix文件系统三种），用户配置在Windows系统上可能保存在注册表中、在类Unix文件系统上可能保存在/tmp下的某个隐藏文件中，而对于使用者来说这些实现细节都不必考虑，只需知道Preferences类是用来保存用户配置即可。用法如下： Main.java: /** * Returns the person file preference, i.e. the file that was last opened. * The preference is read from the OS specific registry. If no such * preference can be found, null is returned. * * @return */ public File getPersonFilePath() &#123; Preferences prefs = Preferences.userNodeForPackage(Main.class); String filePath = prefs.get(\"filePath\", null); if (filePath != null) &#123; return new File(filePath); &#125; else &#123; return null; &#125; &#125; /** * Sets the file path of the currently loaded file. The path is persisted in * the OS specific registry. * * @param file the file or null to remove the path */ public void setPersonFilePath(File file) &#123; Preferences prefs = Preferences.userNodeForPackage(Main.class); if (file != null) &#123; prefs.put(\"filePath\", file.getPath()); // Update the stage title. primaryStage.setTitle(\"AddressApp - \" + file.getName()); &#125; else &#123; prefs.remove(\"filePath\"); // Update the stage title. primaryStage.setTitle(\"AddressApp\"); &#125; &#125; 使用JAXBJAXB包是Java中提供的对数据进行编列(marshall)成XML文件以及对XML文件反编列(unmarshall)为数据结构的包，Java SE中有如下支持类型：JAXB 2.0是JDK 1.6的组成部分。JAXB 2.2.3是JDK 1.7以上的组成部分，而实际上在Java 9之后就已将JAXB包移除，因此使用时需添加额外的lib包，详情可见博客真正解决方案：java.lang.ClassNotFoundException: javax.xml.bind.JAXBException。 JAXB模型类我们希望持久化的数据应该是Main中的personData，而JAXB有以下要求： 使用@XmlRootElement定义XML根元素的名称 使用@XmlElement指定一个XML元素，可选 而Main中的personData是ObservableList类型，由于ObservableList类型不支持添加注解，因此我们需要创建另外一个能保存Person列表同时又能存储为XML文件的类，如下。 PersonListWrapper.java: package com.tanrui.model;import java.util.List;import javax.xml.bind.annotation.XmlElement;import javax.xml.bind.annotation.XmlRootElement;/** * Helper class to wrap a list of persons. This is used for saving the * list of persons to XML. */@XmlRootElement(name = \"persons\")public class PersonListWrapper &#123; private List&lt;Person&gt; persons; @XmlElement(name = \"person\") public List&lt;Person&gt; getPersons() &#123; return persons; &#125; public void setPersons(List&lt;Person&gt; persons) &#123; this.persons = persons; &#125;&#125; 使用JAXB读写数据到XML文件我们将读写XML文件的逻辑放到Main类中，Controller在用到相应的逻辑时，直接调用Main中的方法即可。 Main.java: /** * Loads person data from the specified file. The current person data will * be replaced. * * @param file */public void loadPersonDataFromFile(File file) &#123; try &#123; JAXBContext context = JAXBContext .newInstance(PersonListWrapper.class); Unmarshaller um = context.createUnmarshaller(); // Reading XML from the file and unmarshalling. PersonListWrapper wrapper = (PersonListWrapper) um.unmarshal(file); personData.clear(); personData.addAll(wrapper.getPersons()); // Save the file path to the registry. setPersonFilePath(file); &#125; catch (Exception e) &#123; // catches ANY exception new ShowDialog(this.getPrimaryStage(), Alert.AlertType.ERROR, \"Error\", \"Could not save data to file:\\n\" + file.getPath()).ShowSpecificDialog(); &#125;&#125;/** * Saves the current person data to the specified file. * * @param file */public void savePersonDataToFile(File file) &#123; try &#123; JAXBContext context = JAXBContext.newInstance(PersonListWrapper.class); Marshaller m = context.createMarshaller(); m.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, true); // Wrapping our person data. PersonListWrapper wrapper = new PersonListWrapper(); wrapper.setPersons(personData); // Marshalling and saving XML to the file. m.marshal(wrapper, file); // Save the file path to the registry. setPersonFilePath(file); &#125; catch (Exception e) &#123; // catches ANY exception new ShowDialog(this.getPrimaryStage(), Alert.AlertType.ERROR, \"Error\", \"Could not save data to file:\\n\" + file.getPath()).ShowSpecificDialog(); &#125;&#125; 编组(marshall):savePersonDataToFile(…)和解组(unmarshall):loadPersonDataFromFile(…)已准备好，下面在界面中使用它。 创建打开和保存菜单为File菜单添加子项 处理菜单相应动作Controller中使用FileChooser的方法，FileChooser同样封装了不同操作系统的具体实现，使用者仅需调用接口即可。 本类中使用了FileChooser.ExtensionFilter，对文件系统中文件进行过滤，保留.xml结尾的文件。 当用户选择特定文件而后点击打开按钮时，会返回该文件，否则返回Null。 package com.tanrui.view;import com.tanrui.Main;import com.tanrui.util.ShowDialog;import javafx.fxml.FXML;import javafx.scene.control.Alert;import javafx.stage.FileChooser;import java.io.File;/** * The controller for the root layout. The root layout provides the basic * application layout containing a menu bar and space where other JavaFX * elements can be placed. */public class RootLayoutController &#123; // Reference to the main application private Main main; /** * Is called by the main application to give a reference back to itself. * * @param main */ public void setMain(Main main) &#123; this.main = main; &#125; /** * Creates an empty address book. */ @FXML private void handleNew() &#123; main.getPersonData().clear(); main.setPersonFilePath(null); &#125; /** * Opens a FileChooser to let the user select an address book to load. */ @FXML private void handleOpen() &#123; FileChooser fileChooser = new FileChooser(); // Set extension filter FileChooser.ExtensionFilter extFilter = new FileChooser.ExtensionFilter( \"XML files (*.xml)\", \"*.xml\"); fileChooser.getExtensionFilters().add(extFilter); // Show save file dialog File file = fileChooser.showOpenDialog(main.getPrimaryStage()); if (file != null) &#123; main.loadPersonDataFromFile(file); &#125; &#125; /** * Saves the file to the person file that is currently open. If there is no * open file, the \"save as\" dialog is shown. */ @FXML private void handleSave() &#123; File personFile = main.getPersonFilePath(); if (personFile != null) &#123; main.savePersonDataToFile(personFile); &#125; else &#123; handleSaveAs(); &#125; &#125; /** * Opens a FileChooser to let the user select a file to save to. */ @FXML private void handleSaveAs() &#123; FileChooser fileChooser = new FileChooser(); // Set extension filter FileChooser.ExtensionFilter extFilter = new FileChooser.ExtensionFilter( \"XML files (*.xml)\", \"*.xml\"); fileChooser.getExtensionFilters().add(extFilter); // Show save file dialog File file = fileChooser.showSaveDialog(main.getPrimaryStage()); if (file != null) &#123; // Make sure it has the correct extension if (!file.getPath().endsWith(\".xml\")) &#123; file = new File(file.getPath() + \".xml\"); &#125; main.savePersonDataToFile(file); &#125; &#125; /** * Opens an about dialog. */ @FXML private void handleAbout() &#123; new ShowDialog(main.getPrimaryStage(), Alert.AlertType.INFORMATION, \"About\", \"Author: Tan\\\\nWebsite: https://guitoubing.top\").ShowSpecificDialog(); &#125; /** * Closes the application. */ @FXML private void handleExit() &#123; System.exit(0); &#125; /** * Opens the birthday statistics. */ @FXML private void handleShowBirthdayStatistics() &#123; main.showBirthdayStatistics(); &#125;&#125; 连接FXML文件和Controller、绑定菜单和对应动作 在Main中部署该控制器Main.java: /** * Initializes the root layout. */ public void initRootLayout() &#123; try &#123; // Load root layout from fxml file. FXMLLoader loader = new FXMLLoader(); loader.setLocation(Main.class.getResource(\"view/RootLayout.fxml\")); rootLayout = (BorderPane) loader.load(); // Show the scene containing the root layout. Scene scene = new Scene(rootLayout); primaryStage.setScene(scene); RootLayoutController controller = loader.getController(); controller.setMain(this); primaryStage.show(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; File file = getPersonFilePath(); if (file != null)&#123; loadPersonDataFromFile(file); &#125; &#125; 参考资料 code.makery —— JavaFX中文教程 JavaFX Tutorial 真正解决方案：java.lang.ClassNotFoundException: javax.xml.bind.JAXBException fxexperience —— ControlFX Java SE8 —— Lambda ………… 写在后面本博主要是在学习code.makery —— JavaFX中文教程博客中对于JavaFX的教程，跟着博主的项目逻辑和代码自己过了一遍，对一些由于版本不兼容（博主使用的是JDK 8u40，我这里使用的是Java 10 2018-03-20）造成的问题进行了解决，同时对项目过程中一些功能进行了拓展学习，研究了很多用到的包源码，收获颇多。可点击JavaFX-Test中获取源码。 希望藉此次JavaFX学习开启我的Java源码学习之旅，道阻且长！","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.guitoubing.top/tags/Java/"},{"name":"JavaFX","slug":"JavaFX","permalink":"http://blog.guitoubing.top/tags/JavaFX/"},{"name":"Java源码学习之旅","slug":"Java源码学习之旅","permalink":"http://blog.guitoubing.top/tags/Java源码学习之旅/"}]},{"title":"TimesTen内存数据库课程笔记（更新中）","slug":"TimesTen内存数据库课程笔记","date":"2018-09-02T12:59:50.000Z","updated":"2019-02-26T05:48:13.649Z","comments":true,"path":"2018/09/02/TimesTen内存数据库课程笔记/","link":"","permalink":"http://blog.guitoubing.top/2018/09/02/TimesTen内存数据库课程笔记/","excerpt":"内存计算与内存数据库第零章OLTP：行存储（记录：元组），联机事务处理 OLAP：列存储（key-value），联机分析处理 Timesten操作小记","text":"内存计算与内存数据库第零章OLTP：行存储（记录：元组），联机事务处理 OLAP：列存储（key-value），联机分析处理 Timesten操作小记 平台 系统：Red Hat Enterprise Linux Server release 5.7 (Tikanga) 创建DSN（Data Source Name） 逻辑名，用于标识某一数据库连接 打开数据库配置文件(通常称为系统ODBC.INI配置文件)$ cd $TT_HOME/info$ gedit sys.odbc.ini 在数据库DSN列表中添加需要新建的数据库名称# 添加my_ttdb数据库，“=”后面是指该数据库使用某种驱动，如第3行所示[ODBC Data Sources]my_ttdb=TimesTen 11.2.2 DriverTT_1122=TimesTen 11.2.2 Driversampledb_1122=TimesTen 11.2.2 Drivercachedb1_1122=TimesTen 11.2.2 Driverrepdb1_1122=TimesTen 11.2.2 Driverrepdb2_1122=TimesTen 11.2.2 DriversampledbCS_1122=TimesTen 11.2.2 Client Drivercachedb1CS_1122=TimesTen 11.2.2 Client Driverrepdb1CS_1122=TimesTen 11.2.2 Client Driverrepdb2CS_1122=TimesTen 11.2.2 Client Driver 为2中创建的数据库添加配置，日志文件与检查点文件应存储在不同磁盘中# 配置my_ttdb[my_ttdb]# 数据库监听器驱动位置Driver=/home/oracle/TimesTen/tt1122/lib/libtten.so # DataStore为检查点文件存储位置DataStore=/u02/ttdata/datastores/my_ttdb # LogDir为日志文件存储位置LogDir=/u03/ttdata/logs# 以下两个Size是TimesTen内存数据库的内存分配PermSize=40TempSize=32# 数据库的字符集DatabaseCharacterSet=AL32UTF8 TimesTen的内存分配主要是PermSize和TempSize两块，可先参考博客如何更改TimesTen数据库的大小。 保存配置文件并关闭数据库服务器基本命令查看服务器状态[oracle@timesten-hol info]$ ttstatusTimesTen status report as of Thu Sep 27 04:08:30 2018Daemon pid 2637 port 53392 instance tt1122TimesTen server pid 2646 started on port 53393------------------------------------------------------------------------Accessible by group oracleEnd of report 启动/停止数据库[oracle@timesten-hol info]$ ttdaemonadmin -stopTimesTen Daemon stopped.[oracle@timesten-hol info]$ ttstatusttStatus: Could not connect to the TimesTen daemon.If the TimesTen daemon is not running, please start itby running \"ttDaemonAdmin -start\".[oracle@timesten-hol info]$ ttdaemonadmin -startTimesTen Daemon startup OK.[oracle@timesten-hol info]$ ttstatusTimesTen status report as of Thu Sep 27 04:10:00 2018Daemon pid 6522 port 53392 instance tt1122TimesTen server pid 6531 started on port 53393------------------------------------------------------------------------Accessible by group oracleEnd of report 创建TimesTen内存数据库 默认情况下，TimesTen内存数据库在第一次连接到数据库时创建并加载到内存中，并在关闭数据库的最后一个连接时从内存卸载。当然此行为可通过ttadmin -RAMPolicy修改，后面会说到。 也就是说，默认情况下（前提是RAM策略为inUse，下一节会讲到RAM策略的修改），每次在执行connect “dsn=ttdb_name”连接到一个特定的DSN时，都是一个创建TimesTen内存数据库、加载数据到内存中等过程，因此本节的标题是创建而不是连接到。 连接到特定DSN，创建内存数据库[oracle@timesten-hol info]$ ttisqlCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.Type ? or \"help\" for help, type \"exit\" to quit ttIsql.Command&gt; connect \"dsn=my_ttdb\";Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;(Default setting AutoCommit=1) 或者直接在ttisql中指定DSN名称： [oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\"Copyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.Type ? or \"help\" for help, type \"exit\" to quit ttIsql.connect \"dsn=my_ttdb\";Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;(Default setting AutoCommit=1)[oracle@timesten-hol ~]$ ttisql my_ttdbCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.Type ? or \"help\" for help, type \"exit\" to quit ttIsql.connect \"DSN=my_ttdb\";Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;(Default setting AutoCommit=1) 问题：重复运行connect “dsn=ttdb_name”命令可以看到命令行中显示了多了连接，这是什么作用呢？ &gt; Command&gt; connect \"dsn=my_ttdb\";&gt; Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;&gt; (Default setting AutoCommit=1)&gt; Command&gt; connect \"dsn=my_ttdb\";&gt; Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;&gt; (Default setting AutoCommit=1)&gt; con1: Command&gt; connect \"dsn=my_ttdb\";&gt; Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;&gt; (Default setting AutoCommit=1)&gt; con2: Command&gt; connect \"dsn=my_ttdb\";&gt; Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;&gt; (Default setting AutoCommit=1)&gt; con3: Command&gt; &gt; 查看内存数据库的内存分配及容量Command&gt; dssize PERM_ALLOCATED_SIZE: 40960 PERM_IN_USE_SIZE: 9453 PERM_IN_USE_HIGH_WATER: 9453 TEMP_ALLOCATED_SIZE: 32768 TEMP_IN_USE_SIZE: 9442 TEMP_IN_USE_HIGH_WATER: 9505 使用Host命令可以调用操作系统级别的指令Command&gt; host ttstatus;TimesTen status report as of Thu Sep 27 04:37:28 2018Daemon pid 6522 port 53392 instance tt1122TimesTen server pid 6531 started on port 53393------------------------------------------------------------------------Data store /u01/ttdata/datastores/my_ttdbThere are 12 connections to the data storeShared Memory KEY 0x1200c904 ID 2785297PL/SQL Memory KEY 0x1300c904 ID 2818066 Address 0x7fa0000000Type PID Context Connection Name ConnIDProcess 6973 0x0000000000c72c00 my_ttdb 1Subdaemon 6529 0x00000000012d3360 Manager 142Subdaemon 6529 0x000000000132a1e0 Rollback 141Subdaemon 6529 0x000000000140b360 HistGC 139Subdaemon 6529 0x0000000001420070 AsyncMV 140Subdaemon 6529 0x00000000014b4e00 Log Marker 136Subdaemon 6529 0x0000000001509a30 Deadlock Detector 135Subdaemon 6529 0x000000000151e620 Flusher 134Subdaemon 6529 0x0000000001533210 Checkpoint 133Subdaemon 6529 0x00000000016286b0 Monitor 132Subdaemon 6529 0x00007f95880208e0 Aging 138Subdaemon 6529 0x00007f958808f900 IndexGC 137Replication policy : ManualCache Agent policy : ManualPL/SQL enabled.------------------------------------------------------------------------Accessible by group oracleEnd of report 修改RAM策略 上一节讲到每一次的连接到特定的DSN都是新建一个内存数据库的过程，当然这是基于默认RAM策略为inUse的情况，下面会讲到当RAM策略设置为Manual时创建内存数据库的过程。 Manual策略适用于当数据库中数据规模巨大，装载到内存中的时间可能很长，从而导致内存数据库效率低下；而inUse策略适用于大多数情况，数据规模不是很大，装载到内存中的时间很短或者说在业务需求中可以忽略不计。 查看当前RAM策略[oracle@timesten-hol info]$ ttadmin my_ttdbRAM Residence Policy : inUseReplication Agent Policy : manualReplication Manually Started : FalseCache Agent Policy : manualCache Agent Manually Started : False 修改RAM策略为手动模式（Manual） 手动模式下，创建DSN连接时并不会将数据加载到内存中，需要手动进行数据装载和卸载 [oracle@timesten-hol info]$ ttadmin -rampolicy manual my_ttdbRAM Residence Policy : manualManually Loaded In RAM : FalseReplication Agent Policy : manualReplication Manually Started : FalseCache Agent Policy : manualCache Agent Manually Started : False[oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\";Copyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.Type ? or \"help\" for help, type \"exit\" to quit ttIsql.connect \"dsn=my_ttdb\"; 707: Attempt to connect to a data store that has been manually unloaded from RAMThe command failed.Done.[oracle@timesten-hol info]$ 向内存中装载数据[oracle@timesten-hol info]$ ttadmin -ramload my_ttdbRAM Residence Policy : manualManually Loaded In RAM : TrueReplication Agent Policy : manualReplication Manually Started : FalseCache Agent Policy : manualCache Agent Manually Started : False[oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\";Copyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.Type ? or \"help\" for help, type \"exit\" to quit ttIsql.connect \"dsn=my_ttdb\";Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;(Default setting AutoCommit=1)Command&gt; 从内存中卸载数据[oracle@timesten-hol info]$ ttadmin -ramunload my_ttdbRAM Residence Policy : manualManually Loaded In RAM : FalseReplication Agent Policy : manualReplication Manually Started : FalseCache Agent Policy : manualCache Agent Manually Started : False[oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\";Copyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.Type ? or \"help\" for help, type \"exit\" to quit ttIsql.connect \"dsn=my_ttdb\"; 707: Attempt to connect to a data store that has been manually unloaded from RAMThe command failed.Done.[oracle@timesten-hol info]$ 日志和检查点查看日志文件，提交之前会预写日志Command&gt; host ls -al /u03/ttdata/logs/my*-rw-rw---- 1 oracle oracle 18270208 Sep 28 23:00 /u03/ttdata/logs/my_ttdb.log4-rw-rw---- 1 oracle oracle 67108864 Sep 27 04:18 /u03/ttdata/logs/my_ttdb.res0-rw-rw---- 1 oracle oracle 67108864 Sep 27 04:18 /u03/ttdata/logs/my_ttdb.res1-rw-rw---- 1 oracle oracle 67108864 Sep 27 04:18 /u03/ttdata/logs/my_ttdb.res2 查看检查点Command&gt; host ls -al /u02/ttdata/datastores/my*-rw-rw---- 1 oracle oracle 31906840 Sep 28 23:00 /u02/ttdata/datastores/my_ttdb.ds0-rw-rw---- 1 oracle oracle 31906840 Sep 28 22:57 /u02/ttdata/datastores/my_ttdb.ds1 手动更新检查点文件 非手动状态下检查点会每间隔一段时间执行一次，会将自上次检查点后提交的事务更新到检查点中；检查点文件是非阻塞的，即更新检查点文件时也可执行事务。 如下调用检查点文件： Command&gt; call ttckpt;Command&gt; call ttckpt; ttisql基本命令——用户操作创建用户，可在表sys.all_users中查找所有的用户信息Command&gt; select * from sys.all_users;&lt; SYS, 0, 2018-09-27 04:18:18.063030 &gt;&lt; TTREP, 2, 2018-09-27 04:18:18.063030 &gt;&lt; SYSTEM, 3, 2018-09-27 04:18:18.063030 &gt;&lt; GRID, 4, 2018-09-27 04:18:18.063030 &gt;&lt; ORACLE, 10, 2018-09-27 04:18:18.063030 &gt;&lt; SCOTT, 11, 2018-09-27 05:06:39.267433 &gt;6 rows found.Command&gt; create user tthr identified by tthr;User created.Command&gt; select * from sys.all_users;&lt; SYS, 0, 2018-09-27 04:18:18.063030 &gt;&lt; TTREP, 2, 2018-09-27 04:18:18.063030 &gt;&lt; SYSTEM, 3, 2018-09-27 04:18:18.063030 &gt;&lt; GRID, 4, 2018-09-27 04:18:18.063030 &gt;&lt; ORACLE, 10, 2018-09-27 04:18:18.063030 &gt;&lt; SCOTT, 11, 2018-09-27 05:06:39.267433 &gt;&lt; TTHR, 12, 2018-09-28 23:11:57.126074 &gt;7 rows found. 给用户分配权限Command&gt; grant create session to tthr;Command&gt; grant create table to tthr;Command&gt; grant create view to tthr;Command&gt; grant create sequence to tthr; 查看当前数据库系统内用户权限Command&gt; select * from sys.dba_sys_privs;&lt; SYS, ADMIN, YES &gt;&lt; SYSTEM, ADMIN, YES &gt;&lt; ORACLE, ADMIN, YES &gt;&lt; SCOTT, CREATE SESSION, NO &gt;&lt; SCOTT, CREATE TABLE, NO &gt;&lt; TTHR, CREATE SESSION, NO &gt;&lt; TTHR, CREATE TABLE, NO &gt;&lt; TTHR, CREATE VIEW, NO &gt;&lt; TTHR, CREATE SEQUENCE, NO &gt;9 rows found. 撤回用户权限 以下示例展示了如何从用户撤回权限（赋予delete any table权限后再撤回该权限） Command&gt; grant delete any table to tthr;Command&gt; select * from sys.dba_sys_privs;&lt; SYS, ADMIN, YES &gt;&lt; SYSTEM, ADMIN, YES &gt;&lt; ORACLE, ADMIN, YES &gt;&lt; SCOTT, CREATE SESSION, NO &gt;&lt; SCOTT, CREATE TABLE, NO &gt;&lt; TTHR, CREATE SESSION, NO &gt;&lt; TTHR, DELETE ANY TABLE, NO &gt;&lt; TTHR, CREATE TABLE, NO &gt;&lt; TTHR, CREATE VIEW, NO &gt;&lt; TTHR, CREATE SEQUENCE, NO &gt;10 rows found.Command&gt; revoke delete any table from tthr;Command&gt; select * from sys.dba_sys_privs;&lt; SYS, ADMIN, YES &gt;&lt; SYSTEM, ADMIN, YES &gt;&lt; ORACLE, ADMIN, YES &gt;&lt; SCOTT, CREATE SESSION, NO &gt;&lt; SCOTT, CREATE TABLE, NO &gt;&lt; TTHR, CREATE SESSION, NO &gt;&lt; TTHR, CREATE TABLE, NO &gt;&lt; TTHR, CREATE VIEW, NO &gt;&lt; TTHR, CREATE SEQUENCE, NO &gt;9 rows found. ttisql基本命令——数据库对象操作关闭自动提交 意即每次执行事务后，均需要执行commit以提交事务。 Command&gt; autocommit off; 建表、插入数据Command&gt; create table ttemployees &gt; (employee_id NUMBER(6) NOT NULL, &gt; last_name VARCHAR2(10) NOT NULL, hire_date DATE, performance_report CLOB, &gt; PRIMARY KEY (employee_id) ) &gt; UNIQUE HASH ON (employee_id) PAGES = 1;Command&gt; insert into ttemployees values (1, &apos;Smith&apos;, &apos;2009-02-23&apos;, &apos;excellent&apos;); 1 row inserted.Command&gt; insert into ttemployees values (2, &apos;King&apos;, &apos;2005-08-05&apos;, &apos;great&apos;);1 row inserted.Command&gt; insert into ttemployees values (3, &apos;Taylor&apos;, &apos;2012-01-28&apos;, EMPTY_CLOB());1 row inserted.Command&gt; commit; 一些命令总结 tables and alltables - Lists tables indexes and allindexes - Lists indexes views and allviews - Lists views sequences and allsequences - Lists sequences synonyms and allsynonyms - Lists synonyms functions and allfunctions - Lists PL/SQL functions procedures and allprocedures - Lists PL/SQL procedures packages and allpackages - Lists PL/SQL packages PLSQL编程创建plsqldb、pls用户、运行sql脚本call ttOptUpdateStats;// 更新统计数据，用于分析生成最优执行计划 使用sql developer连接TimesTen和Oracle配置如下： plsql语法 What Is a PL/SQL Package?A package is a schema object that groups logically related PL/SQL types, items, and subprograms. Packages usually have two parts, a specification and a body, although sometimes the body is unnecessary. The specification (spec for short) is the interface to your applications; it declares the types, variables, constants, exceptions, cursors, and subprograms available for use. The body fully defines cursors and subprograms, and so implements the spec. 包是一个模式对象，它对逻辑上相关的PL/SQL类型、项和子程序进行分组。包通常有两个部分，规范和主体，主体不是必要的。规范是应用程序的接口：它声明可用的类型、变量、常量、异常、游标和子程序。主体将完全定义游标和子程序，以此实现规范。 As Figure 9-1 shows, you can think of the spec as an operational interface and of the body as a “black box.” You can debug, enhance, or replace a package body without changing the interface (package spec) to the package. ——Oracle PL/SQL Package文档 1_package.sql: CREATE OR REPLACE PACKAGE test AS -- Declare a record for the desired EMP fields TYPE empRecType IS RECORD ( r_empno EMP.EMPNO%TYPE, -- 使用EMP表中EMPNO的类型 r_ename EMP.ENAME%TYPE, r_salary EMP.SAL%TYPE ); -- Declare a Ref Cursor type TYPE EmpCurType IS REF CURSOR RETURN empRecType; -- 游标类型需要有返回值 -- A parameterized cursor，定义 -- 游标 CURSOR low_paid (num PLS_INTEGER) IS SELECT empno FROM emp WHERE rownum &lt;= num ORDER BY sal ASC; -- 过程(IN表示输入，OUT表示输出) PROCEDURE ddl_dml (myComment IN VARCHAR2, errCode OUT PLS_INTEGER, -- 整型 errText OUT VARCHAR2); PROCEDURE givePayRise (num IN PLS_INTEGER, name OUT EMP.ENAME%TYPE, -- name是plsql中的保留字，应该尽量避免使用保留字 errCode OUT PLS_INTEGER, errText OUT VARCHAR2); PROCEDURE getCommEmps (empRefCur IN OUT EmpCurType, errCode OUT PLS_INTEGER, errText OUT VARCHAR2); -- Associative array TYPE sum_multiples IS TABLE OF PLS_INTEGER -- Associative array type INDEX BY PLS_INTEGER; -- indexed by pls_integer FUNCTION get_sum_multiples ( multiple IN PLS_INTEGER, num IN PLS_INTEGER ) RETURN sum_multiples;END test;/CREATE OR REPLACE PACKAGE BODY test AS PROCEDURE ddl_dml (myComment IN VARCHAR2, errCode OUT PLS_INTEGER, errText OUT VARCHAR2) IS sql_str VARCHAR2(256); name_already_exists EXCEPTION; insufficient_privileges EXCEPTION; PRAGMA EXCEPTION_INIT(name_already_exists, -0955); PRAGMA EXCEPTION_INIT(insufficient_privileges, -1031); seq_value number; BEGIN BEGIN sql_str := &apos;create table foo (COL1 VARCHAR2 (20),COL2 NVARCHAR2 (60))&apos;; DBMS_OUTPUT.PUT_LINE(sql_str); execute immediate sql_str; EXCEPTION WHEN name_already_exists THEN DBMS_OUTPUT.PUT_LINE(&apos; Ignore existing table errors&apos;); WHEN insufficient_privileges THEN DBMS_OUTPUT.PUT_LINE(&apos; Ignore insufficient privileges errors&apos;); END; -- Cast num_col1 and char_col values insert into temp values (1, 1, myComment); commit; errCode := 0; errtext := &apos;OK&apos;; EXCEPTION WHEN name_already_exists THEN errCode := 0; errtext := &apos;OK&apos;; WHEN OTHERS THEN errCode := SQLCODE; errText := SUBSTR(SQLERRM, 1, 200); END ddl_dml; PROCEDURE givePayRise (num IN PLS_INTEGER, name OUT EMP.ENAME%TYPE, errCode OUT PLS_INTEGER, errText OUT VARCHAR2) IS -- Can use PLSQL collections within TimesTen PLSQL TYPE lowest_paid_type IS TABLE OF emp.empno%TYPE; lowest_paid lowest_paid_type; i PLS_INTEGER; numRows PLS_INTEGER; lucky_index PLS_INTEGER; lucky_emp EMP.EMPNO%TYPE; BEGIN -- Initialize the output variable name := &apos;Nobody&apos;; -- Initialize the collection lowest_paid := lowest_paid_type(0, 1, 2, 3, 4, 5, 6, 7, 8, 9); i := 1; -- Constrain the resultset size IF num &lt; 1 OR num &gt; 10 THEN -- If bad inputs, default to 5 rows numRows := 5; ELSE numRows := num; END IF; -- Create the cursor resultset with up to &apos;numRows&apos; rows OPEN low_paid( numRows ); LOOP -- Get the current empid FETCH low_paid INTO lowest_paid(i); EXIT WHEN low_paid%NOTFOUND; -- Increment the PLSQL table index i := i + 1; END LOOP; -- Close the cursor CLOSE low_paid; -- List the subset of lowest paid employees FOR j in lowest_paid.FIRST .. numRows LOOP DBMS_OUTPUT.PUT_LINE(&apos; Lowest paid empno &apos; || j || &apos; is &apos; || lowest_paid(j) ); END LOOP; -- Randomly choose one of the lowest paid employees for a 10% pay raise. lucky_index := trunc(dbms_random.value(lowest_paid.FIRST, numRows)); lucky_emp := lowest_paid(lucky_index); -- Give lucky_emp a 10% pay raise and return their name UPDATE emp SET sal = sal * 1.1 WHERE empno = lucky_emp RETURNING ename INTO name; COMMIT; errCode := 0; errtext := &apos;OK&apos;; EXCEPTION WHEN OTHERS THEN errCode := SQLCODE; errText := SUBSTR(SQLERRM, 1, 200); END givePayRise; PROCEDURE getCommEmps (empRefCur IN OUT EmpCurType, errCode OUT PLS_INTEGER, errText OUT VARCHAR2) IS salesGuy empRecType; BEGIN DBMS_OUTPUT.PUT_LINE(&apos; &apos;); DBMS_OUTPUT.PUT_LINE(&apos;Displaying the refcursor for the sales people&apos;); -- The refcursor (empRefCur) result was opened before calling this procedure LOOP FETCH empRefCur INTO salesGuy; EXIT WHEN empRefCur%NOTFOUND; DBMS_OUTPUT.PUT_LINE(salesGuy.r_ename); END LOOP; CLOSE empRefCur; errCode := 0; errtext := &apos;OK&apos;; EXCEPTION WHEN OTHERS THEN errCode := SQLCODE; errText := SUBSTR(SQLERRM, 1, 200); END getCommEmps; FUNCTION get_sum_multiples ( multiple IN PLS_INTEGER, num IN PLS_INTEGER ) RETURN sum_multiples IS s sum_multiples; BEGIN FOR i in 1..num LOOP s(i) := multiple * ((i * (i + 1)) / 2); -- sum of the multiples END LOOP; RETURN s; END get_sum_multiples;BEGIN -- package initialization goes here DBMS_OUTPUT.PUT_LINE(&apos;Initialized package test&apos;);END test;/ 2_call_package.sql: set serveroutput on;declare errCode PLS_INTEGER; errtext VARCHAR2(256); myRefCur test.EmpCurType; -- 使用test包中定义的类型 salesPerson test.empRecType; name EMP.ENAME%TYPE; n PLS_INTEGER := 5; -- number of multiples to sum for display sn PLS_INTEGER := 10; -- number of multiples to sum m PLS_INTEGER := 3; -- multiple begin dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos;Find some of the lowest paid employees and give a random employee a 10% pay raise&apos;); -- Give a lowely paid random employee a 10% pay raise test.givePayRise(5, name, errCode, errText); if errCode != 0 then dbms_output.put_line(&apos;Error code = &apos; || errCode || &apos; Error Text = &apos; || errtext); else dbms_output.put_line(name || &apos; got the 10% payraise&apos;); end if; -- Open a refcursor OPEN myRefCur FOR SELECT empno, ename, sal FROM emp WHERE comm IS NOT NULL; -- display the resultset of the refcursor test.getCommEmps(myRefCur, errCode, errText); if errCode != 0 then dbms_output.put_line(&apos;Error code = &apos; || errCode || &apos; Error Text = &apos; || errtext); end if; dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos;Do some DDL and DML in a stored procedure&apos;); test.ddl_dml(&apos;hi&apos;, errCode, errText); if errCode != 0 then dbms_output.put_line(&apos;Error code = &apos; || errCode || &apos; Error Text = &apos; || errtext); end if; -- associative arrays dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos;Use an associative array to compute the sum of multiples&apos;); dbms_output.put_line( &apos;Sum of the first &apos; || TO_CHAR(n) || &apos; multiples of &apos; || TO_CHAR(m) || &apos; is &apos; || TO_CHAR(test.get_sum_multiples (m, sn)(n))); end;/ 3_create_package_workload.sql: CREATE OR REPLACE PACKAGE workload AS PROCEDURE oltp_read_only ( v_id IN PLS_INTEGER, v_n IN PLS_INTEGER, v_m IN PLS_INTEGER, errCode OUT PLS_INTEGER, errText OUT VARCHAR2); PROCEDURE oltp_read_write ( v_id IN PLS_INTEGER, v_n IN PLS_INTEGER, v_m IN PLS_INTEGER, v_c IN CHAR, v_p IN VARCHAR2, errCode OUT PLS_INTEGER, errText OUT VARCHAR2);END workload;/CREATE OR REPLACE PACKAGE BODY workload AS -- Private package variables used for package initialization theErrCode PLS_INTEGER := 0; theErrText VARCHAR2(256) := &apos;OK&apos;; -- Using shared package cursors for efficiency CURSOR range_query (n PLS_INTEGER, m PLS_INTEGER) IS SELECT c FROM sbtest WHERE id BETWEEN n AND m; CURSOR range_order_query (n PLS_INTEGER, m PLS_INTEGER) IS SELECT c FROM sbtest WHERE id BETWEEN n AND m ORDER BY c; CURSOR range_distinct_query (n PLS_INTEGER, m PLS_INTEGER) IS SELECT DISTINCT c FROM sbtest WHERE id BETWEEN n AND m ORDER BY c; -- The workload read only workload PROCEDURE oltp_read_only ( v_id IN PLS_INTEGER, v_n IN PLS_INTEGER, v_m IN PLS_INTEGER, errCode OUT PLS_INTEGER, errText OUT VARCHAR2) IS -- Store the result of the column &apos;c&apos; cValue char(120); -- Store the sum of the rows in (n..m) sumK number(38,0); BEGIN errCode := 0; errtext := &apos;OK&apos;; -- oltp point query FOR i in 1 .. 10 LOOP -- DBMS_OUTPUT.PUT_LINE(&apos;oltp point query&apos;); SELECT c INTO cValue FROM sbtest WHERE id = v_id; -- DBMS_OUTPUT.PUT_LINE(&apos;c = &apos; || cValue); END LOOP; -- oltp range query (using a cursor for loop)-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range query&apos;); FOR range_rows IN range_query(v_n, v_m) LOOP-- DBMS_OUTPUT.PUT_LINE(range_query%ROWCOUNT || &apos; c = &apos; || range_rows.c); null; END LOOP; -- olpt range SUM() query-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range SUM() query&apos;); SELECT sum(k) INTO sumK FROM sbtest WHERE id BETWEEN v_n AND v_m;-- DBMS_OUTPUT.PUT_LINE(&apos;sumK = &apos; || sumK); -- oltp range ORDER BY query (using explicit fetches)-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range ORDER BY query&apos;); OPEN range_order_query(v_n, v_m); LOOP FETCH range_order_query INTO cValue; EXIT WHEN range_order_query%NOTFOUND;-- DBMS_OUTPUT.PUT_LINE(&apos;c = &apos; || cValue); END LOOP; CLOSE range_order_query; -- oltp range DISTINCT query-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range DISTINCT query&apos;); OPEN range_distinct_query(v_n, v_m); LOOP FETCH range_distinct_query INTO cValue; EXIT WHEN range_distinct_query%NOTFOUND;-- DBMS_OUTPUT.PUT_LINE(&apos;c = &apos; || cValue); END LOOP; CLOSE range_distinct_query; EXCEPTION WHEN NO_DATA_FOUND THEN errCode := 0; errText := &apos;OK&apos;; WHEN OTHERS THEN errCode := SQLCODE; errText := SUBSTR(SQLERRM, 1, 200); END oltp_read_only; -- The workload read + write workload PROCEDURE oltp_read_write ( v_id IN PLS_INTEGER, v_n IN PLS_INTEGER, v_m IN PLS_INTEGER, v_c IN CHAR, v_p IN VARCHAR2, errCode OUT PLS_INTEGER, errText OUT VARCHAR2) IS -- Store the result of the column &apos;c&apos; cValue char(120); -- Store the sum of the rows in (n..m) sumK number(38,0); BEGIN errCode := 0; errtext := &apos;OK&apos;; -- oltp point query FOR i in 1 .. 10 LOOP -- DBMS_OUTPUT.PUT_LINE(&apos;oltp point query&apos;); SELECT c INTO cValue FROM sbtest WHERE id = v_id; -- DBMS_OUTPUT.PUT_LINE(&apos;c = &apos; || cValue); END LOOP; -- oltp range query (using a cursor for loop)-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range query&apos;); FOR range_rows IN range_query(v_n, v_m) LOOP-- DBMS_OUTPUT.PUT_LINE(range_query%ROWCOUNT || &apos; c = &apos; || range_rows.c); null; END LOOP; -- olpt range SUM() query-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range SUM() query&apos;); SELECT sum(k) INTO sumK FROM sbtest WHERE id BETWEEN v_n AND v_m;-- DBMS_OUTPUT.PUT_LINE(&apos;sumK = &apos; || sumK); -- oltp range ORDER BY query (using explict fetches)-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range ORDER BY query&apos;); OPEN range_order_query(v_n, v_m); LOOP FETCH range_order_query INTO cValue; EXIT WHEN range_order_query%NOTFOUND;-- DBMS_OUTPUT.PUT_LINE(&apos;c = &apos; || cValue); END LOOP; CLOSE range_order_query; -- oltp range DISTINCT query-- DBMS_OUTPUT.PUT_LINE(&apos;oltp range DISTINCT query&apos;); OPEN range_distinct_query(v_n, v_m); LOOP FETCH range_distinct_query INTO cValue; EXIT WHEN range_distinct_query%NOTFOUND;-- DBMS_OUTPUT.PUT_LINE(&apos;c = &apos; || cValue); END LOOP; CLOSE range_distinct_query; -- oltp UPDATES on index column-- DBMS_OUTPUT.PUT_LINE(&apos;oltp UPDATES on index column&apos;); UPDATE sbtest SET k = k + 1 WHERE id = v_n; -- oltp UPDATES on non-index column-- DBMS_OUTPUT.PUT_LINE(&apos;oltp UPDATES on non-index column&apos;); UPDATE sbtest SET c = v_n WHERE id = v_m; -- oltp DELETE query-- DBMS_OUTPUT.PUT_LINE(&apos;oltp DELETE query&apos;); DELETE FROM sbtest WHERE id = v_n; -- oltp INSERT query-- DBMS_OUTPUT.PUT_LINE(&apos;oltp INSERT query&apos;); INSERT INTO sbtest (id, k, c, pad) VALUES (v_n, v_m, v_c, v_p); -- Commit the changes COMMIT; EXCEPTION WHEN NO_DATA_FOUND THEN errCode := 0; errText := &apos;OK&apos;; WHEN OTHERS THEN errCode := SQLCODE; errText := SUBSTR(SQLERRM, 1, 200); END oltp_read_write;BEGIN -- package initialization goes here -- Run the procedures once to initialize everything oltp_read_only(1, 1, 10, theErrCode, theErrText ); oltp_read_write(1, 1, 10, &apos;abc&apos;, &apos;def&apos;, theErrCode, theErrText ); DBMS_OUTPUT.PUT_LINE(&apos;Initialized the workload package&apos;);END workload;/ 4_call_workload.sql: set serveroutput on;declare counter PLS_INTEGER; errCode PLS_INTEGER; errtext VARCHAR2(256); line1 VARCHAR2(256); line2 VARCHAR2(256); someText sbtest.c%TYPE; moreText VARCHAR2(256); i PLS_INTEGER; iterations PLS_INTEGER; startTime NUMBER; endTime NUMBER; duration NUMBER;begin -- Initialize the someText string line1 := &apos;The quick brown foxy did da jumping thing over that lazy doggy. &apos;; line2 := &apos;Question three, who was scott and who or what was tiger?&apos;; someText := line1 || line2; moreText := &apos;&apos;; -- Initialize the moreText string FOR i in 1 .. 60 LOOP moreText := moreText || &apos;a&apos;; END LOOP; -- Get the start time in centi-seconds startTime := DBMS_UTILITY.GET_TIME(); iterations := 10000; for counter in 1 .. iterations LOOP workload.oltp_read_only(1, 1, 1100, errCode, errtext); if errCode != 0 then exit; end if; end loop; -- Get the end time in centi-seconds endTime := DBMS_UTILITY.GET_TIME(); if errCode !=0 then dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos;Error code = &apos; || errCode || &apos; Error Text = &apos; || errtext); end if; duration := endTime - startTime; IF duration &gt; 0 THEN dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos;Called workload.oltp_read_only &apos; || iterations || &apos; times. TPS = &apos; || trunc(iterations / duration * 100, 1) ); ELSE dbms_output.put_line(&apos;Could not get valid timing info&apos;); END IF; iterations := 10000; for counter in 1 .. iterations LOOP workload.oltp_read_write(1, 1, 1100, someText, moreText, errCode, errtext); if errCode != 0 then exit; end if; end loop; -- Get the end time in centi-seconds endTime := DBMS_UTILITY.GET_TIME(); if errCode !=0 then dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos;Error code = &apos; || errCode || &apos; Error Text = &apos; || errtext); end if; duration := endTime - startTime; IF duration &gt; 0 THEN dbms_output.put_line(&apos;Called workload.oltp_read_write &apos; || iterations || &apos; times. TPS = &apos; || trunc(iterations / duration * 100, 1) ); ELSE dbms_output.put_line(&apos;Could not get valid timing info&apos;); END IF;end;/","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"大三上笔记","slug":"大三上笔记","permalink":"http://blog.guitoubing.top/tags/大三上笔记/"},{"name":"TimesTen","slug":"TimesTen","permalink":"http://blog.guitoubing.top/tags/TimesTen/"},{"name":"内存数据库","slug":"内存数据库","permalink":"http://blog.guitoubing.top/tags/内存数据库/"}]},{"title":"软件工程课程笔记（更新中）","slug":"软件工程课程笔记","date":"2018-09-01T13:22:10.000Z","updated":"2019-02-26T05:48:36.467Z","comments":true,"path":"2018/09/01/软件工程课程笔记/","link":"","permalink":"http://blog.guitoubing.top/2018/09/01/软件工程课程笔记/","excerpt":"软件工程第一章第二章 软件工程 定义软件工程的框架(Framework) 软件工程的定义 软件工程是：（1）将系统化的(systematic)、规范的(disciplined)、可量化(quantifiable)的方法应用于软件的开发(development)、运行(operation)和维护(maintenance). （2）对（1）中所述方法(approaches)的研究.","text":"软件工程第一章第二章 软件工程 定义软件工程的框架(Framework) 软件工程的定义 软件工程是：（1）将系统化的(systematic)、规范的(disciplined)、可量化(quantifiable)的方法应用于软件的开发(development)、运行(operation)和维护(maintenance). （2）对（1）中所述方法(approaches)的研究. 软件工程层次图 工具-方法-过程-质量关注点 软件过程 软件过程的定义 软件过程是工作产品构建时所执行的一系列活动、动作和任务的集合，一个活动(activity)包含多个动作(action)，一个动作包含多个任务(task). 过程框架 最经典的过程框架： 需求调研(RE)→需求分析建模(Require Analysis Model)→概要设计(Architecture Design)→详细设计(CLD)→编码(Coding)→单元测试(Unit testing)→整合测试(Integrating testing)→系统测试(System testing)→交付或发布(Delivery or Release) 通用的过程框架： 沟通(Communication)→策划(Planning)→建模(Modeling)→构建(Construction)→部署(Deployment) 沟通包含需求调研； 策划是一个普适性活动或者庇护维活动或质量控制维活动(Umbrella activity)，与开发维(devolope demention)或框架活动(framework)不重合 建模包含需求分析建模、概要设计、详细设计 构建包含编码、单元测试、整合测试、系统测试 部署包含发布 milestone milestone是项目管理中用于标记项目时间轴上特定点的工具，用于某一过程活动完成的标志，以使工程能够成功过渡到下一阶段。 普适性活动包含： 软件项目跟踪和控制(Software project tracking and control，以Planning为基础) 风险管理(Risk management) 首先进行风险识别，得到初始识别的风险表(risk list)，利用以下公式将风险按照RE从高到低排序列出。 &gt; risk exposure(RE，风险曝光度) = impact(影响度) * productivity(影响比例)&gt; 制定风险缓解计划(risk mitigation planning) 风险跟踪(risk tranking)： 可能风险缓解 可能风险真的发生，要有对应的风险处理对策 软件质量保证(Software quality assurance) 例子：SQA，GitHub的bug检查合并 技术评审(Technical review) 按照代码逻辑或者代码行进行评审、检查 测量(Measurement) 定量化， 软件配置管理(Software configuration management) 在整个软件过程中管理变更所带来的影响 可复用管理(Reusability management) 工作产品的准备和生产(Work product preparation and production) 工作分解结构(WBS)： ​ 工作分解结构（简称WBS）跟因数分解是一个原理，就是把一个项目，按一定的原则分解，项目分解成任务，任务再分解成一项项工作，再把一项项工作分配到每个人的日常活动中，直到分解不下去为止。即：项目→任务→工作→日常活动。工作分解结构以可交付成果为导向，对项目要素进行的分组，它归纳和定义了项目的整个工作范围，每下降一层代表对项目工作的更详细定义。WBS总是处于计划过程的中心，也是制定进度计划、资源需求、成本预算、风险管理计划和采购计划等的重要基础。——百度百科 过程的适应性调整 软件工程过程并不是教条的规则，也不要求软件团队机械地执行，而应该是灵活可适应的（根据软件所需解决的问题、项目特点、开发团队和组织文化等进行适应性调整）。 软件工程实践 具体实施通用框架活动的过程就是软件实践。 实践的精髓 理解问题（沟通和分析）—— Understand the problem (communication and analysis) 策划解决方案（建模和软件设计）—— Plan a solution (modeling and software design) 包含概要设计建模和分析设计建模，最重要的是概要设计建模（体系结构、数据库设计、接口设计） 实施计划（代码生成）—— Carry out the plan (code generation) 就是写代码 检查结果的正确性（测试和质量保证）—— Examine the result for accuracy (tesing and quality assurance) 通过设计足够的测试来发现尽可能多的错误 通用原则 存在价值（The reason it all exists） 保持简洁（KISS, Keep it simple, stupid） 保持愿景（Maintain the Vision） 关注使用者（What You Produce， Others Will Consume） 面向未来（Be Open To The Future） 提前计划复用（Plan Ahead for Reuse） 认真思考（Think！） 软件开发神话Exercise: 找到Tools第三章 软件过程结构通用过程模型 过程流 线性过程流 迭代过程流 演化过程流 并行过程流 定义框架活动过程模式第四章 过程模型（Process Models）传统（惯用）过程模型（Prescriptive Process Models）瀑布模型（Waterfall Model） 又称经典生命周期（Classic life cycle） 瀑布模型可能会有反复的过程，但无迭代的过程，但反复会使得开发过程产生混乱。 瀑布模型的变种：V模型（V-model），V模型拉直后与Generic Process Framework一致。 箭头表示测试过程与设计过程的关系（相关性） 增量过程模型（Incremental Process Models） 增量过程模型没有迭代过程，因为其开发过程没有环 特点： 每1个增量交叉并行 每1个增量都是可以供用户直接使用的系统 第1个增量往往包含主要的、核心的功能 模型的选择：时间限制、资金限制、技术限制 例如项目的99%的需求已经完善，项目需要6个月完成，若时间充足可使用瀑布模型，但若甲方所给时间比较少，则可先完成一部分主要的内容，先交付，后来的需求可在后面的增量中开发，这就是增量模型的一个例子。 演化过程模型（Evolutionary Process Model） 演化模型是迭代的过程模型","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"大三上笔记","slug":"大三上笔记","permalink":"http://blog.guitoubing.top/tags/大三上笔记/"},{"name":"软件工程","slug":"软件工程","permalink":"http://blog.guitoubing.top/tags/软件工程/"}]},{"title":"计算机网络课程笔记（更新中）","slug":"计算机网络课程笔记","date":"2018-09-01T12:51:13.000Z","updated":"2019-03-06T13:08:43.357Z","comments":true,"path":"2018/09/01/计算机网络课程笔记/","link":"","permalink":"http://blog.guitoubing.top/2018/09/01/计算机网络课程笔记/","excerpt":"计算机网络简介 网络通信是进程间的通信，进程的表示： IP:port //IP为服务器IP地址，port为服务器上的进程号","text":"计算机网络简介 网络通信是进程间的通信，进程的表示： IP:port //IP为服务器IP地址，port为服务器上的进程号 网络组成： Management Application Hardware Cable：电缆、光纤 Network Interface Card：网卡 Switch：交换机 Router：路由器 传播介质（第7章）对传播介质的度量 传播延时 信号在介质中往返一次所需的时间 信道容量 介质可以支持的最大数据速率 频率范围 介质可接受的最大的频率变化范围 带宽 每秒所收到的数据量（Bit） 奈奎斯特定理D=2*B*log2KK:传输系统使用的信号电平数B:模拟带宽D:以每秒位元数计算的最大数据速率 香农定理C=B*log2(1+S/N)B:硬件带宽S/N:信噪比C:用每秒位数表示的对信道容量的有效限制 分贝(db)和信噪比(S/N)是指数关系 dB=10*log10S/Neg: dB = 20 =&gt; S/N = 100 db = 30 =&gt; S/N = 1000 例子：电话线 Bandwidth = 3000HZS/N ratio = 30db=&gt; C = 30Kps 传输模式（第9章）传输模式分类 串行传输 并行传输 传输数据 例子：Byte 正序(big-endian) &amp;&amp; Bit 逆序(little-endian) 串行传输方式 异步传输 键盘输入，RS-232异步字符传输 RS-232异步字符传输标准 把一串字符串通过铜线进行传输 S1:把字符用ASCII码表示出来；S2: 状态机：电压变化表示状态切换 空闲状态： ​ 接受”-“：保持空闲状态 ​ 接受”+“：变成传输状态 传输状态： ​ 接受”-“：保持传输状态，传1 ​ 接受“+”：保持传输状态，传0 传输的数据前后各需要一位，分别作为起始位(+)、终止位(-) 结束按照“翻转”时间确定，传输完成保持负电压 最终传输到接收方是9位，多一位校验码 同步传输 以太网 原理同对表一样 实现方法：采用先传输一部分规定好的数据，来检测发送方和接收方是否一致 等时传输 利用缓冲区实现 标准 波特率匹配 例子：传输Z(0x5A)，检测波特率提高一倍 通信信道 单工信道 Eg：广播、收音机 全双工信道 数据线路设备(DCE)和数据终端设备(DTE) 反接线 半双工信道 Eg：对讲机 调制和调制解调器（第10章）远距离传输 考虑：干扰、信号衰减 解决方案：载波传输 载波传输方式 连续性好 载波改变方式——调制（Modulation）与解调（Demodulation）S(t)=Asin(2πFt+P)// A: Amplitude Modulation(调幅)// F: Frequency Modulation(调频，单位时间内波的个数)// P: Phase Modulation(调相) 调幅 调幅的大小有一定的限制（香农定理的限制） 调频 调相 键控（Shift keying）调制技术的比较 调相的效率要高一点，变化一次可传输不止一位（通过相位分隔，例如将2π分为8份，则有8种信号，可传输3位数据） 正交调幅(QAM, Quadrature Amplitude Modulation) 结合调幅和移相键控，使用同时包含相位和振幅的改变来表示数据，QAM最大可以表示1024个 公式：Y~m~(t) = A~m~sinwt+B~m~coswt，运算为矢量运算 调制解调器类型 无线猫（RF，Radio Frequency） 光纤猫（optical modems） 拨号猫（Dialup modem） 拨号调制解调器模式 Calling mode Answer mode 复用与解复用（第11章）分类频分多路复用FDM 多个逻辑信道，实际上只有一个物理信道。 防止频道之间干扰，通常有个区间为防护带区间。 信号的漂移现象 解决方法：子信道分配 分级FDM 分布式平铺 波分多路复用WDM 是指应用于光纤中的频分复用技术 时分多路复用TDM 同步TDM 问题：空闲时隙 应用：电话通话 分级TDM 统计TDM 应用：网络 逆转复用 将单个高速数字输入被分配到多个低速连接上，传输后再重新复合而形成输入的副本 码分多路复用CDM 矢量（Vector） 矢量的运算 结论 可靠性和信道编码（第8章）数据传输错误的3个源头 干扰 失真 衰减 传输差错对数据的影响 单个差错 突发差错 擦除（模糊） 处理信道差错的两种策略（信道编码） 发送数据的同时，发送校验码 前向纠错（FEC） 自动重传请求（ARQ） FEC机制 单奇偶检验 奇偶性定义为1的个数，且校验位的添加会使得码字始终保持奇数或偶数，保持奇数就是奇校验，保持偶数就是偶校验. 限制：校验能力有限，出两个错误时便无法校验 分组码数学与（n, k）表示 汉明距离 先计算最小汉明距d，而后得出可检查的最大的有效位长度：E&lt;=d-1 纵横奇偶校验 作用：可以找出错误的位置，并改正错误 缺点：效率低下，一般不用 校验和 码的长度一般为字节的倍数，进位需加回到原和中 优点： 校验和的大小比较小 计算很简单 开支很低 缺点： 对纵向错误无法校验（导致校验和方法一般不用在硬件上） 一般情况下，校验和位取的是算数反码，校验时所有数据位相加，得到结果取补码为0则数据正确 IP包的头部长度：20Bytes 循环冗余校验码（CRC码，适宜用在硬件上，例如网卡） 关键特性 任意长度报文 出色的检错能力 快速硬件实现 线性码、循环线性码 线性码是一个码的集合C，且C~1~、C~2~∈C，则C~1~、C~2~∈C的线性组合仍然∈C； 循环线性码是指码循环移位后的码仍然属于该集合。 原理 硬件实现 异或门实现基本运算 算法 自动重传请求(ARQ)机制 数据传输成功会发送回执，错误则不发送回执 ​ OSI Reference Model 数据流（Data Flow）： Service服务：下一层对上一层提供服务（接口、方法） Protocol协议 Physical物理 物理层（5 7 9 10 11） 数据链路层（8） 将一条物理上有差错的传输信道通过通知和管理而变成逻辑上无差错的 因特网应用与网络编程（第3章）线路交换网络（circuit switched network）包交换网络（packet switched network） 特征：轮流 ​ 异步 不用安装 主要区别在于二者的共享性 局域网：分组、帧和拓扑（第13章）以太网的接受方式 广播式： MAC子层拷贝每个包 LLC子层提取每个包的拷贝 LLC子层只接受那些单一传播、广播或多路传播的地址相匹配的包 帧 帧头、帧尾用于检测传输过程是否发生错误，同时用作边界 边界采用两个ASC码中很少使用的字符： SOH（01）头部起始字符 EOT（04）传输结束字符 此方案的缺陷假如使用此两个字符，将会发生接受解析问题 解决方案 字填充（ABC可换成“任意”字符，但是效率不同，找一些不太会出现的字符会提高效率）： soh → esc + A eot → esc + B esc → esc + C 位填充： 5个1出现了便插入1个0，首尾使用01111110作为边界 IEEE MAC子层（第14章）受控介入协议（Control Access Protocols）轮询 方式： 按循环顺序 按优先级顺序 算法： &gt; 目的：&gt; 通过轮询来控制分组的发送&gt; 方法：&gt; 控制器不断重复&#123;&gt; 选择站点S，发送一个查询报文给S；&gt; 等待S发送一个分组来进行响应或跳过；&gt; &#125;&gt; 预定 算法： &gt; 目的：&gt; 通过预约来控制分组的发送&gt; 方法：&gt; 控制器不断重复&#123;&gt; 形成一个需要发送分组的站点列表；&gt; 允许列表中的站点发送分组；&gt; &#125;&gt; 令牌传递 令牌是一个特殊的帧，不管有没有数据都会在环状网络中传输 令牌有两个状态（空和忙的切换只能由同一个站点切换）： 空 → 可以发送（数据在传输时转变为忙令牌） 忙 → 无法发送（只能当数据在环网中发送一周时，才能将忙令牌转换为空令牌） 算法： &gt; 目的：&gt; 通过令牌传递来控制分组的发送&gt; 方法：&gt; 网络上的每台计算机重复执行&#123;&gt; 等待令牌的到达；&gt; 如果本计算机有分组正在等待发送，则发送一个分组；&gt; 将令牌发送到下一站；&gt; &#125;&gt; &gt; 1）空令牌传递到下一个节点；&gt; 2）节点是否要发送？不发送，转向1）&gt; 3）填充帧到令牌中，并置为忙&gt; 4）忙令牌传递到下一个节点&gt; 5）是否接受节点？是，复制该帧；转向4）&gt; 6）节点是否发送节点？是，销毁令牌中的帧，并置空，返回1）&gt; 7）返回4）&gt; 随机接入协议（Random Access Protocol）ALOHACSMA/CD（Collision Detect） 以太网中一个网卡数据一旦发送，便不能停下，需等到数据发送完 算法： &gt; 1）监听网络状态；如果空闲，转向3）&gt; 2）等待，返回1）&gt; 3）发送，在发送的过程中同时进行碰撞监听&gt; 4）一旦发生碰撞，立即停止发送&gt; 5）推后一个随机时间，返回1）&gt; 检测冲突的方法： 载波侦听 冲突检测 二进制指数退避 CSMA/CA（Collision Avoidance） 算法： 有限局域网技术（第15章）以太网帧格式 以太网帧结构（截自维基百科） Question：(Using 广播 ) How does the sender know the target physical address？（注意：网卡无法识别IP地址） 地址解析（Address Resolution）目的地地址解析Sender： 发送广播，征询目的节点的物理地址 接到目的节点应答，取出目的节点物理地址 All Receivers： 接到广播，取出源节点物理地址,比较主机名是否相同 目标节点，匹配，就取出源节点物理地址，以该地址为目的地址，本物理地址为源地址，作询问应答 其他节点，因不匹配不需要作回答 帧类型（Frame Type） 用于区分帧的类型，是ARP包还是IP包（区分协议类型） IP：0800 ARP：0806 IEEE’s 802.3 Ethernet Frame（一种新的帧格式）网卡 NIC Network Interface Card NIC可以直接访问Memory，NIC与CPU仅存在指令关系 过程： 发送 Before sending data, CPU forms a packet in memory 发送数据之前，CPU在内存中产生一个数据包 CPU then instructs the NIC to begin transmission CPU给NIC发送播送指令 NIC transmits the frame containing the packet After finishing transmission, NIC uses the computer’s interrupt mechanism to inform the CPU 接收 The NIC waits for a frame to cross the network The NIC makes a copy of the frame The NIC verifies the frame CRC and checks the destination address If the destination address is correct，the NIC stores a copy of the packet in memory The NIC then interrupts the CPU Otherwise，the NIC discards the frame 网卡产品（NIC Evolution）粗缆（Original Thick Ethernet Wiring） IEEE802.310Base5 最大长度：500m（摩天大楼的高度） 组成： 网卡（连在设备上） 收发器 电缆 Terminator（终结器）：将信号能量消耗掉，防止信号反弹造成干扰，原理是电阻 Connection Multiplexor（多路连接器）：允许多台计算机连接到单个收发器，且提供与传统收发器完全相同的信号 细缆（Thin Ethernet） 将前者的三部分组合起来，结构和环网很像，但传输方式仍然是广播式的，Terminator仍然需要。 双绞线以太网（Twisted Pair Ethernet） HUB（集线器）里面包含了主线 集成网卡 RJ-45：双绞线 AUI：粗缆 BNC：细缆 双绞线网卡拓扑结构 Tips：网络上的逻辑上和结构上的拓扑结构可以不同！ 物理上：星形结构 逻辑上：总线结构 举例： 布线工程 无线联网技术（第16章）个域网（PAN，802.15） 蓝牙 红外 蓝牙耗电比较低，红外耗电高 紫峰（ZigBee） ISM无线 无线局域网（WLAN、WiFi，802.11） 为降低信号衰减采用FDM分布式平铺技术（第11章） AP，Access Point through the air （Base Station），相当于集线器 类型 专门构建型（Ad hoc） 点到点，不通过AP 基础结构型（Infrastructure） 通过AP Manet（Mobile Ad-hoc Networks）","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"大三上笔记","slug":"大三上笔记","permalink":"http://blog.guitoubing.top/tags/大三上笔记/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://blog.guitoubing.top/tags/计算机网络/"}]},{"title":"dotnet基本配置及EFCore连接Mysql","slug":"Dotnet","date":"2018-06-26T08:57:08.000Z","updated":"2018-12-11T16:33:44.757Z","comments":true,"path":"2018/06/26/Dotnet/","link":"","permalink":"http://blog.guitoubing.top/2018/06/26/Dotnet/","excerpt":"前奏部分 下载并安装dotnet core 下载并安装vscode（需要把vscode添加到path中）","text":"前奏部分 下载并安装dotnet core 下载并安装vscode（需要把vscode添加到path中） vscode中搜索并安装C#插件、NuGet Package Manager插件 新建项目 &gt; mkdir dotnet&gt; cd dotnet&gt; dotnet new mvc&gt; code .&gt; commond + shift + p输入nuget add package安装以下依赖包，各个包的Version可在添加时选择 添加包时以下代码将自动在dotnet.csproj中添加： &gt; &lt;ItemGroup&gt;&gt; &lt;PackageReference Include=\"Microsoft.AspNetCore.All\" Version=\"2.0.6\"/&gt;&gt; &lt;PackageReference Include=\"Microsoft.EntityFrameworkCore.Sqlite\" Version=\"2.1.0\"/&gt;&gt; &lt;PackageReference Include=\"Microsoft.EntityFrameworkCore.Tools\" Version=\"2.1.0\"/&gt;&gt; &lt;PackageReference Include=\"Microsoft.EntityFrameworkCore.Sqlite.Design\" Version=\"2.0.0-preview1-final\"/&gt;&gt; &lt;PackageReference Include=\"Microsoft.EntityFrameworkCore.Tools.DotNet\" Version=\"2.1.0-preview1-final\"/&gt;&gt; &lt;PackageReference Include=\"Pomelo.EntityFrameworkCore.MySql\" Version=\"2.1.0-rc1-final\"/&gt;&gt; &lt;PackageReference Include=\"Pomelo.EntityFrameworkCore.MySql.Design\" Version=\"1.1.2\"/&gt;&gt; &lt;/ItemGroup&gt;&gt; Model部分 连接数据库创建实体： 在vscode终端中输入以下命令 dotnet ef dbcontext scaffold &quot;server=localhost;userid=user;pwd=password;port=3306;database=university;sslmode=none;&quot; Pomelo.EntityFrameworkCore.MySql -o Models dotnet ef两个问题 问题1：No executable found matching command “dotnet-ef”解决方法：dotnet.csproj中添加如下行： &gt; &lt;ItemGroup&gt;&gt; &lt;DotNetCliToolReference Include=\"Microsoft.EntityFrameworkCore.Tools.DotNet\" Version=\"2.1.0-preview1-final\"/&gt;&gt; &lt;/ItemGroup&gt;&gt; 问题2：Version for package Microsoft.EntityFrameworkCore.Tools.DotNet could not be resolved. 原因：上述配置中Version版本与包引用中的版本不一致，修改上述添加代码的Version即可 此时将会在Models文件夹下创建所有数据库表的实体，同时会创建一个universityContext.cs实体（university为我数据库名称，自行定义），用于对整个数据库的操作。至此MVC已完成Model部分。 Controller及View部分 目前项目Models文件夹下已有DBFirst模式生成的实体文件： 我们选择Student的Model创建C-V视图 这里说明一下，MVC模式中Model顾名思义是数据模型、实体，而View和Controller是相互依存的。一般步骤是先创建StudentController.cs文件，定义其中的路由(URL映射，定义了路由之后可以直接通过URL访问该函数)，如本项目中的StudentController.cs中定义的Index： &gt; public IActionResult Index()&#123;&gt; return View(_context.Student.ToList());&gt; &#125;&gt; 如此定义后，再在Views文件夹下创建对应Controller的文件夹，此处为Student，而在Controller中定义的每一个路由，都要有对应的一个cshtml文件，此处在Student下创建Index.cshtml。简而言之，View只负责处理布局，Controller只负责处理逻辑。 创建StudentController.cs &gt; using System;&gt; using System.Collections.Generic;&gt; using System.Diagnostics;&gt; using System.Linq;&gt; using System.Threading.Tasks;&gt; using Microsoft.AspNetCore.Mvc;&gt; using dotnet.Models;&gt; using dotnet;&gt; &gt; public class StudentController : Controller&#123;&gt; private universityContext _context;&gt; &gt; public StudentController(universityContext context)&#123;&gt; _context = context;&gt; &#125;&gt; &gt; public IActionResult Index()&#123;&gt; return View(_context.Student.ToList());&gt; &#125;&gt; &gt; public IActionResult Register()&#123;&gt; return View();&gt; &#125;&gt; &gt; [HttpPost]&gt; [ValidateAntiForgeryToken]&gt; public IActionResult Register(Student student)&#123;&gt; if(ModelState.IsValid)&#123;&gt; _context.Student.Add(student);&gt; _context.SaveChanges();&gt; return RedirectToAction(&quot;Index&quot;);&gt; &#125;&gt; return View(student);&gt; &#125;&gt; &#125;&gt; 创建Student文件夹，以及对应路由的cshtml Index.cshtml &gt; @&#123;&gt; ViewData[\"Title\"] = \"学生主页\";&gt; &#125;&gt; &gt; &lt;!-- 此处这个model声明不能忘记 --&gt;&gt; @model IEnumerable&lt;dotnet.Student&gt;&gt; &gt; &lt;table class=\"table\"&gt;&gt; &lt;tr&gt;&gt; &lt;th&gt;Id&lt;/th&gt;&gt; &lt;th&gt;姓名&lt;/th&gt;&gt; &lt;th&gt;系&lt;/th&gt;&gt; &lt;th&gt;学分&lt;/th&gt;&gt; &lt;/tr&gt;&gt; @foreach (var item in Model)&#123;&gt; &lt;tr&gt;&gt; &lt;td&gt;&gt; @Html.DisplayFor(modelItem =&gt; item.Id)&gt; &lt;/td&gt;&gt; &lt;td&gt;&gt; @Html.DisplayFor(modelItem =&gt; item.Name)&gt; &lt;/td&gt;&gt; &lt;td&gt;&gt; @Html.DisplayFor(modelItem =&gt; item.DeptName)&gt; &lt;/td&gt;&gt; &lt;td&gt;&gt; @Html.DisplayFor(modelItem =&gt; item.TotCred)&gt; &lt;/td&gt;&gt; &lt;/tr&gt;&gt; &#125;&gt; &lt;/table&gt;&gt; Register.cshtml &gt; @model dotnet.Student&gt; &gt; @&#123;&gt; ViewData[\"Title\"] = \"注册\";&gt; &#125;&gt; &gt; &lt;form asp-controller=\"Student\" asp-action=\"Register\" method=\"POST\"&gt;&gt; &lt;div class=\"form-group\"&gt;&gt; &lt;label asp-for=\"Id\" class=\"col-md-2 control-label\"&gt;编号：&lt;/label&gt;&gt; &lt;div class=\"col-md-10\"&gt;&gt; &lt;input class=\"form-control\" asp-for=\"Id\"/&gt;&gt; &lt;span asp-validation-for=\"Id\" class=\"text-danger\"&gt;&lt;/span&gt;&gt; &lt;/div&gt;&gt; &lt;label asp-for=\"Name\" class=\"col-md-2 control-label\"&gt;名字：&lt;/label&gt;&gt; &lt;div class=\"col-md-10\"&gt;&gt; &lt;input class=\"form-control\" asp-for=\"Name\"/&gt;&gt; &lt;span asp-validation-for=\"Name\" class=\"text-danger\"&gt;&lt;/span&gt;&gt; &lt;/div&gt;&gt; &lt;label asp-for=\"DeptName\" class=\"col-md-2 control-label\"&gt;系：&lt;/label&gt;&gt; &lt;div class=\"col-md-10\"&gt;&gt; &lt;input class=\"form-control\" asp-for=\"DeptName\"/&gt;&gt; &lt;span asp-validation-for=\"DeptName\" class=\"text-danger\"&gt;&lt;/span&gt;&gt; &lt;/div&gt;&gt; &lt;label asp-for=\"TotCred\" class=\"col-md-2 control-label\"&gt;学分：&lt;/label&gt;&gt; &lt;div class=\"col-md-10\"&gt;&gt; &lt;input class=\"form-control\" asp-for=\"TotCred\"/&gt;&gt; &lt;span asp-validation-for=\"TotCred\" class=\"text-danger\"&gt;&lt;/span&gt;&gt; &lt;/div&gt;&gt; &lt;div class=\"col-md-offset-2 col-md-10\"&gt;&gt; &lt;input type=\"submit\" value=\"保存\" class=\"btn btn-default\"/&gt;&gt; &lt;/div&gt;&gt; &lt;/div&gt;&gt; &lt;/form&gt;&gt; 关于抛出以下错误的解决方法 错误： 解决方法： 注意最下面的Tip：由于我们在Startup.cs中已经添加如下代码： &gt; public void ConfigureServices(IServiceCollection services)&gt; &#123;&gt; services.AddDbContext&lt;universityContext&gt;();&gt; services.AddMvc();&gt; &#125;&gt; 即满足条件“already configured outside of the context in Startup.cs”，因此我们需要将上述图片中的if语句注释掉，如下： &gt; //if (!optionsBuilder.IsConfigured)&#123; &gt; optionsBuilder.UseMySql(&quot;server=localhost;userid=root;pwd=tanrui;port=3306;database=university;sslmode=none;&quot;);&gt; //&#125;&gt; 运行项目 调试的方法 vscode下点按“开始调试” 浏览器将会自动跳转至localhost:5000 在URL中添加/student或student/index跳转到我们定义的Controller中，一般情况下index路由是可以忽略不写的，此时自动定位到index中： 戳这里下载Asp.net Core开发实战.pdf","categories":[{"name":"archives","slug":"archives","permalink":"http://blog.guitoubing.top/categories/archives/"}],"tags":[{"name":"Dotnet","slug":"Dotnet","permalink":"http://blog.guitoubing.top/tags/Dotnet/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.guitoubing.top/tags/数据库/"}]},{"title":"我们梦中见","slug":"2017-10-14","date":"2018-06-26T04:29:17.000Z","updated":"2019-02-26T05:47:30.844Z","comments":true,"path":"2018/06/26/2017-10-14/","link":"","permalink":"http://blog.guitoubing.top/2018/06/26/2017-10-14/","excerpt":"“Yeah It’s on. ” 26/06/2018当兵回来用的虚拟主机建的博客，hexo建在本地。前段时间电脑重装了，以前的博客就落满了灰，现迁移过来，换个心情。 14/10/2017（是不是个技博自己心里没点B数？","text":"“Yeah It’s on. ” 26/06/2018当兵回来用的虚拟主机建的博客，hexo建在本地。前段时间电脑重装了，以前的博客就落满了灰，现迁移过来，换个心情。 14/10/2017（是不是个技博自己心里没点B数？ 应该说天明学长在技术方面给予了很大的支持，为她打call！ 说要建站已经是三年前了，那时候在某课网上闲逛看到了关于Linux搭建服务器的视频，学了点，发现，what are you fk saying？后来自己买了本书，噢~ 更™不懂了。然后，就去了号子（？？）。转眼两年过去了，是该重新做人了，该搬的砖还得搬，搬不完还想吃饭？ 买的第一个虚拟主机是景安一台国内主机，这个时候还是不知道国内主机和海外主机有啥区别，只知道国内主机便宜，不，新用户免费。于是买了个试了下。配套的买了个top域名¥15.00/月，是贼贵了。绑定域名时发现需要备案，备案就备案吧，流程走下去。一大堆东西拍了照填了表提交上去了想的差不多了吧。结果跟我说非上海本地户口要™居住证或者临时居住证，我哪里去办，户口都没迁过来，想想要不找个备案不怎么严的省份备案下，看了下河南（？？？）以及其他，要么是要本地手机号要么就是居住证，算了，贵国厉害，我买海外。于是买了个HK主机，¥199/年（后来看到阿里云服务器学生价¥10/月+com域名就扇了自己一巴掌，你有钱行了吧）。 接下来是干货了（扯淡然后就是绑定域名了没啥说的。 对于一个毫无前端经验的人来说，有了这些又有啥用，别人进你网站就为了看你在云里面存了多少种子？ 这里又要提到天明学长了，在她网站中得知有了个Hexo的框架，仿佛看到了未来。至于Hexo怎么用，官方文档里面都很详尽了，这里讲几点用的时候踩过的坑，以备。 _config.YML配置，比较重要的几个地方路径URLurl: http://guitoubing.top/root: / url和root一定要注意，最后面的“/”千万不要忘了，不然在hexo generate的时候肯定会报错 在generate后要注意public文件夹的位置，public文件夹一般自动创建在当前目录下，我在server后，本地服务器浏览是没有问题的，但是点开public文件夹里面的index就会连不上css，当然上传到服务器之后肯定也是连不上的了，因为root: /这行代码认为你当前工作目录是在根目录下（硬盘根目录或者服务器根目录），有的同学会想那我把root改成我当前位置不就好了，我也试过，此时public里面的index可以正常浏览，但是传到deploy到服务器上就又连不上了，因为服务器里面没有你当前这样的路径呀。这里我用的笨办法，把创建好的public文件夹复制到硬盘根目录下，然后发现本地服务器上index是可以正常显示了，传到服务器上之后也是可以的。 Disqus插件# Disqus settingsdisqus_username: guitoubing 因为多说已经关闭服务了，只能用Disqus，而Disqus又是需要科学上网才能加载的，所以也没办法了。如果你能科学上网，那只要把这里的disqus_username改成自己注册的账号即可，我用的主题hexo-theme-huxblog已经集成了Disqus的js代码，所以不需要其他设置，如果用的其他主题/themes/layout里面的ejs文件中添加js代码即可。 Analytics# Analytics settings# Baidu Analyticsba_track_id: bcfce8e737b***********04c164dc96# Google Analyticsga_track_id: &apos;UA-10*******-1&apos; # Format: UA-xxxxxx-xxga_domain: guitoubing.top deploydeploy: type: ftpsync host: guitoubing.top user: webmaster@HK****** pass: tanrui106 remote: /WEB/ port: 21 deploy就是部署到服务器上咯，因为我用的是HK虚拟主机，所以配置如上，这里的各个信息都是你所部署的服务器信息没什么好说的。 _config.YML配置完成了就可以开始创作咯hexo new &quot;blog&quot; hexo ghexo s Hexo官方文档都有详细使用方法，不赘述。 有几句MMP当讲古有一商人，于川中收购一批苎麻、小麦、桔子、兽皮，从水路出川。船至半途，水急桨朽，桨折断而顺水去，船夫甚急，问商人： 无桨不得行船，你所携货物中可有长直之物当桨？ 商人安慰他： 莫急，我有桔麻麦皮不知当桨不当桨？ 从开始接触hexo到成功deploy到服务器上，算下来该有一下午加一晚上了。应该说两年没接触编程了，那句“程序员写了一段让自己不用再写代码的代码”已经不是笑话，也许是两年之前也啥屁不懂，现在越来越觉得放眼看世界是多重要。当我还熬夜敲着基础代码时，互联网上已经有了其他解决方案，倒不是说基础代码不重要，而是已经有人用基础代码敲出了不用再敲基础代码的代码，那么，吃肉，还是喝汤，看自己选择了。（我选择狗带）","categories":[{"name":"life","slug":"life","permalink":"http://blog.guitoubing.top/categories/life/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.guitoubing.top/tags/Hexo/"}]}]}