[{"title":"Java类与类加载器","url":"/2019/03/27/Java类与类加载器/","content":"\n## 类加载机制\n\n类加载机制个人认为是JVM中比较重要的一部分，因此在JVM系统学习之前就先学习了类加载机制的相关细节，以记之。\n\n### 阶段\n\n![image-20190327204927833](/images/类加载机制.png)\n\n其中`解析`可能会发生在`初始化`之后，`使用`可能不会被使用。\n\n上述流程指的是**开始时间**的顺序，**比如说`加载`未结束可能`验证`就会开始**。\n\n### 类加载时机\n\n虚拟机严格规定了5种情况**必须立即**对类进行**初始化**(不是上述流程中的初始化，指的是初始化类对象)：\n\n1. 遇到`new`、`getstatic`、`putstatic`、`invokestatic`这4条字节码指令时，如果类没有进行初始化则需要先触发其初始化。\n\n2. 对类进行反射调用；\n3. 当初始化一个类时，若父类还没有被初始化需要先触发其父类的初始化；\n4. 当虚拟机启动时，包含`main()`方法的那个类需要被初始化；\n5. 当使用动态语言支持时，如果一个`java.lang.invoke.MethodHandle`实例最后的解析结果是`REF_getStatic`、`REF_putStatic`、`REF_invokeStatic`的方法句柄，并且句柄对应的类没有被初始化。\n\n**不会触发**类的初始化的**可能操作**：\n\n- **通过子类调用父类的静态字段**，不会导致**子类**初始化\n- **通过数组定义来引用类**，不会触发该类的初始化\n- **引用类的静态常量域或字段**，不会导致该类的初始化\n\n注意，接口也是会有初始化的过程，与类唯一不同的是上述`第3点`：接口在初始化时，**并不要求其父接口全部都完成了初始化**(原因应该是接口`<clinit>()`方法不需要调用父类的`<clinit>()`方法)，只有**在真正使用到父接口的时候**(如引用接口中定义的常量时)才会初始化。\n\n### 加载\n\n加载阶段的3件事情：\n\n1. 通过一个类的**全限定名**来获取**定义此类的二进制字节流**\n2. 将这个**字节流所代表的静态存储结构**转化为**方法区**的**运行时数据结构**\n3. 在内存中**生成一个代表这个类的`Class对象`**，作为方法区这个类的各种数据的访问入口\n\n第1件事情中的`二进制字节流`不一定是本地文件，可能是从**ZIP获取**、**从网络获取(Applet)**、**动态代理**、**JSP生成**、**数据库读取**等。\n\n### 验证\n\n验证主要是为了虚拟机对自身保护的一项重要工作，大致会完成以下4个阶段的检验动作：\n\n1. 文件格式验证：检测字节流是否符合Class文件格式规范\n2. 元数据验证：语义分析，保证信息符合Java语言规范的要求，主要是**数据类型**\n3. 字节码验证：最复杂的一部分，主要是对**类的方法体**进行校验(控制流、跳转等)\n4. 符号引用验证：发生在`解析`阶段，主要是对**符号引用进行匹配性校验**(能否找到、是否可达等)\n\n### 准备\n\n准备阶段是为类变量(静态变量)分配初始值的过程。\n\n注意两点：\n\n1. 初始值**通常情况**下是**数据类型的零值**，比如语句`public static int value = 123;`会在准备阶段给`value`初始化为`int`的零值即`0`，而`123`会在**后续的初始化阶段被赋值**给`value`；\n2. **特殊情况**下，常量类型会在**准备阶段被赋值**，比如语句`public static final int value = 123;`\n\n### 解析\n\n解析阶段是**将常量池内的符号引用替换为直接引用的过程**。\n\n#### 符号引用\n\n是指**以一组符号来描述所引用的目标**，符号引用在使用时能无歧义地定位到目标。\n\n#### 直接引用\n\n是指**可以直接指向目标的指针**、**相对偏移量**或**一个句柄**。\n\n### 初始化\n\n正式开始执行类中定义的Java代码(或者说是字节码)。记得准备阶段有为变量赋予初始值，这里就会为其赋予程序中制定的初始值。\n\n初始化主要的过程是执行`<clinit>()`方法。\n\n### 类与类加载器\n\n对于任意一个类，都需要由**加载它的类加载器**和**类本身**一同确立其在JVM中的唯一性。\n\n在使用`instanceof`关键字、Class对象的`equal()`、`isAssignableFrom()`、`isInstance()`方法时，都需要判定上述两方面是否相等。**自定义的类加载器**和**系统自带的类加载器**加载的**同一个类生成的对象使用相等方法验证是得不到相等结果的**。\n\n### 双亲委派模型\n\n类加载器划分：\n\n- 启动类加载器：负责将`<JAVA_HOME>\\lib`目录下的能被虚拟机识别的类库加载到虚拟机内存中，程序无法直接引用。\n- 扩展类加载器：负责将`<JAVA_HOME>\\lib\\ext`目录下的能被虚拟机识别的类库加载到虚拟机内存中，程序可直接使用。\n- 应用程序类加载器：负责加载用户类路径(ClassPath)上的类库，程序可直接使用。\n\n双亲委派模型如下图所示：\n\n![image-20190327234320380](/images/双亲委派模型.png)\n\n其中每一层与其父层关系一般**不是继承(Inheritance)**而是**组合(Composition)**来复用父加载器的代码。\n\n**工作过程：**如果一个类加载器收到了类加载的请求，它**首先不会尝试加载这个类**，而是**把这个请求委派给父类加载器去加载**，**每个层次都是这样**，直到请求被传递到**顶层的启动类加载器**中；而**只有父加载器反馈自己无法完成此请求时，子加载器才回去尝试加载**。\n\n双亲委托模型在`ClassLoader`类中的`loadClass()`方法中实现。","tags":["Java"],"categories":["archives"]},{"title":"深入学习Java（更新中）","url":"/2019/03/06/深入学习Java（更新中）/","content":"\n## 垃圾回收器—GC\n\n众所周知，Java中的GC负责回收**无用对象占用的内存资源**，但会有特殊情况：假定对象获得了一块\"特殊\"的内存区域（不是使用new创建的），由于**GC只释放那些经由new分配的内存**，所以GC不知道如何释放该对象的这块\"特殊\"内存区域。\n\n作为应对，Java允许在类中定义`finalize()`方法，它使得在GC回收该对象内存之前先调用`finalize()`方法，并在下一次GC回收发生时，真正回收对象内存。举个例子：某个对象创建时会在屏幕上绘出一些图像，当没有明确将其从屏幕擦除时，图像便可能会永远存在在屏幕上，若在`finalize()`指定擦除的方法，那么在GC回收该对象时将会同时将其图像从屏幕上擦除。\n\n**关键点：**\n\n1. 对象可能不被垃圾回收\n2. 垃圾回收并不等于\"析构\"\n3. 垃圾回收只与内存有关\n\n### 避免使用finalize()\n\n> \"终结函数无法预料，常常是危险的，总之是多余的。\"《Effective Java》，第20页\n\n在Java中一切皆为对象，且创建对象的方法只有new，那么必然存在**通过某种创建对象以外的方式为对象分配了存储空间**。\n\nNative Method(本地方法)是Java中调用非Java代码的方式，此时非Java代码中可能使用了malloc()等分配内存的函数而未使用free()对其释放，此时GC也不会去管这块内存，这就使得需要指定特定的finalize()方法来实现内存的释放。\n\n可见，finalize()不是进行普遍的清理工作的合适方式，因此需要避免使用。\n\n### 终结条件的验证\n\n但是finalize()有个有趣的用法——终结条件。看如下代码：\n\n```java\nclass Book{\n    // Book类，约定其在被回收前必须被签入。\n\tboolean checkedOut = false;\n\tBook(boolean checkedOut){\n\t\tcheckedOut = checkedOut;\n\t}\n\tvoid checkIn(){\n\t\tcheckedOut = false;\n\t}\n\tprotected void finalize(){\n        // 终结条件，对象未被签入\n\t\tif (checkedOut) {\n\t\t\tSystem.out.println(\"Error: checked out\");\n\t\t}\n\t}\n}\n\npublic class Main{\n\tpublic static void main(String[] args){\n        // 创建一个Book对象-novel\n\t\tBook novel = new Book(true);\n        // 将其签入\n\t\tnovel.checkIn();\n        // 创建一个Book对象，此时该对象未被签入\n\t\tnew Book(true);\n        // 强制执行垃圾回收，此时会先执行finalize\n\t\tSystem.gc();\n\t}\n}\n\n/* 输出：\nError: checked out\n*/\n```\n\n我们约定所有的Book对象在创建之前都必须被签入，但是在main中，由于疏忽有个新创建的对象未执行签入操作，此时执行垃圾回收，finalize()中的终结条件被激活，把错误反馈给使用者。\n\n> 注意这里使用的System.gc()强制调用垃圾回收器\n\n若没有finalize()将很难实现这种操作。\n\n### GC如何工作\n\n#### 引用计数（未被使用过）\n\n对象创建时便有引用计数，当引用计数变为0时，GC回收该对象内存空间。\n\n缺陷：循环引用不适用，即出现\"对象应该被回收，但引用计数不为0\"的情况，称作\"交互自引用的对象组\"。如下所示：\n\n```java\npublic class Main {\n    public static void main(String[] args) {\n        // object1指向的对象引用计数器：1\n        MyObject object1 = new MyObject();\n        // object2指向的对象引用计数器：1\n        MyObject object2 = new MyObject();\n        // object1指向的对象引用计数器：2\n        object1.object = object2;\n        // object2指向的对象引用计数器：2\n        object2.object = object1;\n        // object1指向的对象引用计数器减少为1\n        object1 = null;\n        // object2指向的对象引用计数器减少为1\n        object2 = null;\n    }\n}\n```\n\n我们将`object1`和`object2`赋值为null，意即我们已经不需要该对象，但由于此时对象的引用计数器不为0导致这两个对象永远不会被回收。\n\n#### 停止-复制（stop-and-copy）\n\n遍历所有**引用**找到所有\"活\"的**对象**，将堆中**所有存活的对象复制到另一个堆中**，没有被复制的便都是垃圾了。\n\n这种策略避免了上述\"交互自引用的对象组\"无法回收的情况，因为这两个对象不会被看作是存活的对象，即遍历的过程中根本找不到这两个对象（他们不在从GC Root出发连接所有存活结点构成的图中）。\n\n**缺陷：效率低**\n\n1. 复制需要在两个堆之间操作，即需要维护多一倍的空间；\n2. 当程序进入稳定状态之后，可能只产生少量垃圾，此时此策略仍然需要进行复制操作，很浪费。\n\n针对第2个情况，有另外一种策略，如下。\n\n#### 标记-清扫（mark-and-sweep）\n\n同样遍历所有**引用**找到所有\"活\"的**对象**，同时会给该对象进行**标记**，当全部标记工作完成后，开始进行清理工作。没有被标记的对象将会被释放，因此剩下的堆空间是不连续的，此时GC需要使用其他整理的方法来清理内存碎片，称作\"标记-整理\"。\n\n> 注意，上面两种垃圾回收机制都不是在后台进行的，意即进行垃圾回收时会暂停程序。\n>\n> 许多文献中有关于\"垃圾回收器是低优先级的后台进程\"的说法，事实上早期版本的JVM使用这两种策略时并非如此。当可用内存不足时，垃圾回收器会暂停运行程序，而后开展\"停止-复制\"或\"标记-清扫\"工作。\n\n\"标记-清扫\"方式速度相当慢，但是当垃圾很少时，就很快了。\n\n#### 自适应技术\n\nJVM会进行监视，如果所有对象都很稳定，GC的效率降低的话，就切换到\"标记-清扫\"方式；同样，JVM也会跟踪\"标记-清扫\"方式，若堆空间出现很多碎片，就会切换回\"停止-复制\"方式。这就是自适应技术。\n\n这是早期Sun版本的垃圾回收器。\n\n#### 分代垃圾收集（Generational Garbage Collection）\n\n上述无论是\"停止-复制\"、\"标记-清扫\"还是\"标记-整理\"对于日益增长的对象列表，效率会逐渐低下。\n\n![image-20190225225057306](/images/image-20190225225057306.png)\n\n堆被分为三代：\n\n- 年轻代(Young Generation)\n\n  内存空间：**eden:S0:S1 = 8:1:1**\n\n  S0和S1**没有先后顺序**，任何一个都可能是**From survivor space**和**To survivor space**\n\n- 年老代(Old Generation)\n\n  内存空间：年老代:年轻代 ≈ 2:1\n\n- 持久代(Permanent Generation)\n\n  用于存放静态文件，如Java类、方法等。持久代对垃圾回收没有显著影响。有些应用可能动态生成或者调用一些class，例如Hibernate等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。\n\n下面说明一下对象在分配内存、老化、回收的过程：\n\n1. 首先，任何新对象创建时内存都会分配在年轻代的**eden space**中，**S0**和**S1**两个**幸存者空间(survivor space)**起初都是空的![image-20190225225802212](/images/image-20190225225802212.png)\n\n2. 当eden space满时，会触发第一次**较小的垃圾回收过程(minor garbage collection，minor GC)**\u0001![image-20190225230110077](/images/image-20190225230110077.png)\n\n   > 实际上MinorGC不一定要等到eden space满了才触发\n\n3. eden space中所有存活对象(referenced objects)被复制到S0，其余对象(unreferenced objects)被视作垃圾，随eden space一起被回收![image-20190225230647640](/images/image-20190225230647640.png)\n\n4. 当下一次minor GC被触发时，eden space执行与第3点中相同的步骤，不过此时存活对象会被复制到S1，同时S0中的存活对象也会被复制到S1，此时S0和eden space都被回收。注意到此时S1有不同老化程度的对象\u0001![image-20190225232204967](/images/image-20190225232204967.png)\n\n5. 再当下一次minor GC被触发时，重复上述操作，幸存者空间变为S0，eden和S1中的存活对象都被复制到S0，同时老化，此时S1和eden space都被回收![image-20190225232407098](/images/image-20190225232407098.png)\n\n6. 当minor GC持续触发到对象老化程度达到一个阈值(此处为8)时，这些对象从年轻代提升到年老代![image-20190225232630665](/images/image-20190225232630665.png)\n\n7. 以上过程涵盖了整个年轻代老化的过程，最终，会在年老代触发**完全的垃圾回收(major gabarge collector, major GC)**，清理并压缩该块内存空间。\n\n   major GC被触发的原因：\n\n   1. 年老代（Tenured）被写满\n\n   2. 持久代（Permanent）被写满\n\n   3. System.gc()被显式调用\n\n   4. 上一次GC之后Heap的各域分配策略动态变化\n\n##### HotSpot JVM的垃圾收集器\n\n**Serial收集器（复制算法)**：新生代单线程收集器，标记和清理都是单线程，优点是简单高效。\n\n**Serial Old收集器(标记-整理算法)**：老年代单线程收集器，Serial收集器的老年代版本。\n\n**ParNew收集器(停止-复制算法)**：新生代收集器，可以认为是Serial收集器的多线程版本,在多核CPU环境下有着比Serial更好的表现。\n\n**Parallel Scavenge收集器(停止-复制算法)**：并行收集器，追求高吞吐量，高效利用CPU。吞吐量一般为99%， 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。\n\n**Parallel Old收集器(停止-复制算法)**：Parallel Scavenge收集器的老年代版本，并行收集器，吞吐量优先\n\n**CMS(Concurrent Mark Sweep)收集器(标记-清扫算法)**：高并发、低停顿，追求最短GC回收停顿时间，cpu占用比较高，响应时间快，停顿时间短，多核cpu 追求高响应时间的选择\n\n【参考：[深入理解JVM(3)——7种垃圾收集器](https://crowhawk.github.io/2017/08/15/jvm_3/)】\n\n## 可变参数列表\n\nJava中的可变参数列表（JSE5之后）的使用与C的使用类似，如下：\n\n```java\npublic class test{\n\tpublic static void main(String[] args){\n\t\tInteger a = 1;\n\t\tInteger b = 2;\n\t\tInteger c = 3;\n\t\tOther.main(a, b);\n\t\tOther.main(a, b, c);\n        Other.main();\n        Other.main(new Object[]{a, b});\n\t\tOther.main(new Object[]{a, b, c});\n\t}\n}\n\nclass Other{\n\tpublic static void main(Object... args){\n\t\tfor (Object s : args){\n\t\t\tSystem.out.println(s + \" \");\n\t\t}\n\t}\n}\n```\n\n如上所示，当输入不同个数参数时，编译器会自动将其**转换成数组**，当参数本身就是数组时，编译器又**不会进行转换**，直接传递给函数。参数为空时编译器便**直接传递一个空Object数组**。\n\n### 可变参数列表的重载\n\n```java\npublic class test{\n\tstatic void f(Character... args){\n\t\tSystem.out.println(\"first\");\n\t}\n\tstatic void f(String... args){\n\t\tSystem.out.println(\"second\");\n\t}\n\tpublic static void main(String[] args){\n\t\tf('a', 'b');\n\t\tf(\"a\", \"b\");\n\t\tf();\n\t}\n}\n```\n\n如上，函数有`f(Character... args)`和`f(String... args)`两种重载方式，此时`f('a', 'b')`和`f(\"a\", \"b\")`都可正常调用，但是`f()`会报错，即两种重载都匹配。\n\n此时可通过为其中一个重载函数添加一个非可变参数（可变参数必须位于参数列表最后）。但这样又会产生新的问题，如下：\n\n```java\npublic class test{\n\tstatic void f(float i, Character... args){\n\t\tSystem.out.println(\"first\");\n\t}\n\tstatic void f(Character... args){\n\t\tSystem.out.println(\"second\");\n\t}\n\tpublic static void main(String[] args){\n\t\tf(1, 'a');\n\t\tf('a', 'b');\n\t}\n}\n```\n\n如上，编译器也会报错，`f('a', 'b')`可匹配两个函数，(可能是)因为`char`类型可提升至`float`类型从而匹配第一个重载函数。\n\n此时可为第二个重载函数也添加一个非可变参数，问题可得到解决。\n\n```java\npublic class test{\n\tstatic void f(float i, Character... args){\n\t\tSystem.out.println(\"first\");\n\t}\n\tstatic void f(char i, Character... args){\n\t\tSystem.out.println(\"second\");\n\t}\n\tpublic static void main(String[] args){\n\t\tf(1, 'a');\n\t\tf('a', 'b');\n\t}\n}\n```\n\n这种用法比较奇怪，因此\"你应该总是只在重载方法的一个版本上使用可变参数列表，或者压根就不是用它\"（《Java编程思想》105页）。\n\n## 内部类\n\n### 内部类对象对外围类对象的访问\n\n当外围类对象创建了一个内部类对象时，此内部类对象必定会秘密地捕获一个指向外围类对象的引用，因此内部类对象可以访问外部类对象的所有成员。\n\n```java\ninterface Selector {\n    boolean end();\n    Object current();\n    void next();\n}\n\npublic class Sequence {\n    private Object[] items;\n    private int next = 0;\n    public Sequence(int size) { items = new Object[size]; }\n    public void add(Object x){\n        if (next < items.length){\n            items[next++] = x;\n        }\n    }\n    private class SequenceSelector implements Selector {\n        private int i = 0;\n        public boolean end() { return i == items.length; }\n        public Object current() { return items[i]; }\n        public void next() { if(i < items.length) i++; }\n    }\n    public Selector selector(){\n        return new SequenceSelector();\n    } \n    public static void main(String[] args){\n        Sequence sequence = new Sequence(10);\n        for (int i = 0; i < 10; i++){\n            sequence.add(Integer.toString(i));\n        }\n        Selector selector = sequence.selector();\n        while(!selector.end()){\n            System.out.print(selector.current() + \" \");\n            selector.next();\n        }\n    }\n}\n```\n\nSequence中的内部类SequenceSelector可以访问Sequence的全部成员，就像SequenceSelector自己拥有这些成员一样。\n\n### 内部类与静态内部类（嵌套类）\n\n#### 创建方法\n\n```java\n// 内部类：DotNew.java\npublic class DotNew {\n    class Inner {\n        Inner(){\n            System.out.println(\"创建内部类\");\n        }\n    }\n    public static void main(String [] args){\n        DotNew dn = new DotNew();\n        DotNew.Inner dni = dn.new Inner();\n    }\n}\n\n// 静态内部类：DotNewStatic.java\npublic class DotNewStatic {\n    static class Inner {\n        Inner() {\n            System.out.println(\"创建静态内部类\");\n        }\n    }\n    public static void main(String[] args){\n        DotNewStatic.Inner inner = new DotNewStatic.Inner();\n    }\n}\n```\n\n### 匿名内部类\n\nJava支持**创建一个继承自某基类的匿名类的对象**，通过new表达式返回的引用被**自动向上转型为对基类的引用**。\n\n匿名内部类可以使用默认构造器生成，也可以使用有参数的构造器。\n\n注意，在匿名内部类中若想使用外部定义的对象，该外部对象的参数引用必须是`final`，如下：\n\n```java\n// Destination.java\npublic interface Destination{\n    String readLabel();\n}\n\n// Parcel9.java\npublic class Parcel9 {\n    public Destination destination(final String dest){// 外部变量dest被引用时需声明为final，否则产生编译时错误\n        return new Destination(){\n            private String label = dest;\n            @Override\n            public String readLabel() {\n                return label;\n            }\n        };\n    }\n    public static void main(String[] args){\n        Parcel9 p = new Parcel9();\n        Destination d = p.destination(\"Tasmania\");\n        System.out.println(d.readLabel());\n    }\n}\n```\n\n> 但是我使用的Java 10中，当dest不声明为final时也不会报错，虽然不会报错，但是当更改dest引用时会报前面所述的编译时错误（Local variable dest defined in an enclosing scope must be final or effectively final）。\n\n> **为什么匿名内部类访问外部变量必须是final的？**\n>\n> 1. 为了避免**外部方法修改引用导致内部类得到的引用值不一致**和**内部类修改引用而导致外部方法的参数值在修改前和修改后不一致**\n>\n> 2. 保证回调函数回调时可访问到变量（**待研究**）\n>\n> 3. 反编译查看其实现细节：\n>\n>    ```java\n>    // 源代码\n>    public interface MyInterface {\n>        void doSomething();\n>    }\n>    public class TryUsingAnonymousClass {\n>        public void useMyInterface() {\n>            final Integer number = 123;\n>            System.out.println(number);\n>    \n>            MyInterface myInterface = new MyInterface() {\n>                @Override\n>                public void doSomething() {\n>                    System.out.println(number);\n>                }\n>            };\n>            myInterface.doSomething();\n>    \n>            System.out.println(number);\n>        }\n>    }\n>    \n>    // 反编译结果\n>    class TryUsingAnonymousClass$1\n>            implements MyInterface {\n>        private final TryUsingAnonymousClass this$0;\n>        private final Integer paramInteger;\n>    \n>        TryUsingAnonymousClass$1(TryUsingAnonymousClass this$0, Integer paramInteger) {\n>            this.this$0 = this$0;\n>            this.paramInteger = paramInteger;\n>        }\n>    \n>        public void doSomething() {\n>            System.out.println(this.paramInteger);\n>        }\n>    }\n>    ```\n>\n>    注意到，number在实际使用时是作为构造函数的参数传入到匿名内部类的，也就是说匿名类内部在使用外部变量时**实际上是做了个\"拷贝\"**或者说**\"赋值\"**。若可以更改，则会造成数据不一致。\n\n## RTTI\n\nRTTI(Run-Time Type Identifier)是Java能在运行时自动识别出某个类型的保证（RTTI在Java运行时维护类的相关信息），是**多态的基础**，由**Class类实现**。\n\n### Class对象\n\n每当编写并且编译一个类时，在与类同名的`.class`文件中会自动产生一个`Class对象`。实现此过程的JVM子系统被称作**类加载器**。\n\nClass对象仅在需要的时候才被加载，也就是所有的类都是**只在对其第一次使用时**，动态加载到JVM中的。所谓第一次使用指的是**对类的非常量静态域的第一次引用。**\n\n- 要注意，**类的构造器**是**隐性非常量静态域**，所以使用new操作符生成对象也是产生这样的Class类引用。\n\n- 与此同时，还可以使用`Class.forName(类名)`产生Class对象的引用，告诉JVM去加载这个类。当JVM未找到这个类，会抛出异常`ClassNotFoundException`。比如在JDBC连接数据库时常常用到的`Class.forName(\"com.mysql.jdbc.Driver\")`，就是告诉JVM去加载MySQL驱动。\n\n- 当已经拥有某个类型的对象（实例）时，可通过调用`getClass()`方法来获取该类型的Class引用。\n\n- 另一种方法，使用**类字面变量**。通过使用`类名.class`可获取此类的Class对象的引用，但是注意，此时**此Class对象还未被初始化**，还需要等到上述的`对类的非常量静态域的第一次引用`这一操作执行时才被初始化。\n\n  > 使用.class方法获取Class对象引用实际包含三个步骤：\n  >\n  > 1. **加载**：类加载器创建Class对象\n  > 2. **链接**\n  > 3. **初始化**：如果该类具有超类，则对其初始化，执行静态初始化器和静态初始化块\n  >\n  > 考虑如下代码：\n  >\n  > ```java\n  > import java.util.Random;\n  > \n  > class Initable {\n  >     static final int staticFinal = 1;\n  >     static final int staticFinal2 = ClassInitialization.rand.nextInt(1000);\n  >     static {\n  >         System.out.println(\"Initializing Initable\");\n  >     }\n  > }\n  > \n  > class Initable2 {\n  >     static int staticNonFinal = 2;\n  >     static {\n  >         System.out.println(\"Initializing Initable2\");\n  >     }\n  > }\n  > \n  > class Initable3 {\n  >     static int staticNonFinal = 3;\n  >     static {\n  >         System.out.println(\"Initializing Initable3\");\n  >     }\n  > }\n  > \n  > public class ClassInitialization {\n  >     public static Random rand = new Random(47);\n  >     public static void main(String[] args) throws ClassNotFoundException {\n  >         // 创建Initable的Class对象的引用，Class对象未初始化\n  >         Class initable = Initable.class;\n  >         // 仍然未初始化，因Initable.staticFinal是常数\n  >         System.out.println(Initable.staticFinal);\n  >         // 触发了Initable的Class对象的初始化\n  >         System.out.println(Initable.staticFinal2);\n  >         // 触发了Initable2的Class对象的初始化\n  >         System.out.println(Initable2.staticNonFinal);\n  >         // 创建Initable3的Class对象的引用，同时会初始化此Class对象\n  >         Class initable3 = Class.forName(\"Initable3\");\n  >         // 此时已初始化，无需再次初始化\n  >         System.out.println(Initable3.staticNonFinal);\n  >     }\n  > }\n  > ```\n\n另外，当我拥有某个Class对象c的时候，我虽然**不知道它确切类型**，但是可以使用`c.newInstance()`来正确地获取c代表的类型的实例。**但是此方法要求对应的类**。\n\n### 泛化的Class对象引用\n\nClass对象可以通过`Class<Type>`的方法产生特定类型的类引用，创建了**使用类型限定后**的Class对象引用**不能再赋值给除本身和子类的其他的Class对象**。\n\n> 注意这里的子类指的是Class对象的继承关系，而不是类本身的继承关系，如`Integer`继承自`Number`，而`Integer Class对象`却不是`Number Class对象`的子类。\n\n使用通配符`Class<?>`优于平凡的`Class`（实际上是等价的），而且会免除编译器警告，看图：![image-20190308105552914](/images/image-20190308105552914.png)\n\n一种更好的用法，`Class<? extends Type>`，这种类型限定比直接`Class<Type>`好的地方在于他产生的Class对象引用**可赋值给Type本身及子类的Class对象**，这种继承关系**是Type所属的继承关系**而**不是对应的Class对象的继承关系**。\n\n### 转型语法（不常用）\n\n```java\nclass Building{}\nclass House extends Building {}\n\npublic class ClassCasts {\n    public static void main(String[] args){\n        Building b = new Building();\n        Class<House> houseType = House.class;\n        House h = houseType.cast(b);\n        h = (House) b;\n    }\n}\n```\n\n如上，使用`houseType.cast(b)`和`(House) b`效果一样，但是执行的工作却不同，具体内部实现尚未学习到。\n\n### 动态的类型检测\n\n#### obj instanceof ClassType\n\n返回一个布尔值，告诉我们某个对象是不是某个特定类型的实例。\n\n#### ClassType.isInstance()\n\n返回一个布尔值，告诉我们某个对象的类型是不是可以被强转为某个特定类型。\n\n#### 区别\n\n区别主要是后者与前者动态等价，看代码：\n\n```java\nclass Father{}\nclass Son extends Father{}\n\npublic class DynamicEqual {\n    public static void main(String[] args){\n        Father father = new Father();\n        Son son = new Son();\n        // instanceof关键词后面必须跟类型的名称，意即其必须首先知道类型名称\n        // if (son instanceof father.getClass()){\n        //     ...\n        // }\n        // isInstance()方法是类对象的方法，任何一种类型的类对象的引用都可调用该方法，简言之，其前面的Class类对象是可动态的。\n        if (father.getClass().isInstance(son)){\n            System.out.println(\"isInstance is Dynamic\");\n        }\n    }\n}\n```\n\n#### 优点\n\n`isInstance()`的存在可以替代`instanceof`，而且可使得代码更简洁。比如说有多个类{A1,A2,A3,…}都继承自A，现有一个A对象实例，要判断其为子类中的哪一个从而产生不同响应时：\n\n- 使用`instanceof`时可能需要使用`switch-case`语句；当需要添加一个子类时，需要修改`switch-case`内部代码。\n- 而使用`isInstance()`时，可创建一个列表存储所有的子类类型，主程序只需要使用一个循环检测该实例即可；当需要添加一个子类时，只需要修改子类类型列表而不用修改程序代码。\n\n### 反射机制\n\n#### 反射与RTTI的区别\n\n- RTTI：编译器在编译时打开和检查`.class`文件（获取类的Class类对象信息）\n- 反射：JVM在运行时打开和检查`.class`文件（编译时可能没有此文件，但是在运行时必须在本地机器或者网络上获取`.class`文件）\n\n#### 类方法提取器\n\n通过Class对象引用：调用`getMethods()`方法获取该类及其父类的方法列表，调用`getConstructors()`方法获取该类的构造方法列表。要注意能获得的方法与该类的访问权限有关，一个**非public类的非public方法是无法被获取的**。\n\n#### 接口与类型信息\n\ninterface关键字的一种重要目标就是允许程序员**隔离构件，进而降低耦合性**。\n\n#### 包权限安全吗？\n\n直接看例子：\n\n```java\n// A.java\npublic interface A{\n    void f();\n}\n\n// HiddenC.java\nclass C implements A{\n\n    @Override\n    public void f() {\n        System.out.println(\"public C.f()\");\n    }\n    public void g(){\n        System.out.println(\"public C.g()\");\n    }\n    void u(){\n        System.out.println(\"package C.u()\");\n    }\n    protected void v(){\n        System.out.println(\"protected C.v()\");\n    }\n    private void w(){\n        System.out.println(\"private C.w()\");\n    }\n}\npublic class HiddenC {\n    public static A makeA(){\n        return new C();\n    }\n}\n\n// HiddenImplementation.java\nimport java.lang.reflect.Method;\npublic class HiddenImplementation {\n    public static void main(String[] args) throws Exception {\n        A a = HiddenC.makeA();\n        a.f();\n        System.out.println(a.getClass().getName());\n        callHiddenMethod(a, \"g\");\n        callHiddenMethod(a, \"u\");\n        callHiddenMethod(a, \"v\");\n        callHiddenMethod(a, \"w\");\n    }\n    static void callHiddenMethod(Object a, String methodName) throws Exception{\n        // 获取a中的方法\n        Method g = a.getClass().getDeclaredMethod(methodName);\n        // 修改该方法的权限\n        g.setAccessible(true);\n        // 调用该方法\n        g.invoke(a);\n    }\n}\n/* output\npublic C.f()\nC\npublic C.g()\npackage C.u()\nprotected C.v()\nprivate C.w()\n*///:)\n```\n\n- 当我知道一个类中有哪些方法时，哪怕是private方法仍然可以在使用`setAccessble(true)`后被调用。\n- 只发布`.class`文件也是没办法避免此问题，`javap -private`命令可以反编译`.class`文件，`-private`参数约定显示所有的成员\n- 同样，内部类和匿名内部类也是没办法避免此情况\n\n## 泛型\n\n### 指定类型有保证吗？\n\n> 在泛型代码内部，无法获得任何有关泛型参数类型的信息。\n\n例如对于`ArrayList<String>`和`ArrayList<Integer>`，二者的实例调用`.getClass()`获取的Class对象时相同的，如下：\n\n```java\nimport java.util.ArrayList;\n\npublic class Erase{\n    public static void main(String[] args){\n        Class<?> s = new ArrayList<String>().getClass();\n        Class<?> i = new ArrayList<Integer>().getClass();\n        System.out.println(s == i);\n        System.out.println(s.getName());\n        System.out.println(s.getTypeParameters());\n    }\n}\n/* Output:\ntrue\njava.util.ArrayList\n[Ljava.lang.reflect.TypeVariable;@68f7aae2\n*///\n```\n\n但是，如果在一个`ArrayList<String>`类型的实例中添加`Integer`会报编译期错误，这个很容易理解（静态类型检查）。但是上述的Class对象相同有给了我们可乘之机：\n\n```java\nimport java.lang.reflect.Method;\nimport java.util.ArrayList;\nimport java.util.Arrays;\n\nclass Apple{\n    @Override\n    public String toString(){\n        return \"This is an apple\";\n    }\n}\n\npublic class ReflectAdd{\n    public static void main(String[] args) throws Exception{\n        ArrayList<String> strings = new ArrayList<>();\n        Class<?> s = strings.getClass();\n        Method method = s.getMethod(\"add\", Object.class);\n        method.invoke(strings, 1);\n        method.invoke(strings, \"2\");\n        method.invoke(strings, 3);\n        method.invoke(strings, new Apple());\n        System.out.println(Arrays.toString(strings.toArray()));\n        for (Object o : strings){\n            System.out.println(o.getClass());\n        }\n    }\n}\n/* Output:\n[1, 2, 3, This is an apple]\nclass java.lang.Integer\nclass java.lang.String\nclass java.lang.Integer\nclass Apple\n*///\n```\n\n我们可以看到上述代码使用反射机制成功的在`ArrayList<String>`里面添加了`Integer`，原因在于`ArrayList`的泛型实现`ArrayList<E>`使其被擦除为`ArrayList<Object>`，从而通过反射机制找到其`add(E e)`方法时，实际上是`add(Object o)`，而我们代码中的`Method method = s.getMethod(\"add\", Object.class);`恰好可以找到包含这样一个参数列表的add方法，后面也就理所当然的可以添加任意类型(甚至是自定义的Apple类)的实例了。\n\n### 与C++的区别\n\n**C++:**\n\n```cpp\n#include <iostream>\nusing namespace std;\n\ntemplate<class T> class Manipulator {\n    T obj;\npublic :\n    Manipulator(T x) { obj = x; }\n    void manipulate() { obj.f(); }\n    void manipulate2() { obj.noF(); }\n};\n\nclass HasF {\npublic:\n    void f(){\n        cout << \"HasF()::f()\" << endl;\n    }\n};\n\nclass DontHaveF{\npublic:\n    void noF(){\n        cout << \"Don't have f()\" << endl;\n    }\n};\n\nint main(){\n    HasF hf;\n    Manipulator<HasF> manipulator(hf);\n    manipulator.manipulate();\n    // manipulator.manipulate2();  无法编译\n    DontHaveF dhf;\n    Manipulator<DontHaveF> manipulator2(dhf);\n    // manipulator2.manipulate();  无法编译\n    manipulator2.manipulate2();\n}\n/* Output:\nHasF()::f()\nDon't have f()\n*///\n```\n\n模板类`Manipulator`在编译时期便可以检测到函数`f()`、`noF()`是在类型参数<T>中存在的，这是在编译器看到声明`Manipulator<HasF> manipulator(hf)`和`Manipulator<DontHaveF> manipulator2(dhf)`所产生的结果。\n\n然而Java中却无法实现这样的操作：\n\n**Java:**\n\n```java\n// HasF.java\npublic class HasF{\n    public void f(){\n        System.out.println(\"HasF.f();\");\n    }\n}\n\n// Manipulation.java\nimport java.lang.reflect.Method;\n\nclass Manipulator<T> {\n    private T obj;\n    public Manipulator(T x) {\n        obj = x;\n    }\n    public void manipulate(){\n        obj.f() // 会报编译错误\n    }\n}\n\npublic class Manipulation{\n    public static void main(String[] args){\n        HasF hf = new HasF();\n        Manipulator<HasF> manipulation = new Manipulator<HasF>(hf);\n        manipulation.manipulate();\n    }\n}\n```\n\n由于Java在编译过程中，`Manipulator<T>`是无法确定其类型参数，只知道他是一个`Object实例`，因此obj**只能调用Object基类所有的公开方法**。若想实现C++的操作有两种办法(目前我已知的只有这两种)。\n\n- 为`T`限定参数类型（给定边界），即声明时指定其所继承的基类：\n\n  ```java\n  class Manipulator<T extends HasF>{\n      ...\n  }\n  ```\n\n- 使用反射机制调用` f()`\n\n  ```java\n  import java.lang.reflect.Method;\n  \n  class Manipulator<T> {\n      private T obj;\n      public Manipulator(T x) {\n          obj = x;\n      }\n      public void manipulate() throws Exception{\n          Class<?> oc = obj.getClass();\n          Method method = oc.getMethod(\"f\");\n          method.invoke(obj);\n      }\n  }\n  \n  public class Manipulation{\n      public static void main(String[] args) throws Exception{\n          HasF hf = new HasF();\n          Manipulator<HasF> manipulation = new Manipulator<HasF>(hf);\n          manipulation.manipulate();\n      }\n  }\n  /* Output:\n  HasF.f();\n  *///\n  ```\n\n### 擦除带来的问题\n\n> 擦除的主要正当理由是从非泛化代码到繁华代码的转变过程，以及在不破坏现有类库的情况下，将泛型融入Java语言。\n\n泛型**不能用于显式地引用运行时类型的操作之中**，例如转型、instanceof、new表达式，因为在静态类型检测之后，泛型就已经被擦除了。\n\n也就是说，需要时刻提醒自己，我只是**看起来好像拥有**有关参数的类型信息而已。实际上，**它只是一个Object！**\n\n### 边界\n\n既然编译器会`擦除`类型信息，那么擦除发生的地点是在哪儿呢？便是所谓的`边界`：对象进入和离开方法的地点，也就是编译器在执行类型检查并插入转型代码的地点。\n\n### 通配符\n\n```java\nimport java.util.Arrays;\nimport java.util.List;\n\nclass Fruit{}\nclass Apple extends Fruit{}\nclass Jonathan extends Apple{}\nclass Orange extends Fruit{}\n\npublic class CompilerIntelligence{\n    public static void main(String[] args){\n        List<? extends Fruit> flist = Arrays.asList(new Apple());\n        Apple a = (Apple) flist.get(0);\n        // Orange o = (Orange) flist.get(0); 运行时错误\n        // flist.add(new Fruit());  编译错误\n        // flist.add(new Apple());  编译错误\n        System.out.println(flist.contains(a));\n        System.out.println(flist.contains(new Apple()));\n        System.out.println(flist.indexOf(new Apple()));\n    }\n}\n/*\ntrue\nfalse\n-1\n*///\n```\n\n对于使用了通配符的`List<? extends Fruit> flist`来说，其需要用到类型参数的方法例如`add()`参数也变成了`<? extends Fruit>`，然而编译器并不能知道这里需要哪一个具体的子类型，于是**编译器拒绝了所有对参数列表中涉及到了通配符的方法的调用，除了构造器。**\n\n## 容器\n\n完整的容器分类法：\n\n![image-20190312200304819](/images/image-20190312200304819.png)\n\n### HashMap\n\n`HashMap`采用了链地址法，也就是**数组+链表**的方式。主干是一个`Entry`数组，链表是为了解决哈希冲突而存在的。`HashMap`中的链表越少，性能越好。\n\n#### Entry数组长度为2的次幂\n\n- 由于在计算`key`的`插入位置`时用到了`hash & (length-1)`，`hash`是`key`计算出来的哈希值，想象一下当`length`不为2的次幂时，`length-1`的二进制必然有`0位`，那么意味着该位为`0`的位置永远不可能被当做`插入位置`，造成了严重的空间浪费。\n- 由于刚才的原因，数组可以使用的位置比数组长度小了很多，意味着进一步增加了碰撞的几率，意即`equal()`操作多了起来，效率也就慢了。\n\n#### resize\n\n`HashMap`当`Entry`数组元素超过`数组大小*loadFactor`时，就会进行数组扩容。`loadFactor`默认值为0.75。此时`Entry`数组大小会扩大一倍，保证了2的次幂大小。\n\n扩容的时候所有的`key`需要重新计算哈希值。\n\n#### JDK1.8优化\n\n由于1.8之前的`HashMap`在`hash`冲突很大时，遍历链表将会效率很低，于是1.8中采用了红黑树部分代替链表，当链表长度到达阈值时，就会改用红黑树存储。\n\n### HashTable\n\n`HashTable`在结构上与`HashMap`基本相同，下面总结其不同点：\n\n- `HashMap`可有`null key`，`HashTable`获取`null key`会报空指针异常\n- `HashTable`有`synchronized`方法同步，线程安全；`HashMap`线程不安全\n- `Hash`值计算方法不同\n- `HashTable`初始大小为`11`，扩容机制为`2*old+1`；`HashMap`初始大小为`16`，扩容机制为`2*old`\n\n### ConcurrentHashMap\n\n`JDK1.7`版本中的`ConcurrentHashMap`比`HashMap`多了一层`Segment`，其中`Segment`继承于`ReentrantLock`：**一次`put`操作会调用`scanAndLockForPut()`方法自旋获取锁**；**而一次`get`操作则不需要加锁，`value`用`volatile`关键词修饰的，保证了内存可见性，每次获取的必定是新值，由于不用加锁，所以很高效**。\n\n`JDK1.8`版本移除了`segment`，有一个`Node`数组相当于`HashMap`中的`Entry`数组。同时采用了`CAS+synchronized关键字`进行`put`操作。`put`操作步骤如下：\n\n- 根据`key`计算出`hashcode`；\n- 判断是否需要进行初始化；\n- `f` 即为当前 `key` 定位出的 `Node`，如果为空表示当前位置可以写入数据，利用 `CAS` 尝试写入，失败则自旋保证成功；\n- 判断是否需要进行扩容；\n- 如果都不满足，则利用 `synchronized` 锁写入数据；\n- 如果数量大于 `TREEIFY_THRESHOLD` 则要转换为红黑树。\n\n## 线程\n\n### Brian Goetz的线程同步规则\n\n> 如果你正在写一个变量，他可能接下来将被另一个线程读取，或者正在读取一个上一次已经被另一个线程写过的变量，那么必须使用同步，并且，**读写线程**都必须用相同的监视器锁同步。\n\n### Executor\n\nExecutor用来管理Thread对象，简化了并发编程，允许管理异步任务的执行，而无须显式管理线程的声明周期。\n\n```java\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class CachedThreadPool {\n    public static void main(String[] args){\n        ExecutorService exec = Executors.newCachedThreadPool();\n        for (int i = 0; i < 5; i++){\n            exec.execute(new LiftOff());\n        }\n        exec.shutdown();\n    }\n}\n/* Output:\n#4(9).#2(9).#1(9).#2(8).#3(9).#4(8).#0(9).#1(8).#2(7).#3(8).#4(7).#0(8).#1(7).#2(6).#3(7).#4(6).#0(7).#1(6).#2(5).#3(6).#4(5).#0(6).#1(5).#2(4).#3(5).#4(4).#0(5).#1(4).#2(3).#3(4).#4(3).#0(4).#1(3).#2(2).#3(3).#4(2).#0(3).#1(2).#2(1).#3(2).#4(1).#0(2).#1(1).#2(LiftOff!).#3(1).#4(LiftOff!).#0(1).#1(LiftOff!).#0(LiftOff!).#3(LiftOff!).\n*///\n```\n\n### 线程池\n\n线程池的作用是**限制系统中执行线程的数量**，根据系统情况可以**自动或手动**设置线程数量，达到最佳运行效果。线程池中的线程若出现异常，会自动补充一个新线程以代替。\n\n- `newSingleThreadExecutor()`：创建一个单线程的线程池，所有的任务在等待队列中等待该线程。\n- `newFixedThreadPool()`：创建固定大小的线程池。\n- `newCachedThreadPool()`：创建一个可缓存的线程池。会根据任务数量自动添加和回收线程，线程池的大小依赖于JVM能够创建的最大线程大小。\n- `newScheduledThreadPool()`：创建一个大小无限的线程池，此线程支持定时以及周期性执行任务的需求。\n\n### 任务的返回值\n\n通常实现`Runnable`接口的类是没有返回值的，要想任务在完成时返回一个值可实现`Callable<T>`接口，其泛型类型参数表示方法`call()`的返回值，并且需要使用`ExecutorService.submit()`方法调用他。\n\n```java\nimport java.util.ArrayList;\nimport java.util.concurrent.*;\n\nclass TaskWithResult implements Callable<String> {\n    private int id;\n\n    public TaskWithResult(int id) {\n        this.id = id;\n    }\n\n    public String call() {\n        return \"result of TaskWithResult\" + id;\n    }\n}\n\npublic class CallableDemo {\n    public static void main(String[] args) {\n        ExecutorService exec = Executors.newCachedThreadPool();\n        ArrayList<Future<String>> results = new ArrayList<>();\n        for (int i = 0; i < 10; i++) {\n            results.add(exec.submit(new TaskWithResult(i)));\n        }\n        for (Future<String> fs : results) {\n            try {\n                System.out.println(fs.get());\n            } catch (InterruptedException | ExecutionException e) {\n                System.err.println(e);\n            } finally {\n                exec.shutdown();\n            }\n        }\n    }\n}\n/* Output：\nresult of TaskWithResult0\nresult of TaskWithResult1\nresult of TaskWithResult2\nresult of TaskWithResult3\nresult of TaskWithResult4\nresult of TaskWithResult5\nresult of TaskWithResult6\nresult of TaskWithResult7\nresult of TaskWithResult8\nresult of TaskWithResult9\n*///\n```\n\n`ExecutorService`对象的`submit()`方法会返回一个`Future<T>`对象，泛型类型参数即是实现`Callable<T>`的类型参数。`get()`方法会返回结果，若任务未完成，`get()`会阻塞。\n\n### 优先级\n\n优先权不会导致死锁，优先级较低的线程仅仅是执行的频率较低。\n\n但是注意优先级高的线程也有几率比优先级底的线程执行的少。\n\n优先级是否起作用也与操作系统及虚拟机版本相关联，会随着不同的线程调度器而产生不同的含义。\n\n### Thread.yield()可靠吗？\n\n`Thread.yield()`源码中提及了该方法的效果：**当前线程会给线程调度器一个暗示，说明我愿意让出当前资源供你调度，但是线程调度器可自由的选择是否忽略其暗示。**意即此处的`让步`只是一厢情愿，发出让步的线程同样可以继续执行。\n\n### 后台线程\n\n后台线程**并不属于程序中不可或缺的部分**。当所有的非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程。\n\n执行`main()`就是一个非后台线程，当`main()`没有执行结束时，程序就不会终止。\n\n后台线程创建的线程也将是后台线程。\n\n同时要注意在后台线程的`run()`方法中若有`finally`子句，其中的语句也不一定会执行。因为随着非后台线程的结束，后台线程会突然终止。\n\n### Thread还是Runnable\n\n创建多线程任务可以继承`Thread`类重写其`run()`方法，也可以实现`Runnable`接口实现其`run()`方法。\n\n实际应用中，`Runnable`还是比较有优势的：\n\n- 避免了由于Java的单继承体系带来的局限（实际上继承Thread也是可以避免，使用内部类）\n- 多个线程区处理同一资源，而非独立处理（这句话有问题）\n\n注意，一开始在理解这里的时候我出现了误解，什么叫**处理同一资源**，意思指的是Thread类无法达到资源共享的目的，而Runnable可以。但是在使用线程池的时候，Thread又可以了**(待确认)**，如下：\n\n```java\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\nclass TestThread extends Thread {\n    private int val = 10;\n    public void run(){\n        while(true){\n            System.out.println(Thread.currentThread() + \"-- val: \" + val--);\n            Thread.yield();\n            if  (val <= 0)\n                return;\n        }\n    }\n}\n\nclass TestRunnable implements Runnable {\n    private int val = 10;\n    @Override\n    public void run() {\n        while(true){\n            System.out.println(Thread.currentThread() + \"-- val: \" + val--);\n            Thread.yield();\n            if (val <= 0)\n                return;\n        }\n    }    \n}\n\npublic class TestRunnableAndThread {\n    public static void main(String[] args){\n        Runnable runnable = new TestRunnable();\n        Thread thread = new TestThread();\n        // a.只有1个线程处理一个数据\n        thread.start();\n        thread.start();\n        thread.start();\n        thread.start();\n        thread.start();\n        // b.5个不同线程处理不同数据\n        new TestThread().start();\n        new TestThread().start();\n        new TestThread().start();\n        new TestThread().start();\n        new TestThread().start();\n        // c.5个不同线程处理相同数据\n        new Thread(runnable).start();\n        new Thread(runnable).start();\n        new Thread(runnable).start();\n        new Thread(runnable).start();\n        new Thread(runnable).start();\n        // d.5个不同线程处理相同数据\n        ExecutorService execRun = Executors.newCachedThreadPool();\n        for (int i = 0; i < 5; i++)\n            execRun.execute(runnable);\n        // e.5个不同线程处理5个不同数据\n        ExecutorService execRun2 = Executors.newCachedThreadPool();\n        for (int i = 0; i < 5; i++)\n            execRun2.execute(new TestRunnable());\n        // f.5个不同线程处理相同数据\n        ExecutorService execThread = Executors.newCachedThreadPool();\n        for (int i = 0; i < 5; i++){\n            execThread.execute(thread);\n        }\n        // g.5个不同线程处理5个不同数据\n        ExecutorService execThread2 = Executors.newCachedThreadPool();\n        for (int i = 0; i < 5; i++)\n            execThread2.execute(new TestThread());\n        // i.5个不同线程处理相同数据\n        ExecutorService execThread2 = Executors.newCachedThreadPool();\n        for (int i = 0; i < 5; i++)\n            execThread2.execute(new Thread(runnable));\n\n        execRun.shutdown();\n        execRun2.shutdown();\n        execThread.shutdown();\n        execThread2.shutdown();\n    }\n}\n```\n\n其中：**c、d、i**实际上是相同的，**b、g**是相同的，而**a**和**f**看起来相同，但是实际作用却差别很大，待研究。\n\n实际上，**a**是错误的用法，**b**、**c**基本上不用，而且，注意当需要共享数据的时候，通常不会在类中定义共享变量，而需要一个**线程安全的外部对象**。\n\n### 共享资源\n\n#### Synchronized\n\n冲突是多线程问题必须解决的任务，Java使用`synchronized`关键字标识访问共享资源的方法，JVM负责跟踪对象被加锁的次数，注意，当对象被解锁（完全释放时）其加锁计数为0，显然此时所有任务都有几率向其加锁，当**某一个任务第一次给该对象加锁时，计数变为1**，此后**只有这个相同的任务能继续给该对象加锁**，计数会递增；**每当离开一个synchronized方法时，计数递减**，直到计数变为0时，对象被解锁。要注意，**每个访问该临界资源的方法都必须被同步**，否则就不会正确地工作。\n\n通常`synchronized`关键字标识方法时，是在`this`上面同步，也可在方法中使用`synchronized(synObject){}`域，**以在特定的对象上同步**，因此不同对象上的锁是相互无关的。\n\n#### Lock\n\nLock对象必须被显式地创建、锁定和释放。\n\n```java\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class MutexEvenGenerator {\n    private int currentEvenValue = 0;\n    // 显式声明\n    private Lock lock = new ReentrantLock();\n    public int next() {\n        // lock()方法创建临界资源\n        lock.lock();\n        try {\n            ++currentEvenValue;\n            Thread.yield();\n            ++currentEvenValue;\n            // return语句必须出现在try子句中\n            return currentEvenValue;\n        }finally {\n            // unlock()方法完成清理工作\n            lock.unlock();\n        }\n    }\n}\n```\n\n与`synchronize`相比，显式的`Lock`优点在于可以使用`finally子句`将系统维护在正常的状态，而在使用`synchronize`关键字时，某些事物失败了就会抛出异常。\n\n```java\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.ReentrantLock;\npublic class AttemptLocking{\n    private ReentrantLock lock = new ReentrantLock();\n    public void untimed() {\n        boolean captured = lock.tryLock();\n        try {\n            System.out.println(\"untimed - tryLock(): \" + captured);\n            System.out.println(\"untimed - isHeldByCurrentThread(): \" + lock.isHeldByCurrentThread());\n        } finally {\n            if (captured) \n                lock.unlock();\n        }\n    }\n    public void timed() {\n        boolean captured = false;\n        try {\n            captured = lock.tryLock(2, TimeUnit.SECONDS);\n        } catch(InterruptedException e){\n            throw new RuntimeException(e);\n        }\n        try {\n            System.out.println(\"timed - tryLock(2, TimeUnit.SECONDS): \" + captured);\n            System.out.println(\"timed - isHeldByCurrentThread(): \" + lock.isHeldByCurrentThread());\n        } finally {\n            if (captured)\n                lock.unlock();\n        }\n    }\n    public static void main(String[] args){\n        final AttemptLocking al = new AttemptLocking();\n        al.untimed();\n        al.timed();\n        // 匿名内部类创建单独的Thread来获取锁，而未释放\n        new Thread(){\n            {setDaemon(true);}\n            public void run(){\n                al.lock.lock();\n                System.out.println(\"acquired\");\n                System.out.println(\"main - isHeldByCurrentThread(): \" + al.lock.isHeldByCurrentThread());\n            }\n        }.start();\n        Thread.yield();\n        al.untimed();\n        al.timed();\n    }\n}\n/* Output:\nuntimed - tryLock(): true\nuntimed - isHeldByCurrentThread(): true\ntimed - tryLock(2, TimeUnit.SECONDS): true\ntimed - isHeldByCurrentThread(): true\nacquired\nmain - isHeldByCurrentThread(): true\nuntimed - tryLock(): false\nuntimed - isHeldByCurrentThread(): false\ntimed - tryLock(2, TimeUnit.SECONDS): false\ntimed - isHeldByCurrentThread(): false\n*///\n```\n\n看代码就很容易理解了。\n\n#### 原子性与易变性\n\n原子操作**有可能无需同步机制**，因为操作是不可分的，一次操作进行的时候不会有其他操作的介入，但是实现原子操作是很难的，或者说原子操作是较少存在的。同时，即使操作是原子性的，操作的修改也可能暂时性地存储在本地处理器的缓存中，对于其他任务有可能是**不可视的**，因此不同的任务对应用状态有不同的视图。\n\n**volatile关键字**确保了前面提及的可视性，以及当一个域被声明为volatile时，那么**只要对这个域产生了写操作，所有的读操作都可以看到这个修改**。即使使用了本地缓存，volatile域的修改也会被立即写入到主存中。\n\n所以**非volatile域**上的原子操作未刷新到主存中去，因此其他读操作未必会看到新值。\n\n因此多个任务在同时访问某个域时，**要么使用volatile关键字限定，要么经由同步机制访问**，以保证一致性。\n\n```java\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class AtomicityTest implements Runnable {\n    private int i = 0;\n    public int getValue() { \n        return i;\n    }\n    private void evenIncrement() {\n            i++; i++;\n    }\n    @Override\n    public void run() {\n        while (true)\n            evenIncrement();\n    }\n    public static void main(String[] args){\n        ExecutorService exec = Executors.newCachedThreadPool();\n        AtomicityTest at = new AtomicityTest();\n        exec.execute(at);\n        while (true){\n            int val = at.getValue();\n            if (val%2 != 0){\n                System.out.println(val);\n                System.exit(0);\n            }\n        }\n    }\n}\n```\n\n看上面这个例子，程序找到奇数时便终止，理想状态下，通过`evenIncrement()`加2，`i`应该始终为偶数，但是由于缺少同步机制，可能导致不稳定的中间状态被读取即获取到奇数，同时`i`也不是`volatile`的，因此还存在可视性问题（当然，这里仅仅使用`volatile`限定`i`是不够的，因为`i++`操作不是原子性的）。下面使用`Lock`显式加锁以实现同步：\n\n```java\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class AtomicityTest implements Runnable {\n    private int i = 0;\n    private Lock lock = new ReentrantLock();\n    public int getValue() { \n        try {\n            lock.lock();\n            return i; \n        } finally {\n            lock.unlock();\n        }\n    }\n    private void evenIncrement() { \n        try {\n            lock.lock();\n            i++; i++; \n        } finally {\n            lock.unlock();\n        }\n    }\n    @Override\n    public void run() {\n        while (true)\n            evenIncrement();\n    }\n    public static void main(String[] args){\n        ExecutorService exec = Executors.newCachedThreadPool();\n        AtomicityTest at = new AtomicityTest();\n        exec.execute(at);\n        while (true){\n            int val = at.getValue();\n            System.out.println(val);\n            if (val%2 != 0){\n                System.out.println(val);\n                System.exit(0);\n            }\n        }\n    }\n}\n```\n\n### 原子类\n\n上面说到**原子操作是较少的**，而`JSE5`引入了`AtomicInteger`、`AtomicLong`、`AtomicReference`等特殊的原子性变量类，这些类的一些方法在某些机器上可以是原子的。通常用在性能调优方面。\n\n### ReetrantLock\n\nReentrantLock是一个**可重入**的**互斥锁**，又被称为\"**独占锁**\"。\n\n> **可重入锁**指的是某个线程获取锁之后，在执行相关的代码块时可继续调用加了同样的锁的方法，理解为嵌套锁。反之，不可重入锁称作自旋锁。\n>\n> **独占锁**指的是同一时间点锁只能被一个线程获取。\n\n同时ReentrantLock也分为**公平锁**和**非公平锁**，它们的区别体现在获取锁的机制是否公平。公平锁通过一个FIFO等待队列管理等待获取该锁的所有进程，而非公平锁不管是否在队列中，都直接获取该锁。\n\n### ReentrantReedWriteLock\n\n顾名思义，ReentrantReadWriteLock维护了**读取锁**和**写入锁**。\n\n读取锁用于只读操作，是**共享锁**，能被多个线程获取；\n\n写入锁用于写入操作，是**独占锁**，只能被一个线程获取。\n\n### 线程状态\n\n- 新建（new）\n- 就绪（Runnable）\n- 阻塞（Blocked）\n  - 调用`sleep(milliseconds)`方法使任务休眠\n  - 调用`wait()`方法挂起\n  - 等待输入输出完成\n  - 获取锁失败\n- 死亡（Dead）\n\n### 线程协作\n\n#### wait()\n\n与`sleep()`和`yield()`不同，调用`wait()`时**需要释放当前线程获取的锁**，由于某个条件不成立使得当前线程进入阻塞状态，直到其他修改使得此条件发生了变化调用了`notifyAll()`方法时，线程被唤醒。\n\n但是要注意，使用`wait()`的时候需要用`while`循环包围：\n\n- 为了检查线程是否被意外唤醒\n\n#### notifyAll()\n\n`notifyAll()`用来唤醒等待**某个锁**的所有**挂起的任务**。`等待某个锁`指的是某些需要获取共同的锁的线程，`notifyAll()`可以唤醒这些线程，而不是程序中所有被挂起的线程。\n\n### 死锁\n\n多个并发进程因争夺系统资源而产生相互等待的现象。\n\n四个必要条件：\n\n- 互斥\n- 占有且等待\n- 不可抢占\n- 循环等待\n\n### 免锁容器\n\n免锁容器的策略是：对容器的修改可以与读取操作**同时发生**，只要读取者只能看到完成修改的结果即可。修改时在容器数据结构的某个部分的一个单独的副本上执行的，并且这个副本在修改过程中是不可视的。只有当修改完成时，被修改的结构才会自动地与主数据结构进行交换，之后读取者就可以看到这个修改了。\n\n这些容器允许并发的读取和写入，但是在任何修改完成之前，读取者仍然是不能够看到它们的。\n\n#### 乐观锁\n\n每次拿数据的时候认为别人不会修改，所以不会上锁，但是在更新的时候会判断此期间有没有别人更新这个数据。上述有提到的原子类就是使用了CAS实现的乐观锁。\n\n#### 悲观锁\n\n每次拿数据的时候都认为别人会修改，所以每次拿数据的时候都会上锁。`synchronized`关键字的实现就是悲观锁。\n\n#### CAS(Compare And Swap)技术\n\nCAS是用来实现乐观锁的一种方法，原理见[这里](https://www.jianshu.com/p/ae25eb3cfb5d)。\n\nCAS机制使用3个基本操作数：**内存地址`V`**，**旧的预期值`A`**，**要修改的新值`B`**。\n\n更新一个变量的时候，只有当`A`和`V`的实际值相同时，才会将`V`对应的值修改为`B`。\n\n缺点：\n\n- ABA问题：链表的头在变化了两次后恢复了原值，但是不代表链表就没有发生变化\n- 循环时间长开销大\n- 只能保证一个共享变量的原子性","tags":["Java"],"categories":["archives"]},{"title":"数据库与内存数据库实验报告","url":"/2019/03/05/数据库与内存数据库实验报告/","content":"\n## 一、实验前准备\n\n### 机器配置\n\n![image-20190114060005845](/images/image-20190114060005845.png)\n\n### 时间计算标准\n\n#### SQL执行过程\n\n首先，本实验的目的是优化数据库，减少数据库语句执行的时间，在此之前，我们要明白一点`数据库执行时间`这句话包含了哪些东西。我们从数据库执行一条SQL语句的过程来看，对于MySQL、Oracle、TimesTen这些具有内部优化的数据库来说，一般的执行步骤是：\n\n![image-20190113214926175](/images/image-20190113214926175.png)\n\n而我们的关注点应放在语句执行这一步骤上。\n\n#### 语句执行步骤进一步深入\n\n##### MySQL\n\nMySQL的执行时间为以下项目的加和：\n\n| State                   | Desription                     |\n| ----------------------- | ------------------------------ |\n| 1. Checking permissions | 检查用户的权限                 |\n| 2. Opening tables       | 打开表                         |\n| 3. Init                 | 初始化过程                     |\n| 4. System lock          | 获取锁                         |\n| 5. Optimizing           | 优化SQL语句                    |\n| 6. Statistics           | 分析SQL语句                    |\n| 7. Preparing            | 准备执行条件                   |\n| 8. Executing            | 执行SQL语句                    |\n| 9. Sending data         | 进行磁盘的IO以及数据的发送返回 |\n| 10. End                 | 执行结束                       |\n| 11. Closing tables      | 关闭表                         |\n| 12. Freeing items       | 释放资源                       |\n| 13. Cleaning up         | 清理缓存以及临时空间           |\n\n##### Oracle\n\n一条SQL语句在进入`语句执行`这一步骤之后，若不在高速缓存中，数据库会从数据文件中把`所在位置`移动到`高速缓存`中而后返回给客户端。这也就意味着，同一条语句在以后的执行中都只从高速缓存取数据（前提是高速缓存`未被清除`）。这样想的话，我们要做的优化应该是一条SQL语句在第一次进入数据库时数据库作出的应答。\n\n那么，我们通过数据库工具来查看执行的SQL语句的时间应该是不准的：**因为我们不知道这条语句是不是第一次执行，或者说我们不知道高速缓存中有没有我们需要的数据**。这里我们选择使用Oracle的执行计划来看SQL语句的准确的执行过程以及其`开销`。如下图：\n\n![image-20190113211220925](/images/image-20190113211220925.png)\n\n我们的关注点在上图中的`COST`，cost是Oracle里判定效率的唯一标准，Oracle的优化器会计算当前SQL语句的最低cost方案，而后为其选择执行计划。Oracle中定义了语句的一次执行开销`cost = CPU cost + IO cost`，对于cost，我们可以理解为一次过程所需要访问的Block数量，那么执行时间就是`t = Block数量 * Block处理时间`。\n\n后续实验过程中的Oracle部分我们都是通过执行计划及cost来做对比。为此我们写了一个procedure来记录一条语句执行计划中记录的cost：\n\n```plsql\n-- 计算query的cost\ncreate or replace procedure calc_cost(query_ varchar2, func_ number, desc_ varchar2) is\n  cpu_cost number := 0;\n  io_cost number := 0;\n  cost_ number := 0;\n  -- 一条SQL语句的唯一标识\n  hash_v number := 0;\n  -- 获取上述标识\n  select_v_sql varchar2(255) := 'select hash_value into :x from v$sql a where a.SQL_TEXT like '':y''';\n  -- 获取cost\n  select_v_sql_plan varchar2(255) := 'select max(cpu_cost) , max(io_cost) into :x :y from V$SQL_PLAN a where hash_value=:z';\n  -- 结果保存\n  insert_result varchar2(255) := 'insert into t_cost_record values(:x,:y,:z,:a,:b,:c)';\nbegin\n  execute immediate select_v_sql using hash_v, query_;\n  execute immediate select_v_sql_plan using cpu_cost, io_cost, cost_;\n  execute immediate insert_result using id_seq.nextval, func_, cpu_cost, io_cost, cost_, desc_;\nend;\n```\n\n##### TimesTen\n\n对于TimesTen来说，不如Oracle的优化器来的智能，它完全靠速度制胜。Oracle中我们讨论了执行时间`t = Block数量 * Block处理时间`，TimesTen就是在Block处理时间上有很大的优势。遗憾的是TimesTen中没有作为本身的高速缓存这一说，这也就意味着一条SQL语句进入TimesTen时都要经过`SQL Prepare -> SQL Execution -> SQL Fetch `这一完整的过程，如下：\n\n![image-20190114052126486](/images/image-20190114052126486.png)\n\n## 二、MySQL实验过程\n\n功能：查询电影评论平均分排行前一百的电影\n\n### SQL语句\n\n```mysql\nselect  m.name_, sum(c1.score) as movie_avg_comment_score\nfrom movie m  , comment_1 c1\nwhere m.id_ = c1.movie_id\ngroup by m.name_\norder by movie_avg_comment_score desc\nlimit 100;\n```\n\n### 仅有主键索引\n\n执行之后得到如下的时间消耗：\n\n![time_3.2_4min](/images/time_3.2_4min.png)\n\n这个时间相比其他数据库慢得多（oracle 约4s)，不符合预期的耗时，且在执行时mysqld的cpu占用率非常高。于是根据以下步骤查看sql执行慢的原因。\n\n### MySQL进程表\n\n使用`show processlist`命令查看正在执行的sql语句列表：\n\n![process_list](/images/process_list.png)\n\n可以看到当前执行的语句就是我们的目标语句，并且没有其他语句在与当前查询语句竞争资源，所以应该把语句执行过慢点原因定位到查询语句本身。\n\n### 解释执行计划\n\n通过查看process list得知对应语句有问题之后，使用`describe`命令查看当前SQL语句的执行计划，MySQL的执行计划与其他相关参数：\n\n![explain_3.2](/images/explain_3.2.png)\n\n可以看到在执行计划中，movie表有可选的主码索引，但是在这个场景中mysql并没有选择使用主码索引，没有使用索引是导致时间过慢点一个原因，于是可以考虑在电影名字字段上建立索引。\n\n### 执行过程\n\n为了进一步查看SQL语句具体的系统能耗分布，我们选择使用`profiling`来分析我们SQL语句的执行过程，在没有创建其他索引的情况下我们得到如下的时间消耗分析：\n\n![detail_3.2](/images/detail_3.2.png)\n\n我们可以看到其中能耗占比最高的是 `Sending data`项，查看官方文档相关解释：\n\n> The thread is reading and processing rows for a `SELECT` statement, and sending data to the client. Because operations occurring during this state tend to perform large amounts of disk access (reads), it is often the longest-running state over the lifetime of a given query.\n>\n> 该线程正在读取和处理SELECT语句的行，并将数据发送到客户端。 由于在此状态期间发生的操作往往会执行大量磁盘访问（读取），因此它通常是给定查询生命周期中运行时间最长的状态\n\n所以这个与我们的磁盘IO的速度以及网络的传输速度有关，磁盘的IO除了受到硬件本身的限制之外还会与数据库的索引有关，更换性能更好的磁盘或者建立适当的索引以减少磁盘IO数量都可以提高查询语句的执行速度。\n\n### 建立索引\n\n根据以上分析过程得到的结论，我们在电影表的名字字段上建立合适的索引，我们在mysql中选择了B-Tree索引。\n\n建立索引之后再查看相同SQL语句的执行计划：\n\n![explain_3.2_index](/images/explain_3.2_index.png)\n\n`key`字段上的值从原来的`null` 变成了我们刚刚创建的索引。\n\n执行该SQL语句，并在结束后使用`Profiling`查看优化后的执行时间：\n\nsending data: 从磁盘读取数据，将数据返回，表示磁盘IO\n\ncreate index：使用临时表来处理select语句\n\n![detail_index_3.2](/images/detail_index_3.2.png)\n\n可以看到`Sending data`的值明显小于优化前，总的执行时间也变为优化前的1/5，所以增加索引能够在很大程度上加快查询的速度。\n\n### 实验结论\n\n综合其他实验，在大数据的处理上MySQL数据库的性能远不如ORACLE及TIMESTEN数据库，有数十倍的耗时差距，而且MySQL作为一个轻量级的数据库，支持的索引类型也少于其他两个数据库，在SQL语句的优化方面也不如ORACLE数据库那般强大。所以在当前的实验环境下我们更倾向于使用ORACLE数据库与TIMESTEN数据库进行对比。\n\n## 三、Oracle实验过程\n\n### 实验1：SQL各子句条件顺序对查询效率的影响\n\n#### 查询语句\n\n```sql\nSELECT T_MOVIE.NAME_, T_MOVIE.YEAR_ FROM T_MOVIE,T_MOVIE_REGION,T_REGION\nWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_ID AND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_ID\nAND T_REGION.NAME_='美国' AND T_MOVIE.SCORE_>6;\n```\n\n#### 实验方式\n\n通过对MySQL、Oracle、TimesTen中SQL语句中select、from、where子句的排序顺序进行调换，观察执行计划的改变\n\n#### 实验结果\n\n1. SELECT子句中，结果集的排序方式不会影响执行计划\n2. FROM子句中，各个表的排序方式不会影响执行计划\n3. WHERE子句中，各个条件的排序方式不会影响执行计划，优化器会首先将筛选条件应用于表进行过滤，最后逐次执行表的连接。\n\n#### 分析\n\n自Oracle6以来，一直采用RBO（Rule-Based Optimization 基于规则的优化器），其基于一套严格死板的使用规则。由于其对于规则的崇尚性，SQL语句的写法则尤为重要。而自Oracle8以来，Oracle引入了一种新的优化方式，即CBO（Cost-Based Optimization 基于代价的优化器），从Oracle 10g开始RBO被完全舍弃。使用CBO优化器时，对SQL语句的要求变得没有那么苛刻，优化器会选择开销比较小的方式执行，而不由用户所写的表的顺序、条件的顺序决定。MySQL与TimesTen的优化器也是如此，有其自己的选择。\n\n> ### 连接方式和连接顺序\n>\n> **连接顺序**：连接顺序表明以哪张表为驱动表来连接其他表的先后顺序。即以某张表为基点，根据其中的信息再去访问其他的表。\n>\n> **连接方式**：简单来讲，就是两个表获得满足条件的数据时的连接过程。主要有三种表连接方式，嵌套循环（NESTED LOOPS）、哈希连接（HASH JOIN）和排序-合并连接（SORT MERGE JOIN）。\n>\n> #### 排序-合并连接\n>\n> 假设有查询：select a.name, b.name from table_A a join table_B b on (a.id = b.id)\n>\n> 内部连接过程：\n>\n> a) 生成 row source 1 需要的数据，按照连接操作关联列（如示例中的a.id）对这些数据进行排序\n>\n> b) 生成 row source 2 需要的数据，按照与 a) 中对应的连接操作关联列（b.id）对数据进行排序\n>\n> c) 两边已排序的行放在一起执行合并操作（对两边的数据集进行扫描并判断是否连接）\n>\n> 延伸：\n>\n> 如果示例中的连接操作关联列 a.id，b.id 之前就已经被排过序了的话，连接速度便可大大提高，因为排序是很费时间和资源的操作，尤其对于有大量数据的表。\n>\n> 故可以考虑在 a.id，b.id 上建立索引让其能预先排好序。**不过遗憾的是**，由于返回的结果集中包括所有字段，所以通常的执行计划中，即使连接列存在索引，也不会进入到执行计划中，除非进行一些特定列处理（如仅仅只查询有索引的列等）。\n>\n> 排序-合并连接的表无驱动顺序，谁在前面都可以；\n>\n> 排序-合并连接**适用**的连接条件有： **<   <=   =   >   >= ，不适用**的连接条件有： **<>    like**\n>\n> #### 嵌套循环\n>\n> 内部连接过程：\n>\n> a) 取出 row source 1 的 row 1（第一行数据），遍历 row source 2 的所有行并检查是否有匹配的，取出匹配的行放入结果集中\n>\n> b) 取出 row source 1 的 row 2（第二行数据），遍历 row source 2 的所有行并检查是否有匹配的，取出匹配的行放入结果集中\n>\n> c) ……\n>\n> 若 row source 1 （即驱动表）中返回了 N 行数据，则 row source 2 也相应的会被全表遍历 N 次。\n>\n> 因为 row source 1 的每一行都会去匹配 row source 2 的所有行，所以当 row source 1 返回的行数尽可能少并且能高效访问 row source 2（如建立适当的索引）时，效率较高。\n>\n> 嵌套循环的表有驱动顺序，注意选择合适的驱动表。嵌套循环连接有一个其他连接方式没有的好处是：**可以先返回已经连接的行**，而不必等所有的连接操作处理完才返回数据，这样可以实现快速响应。\n>\n> 应尽可能使用限制条件（Where过滤条件）使驱动表（row source 1）返回的行数尽可能少，同时在匹配表（row source 2）的连接操作关联列上建立唯一索引（UNIQUE INDEX）或是选择性较好的非唯一索引，此时嵌套循环连接的执行效率会变得很高。若驱动表返回的行数较多，即使匹配表连接操作关联列上存在索引，连接效率也不会很高。\n>\n> #### 哈希连接\n>\n> **哈希连接只适用于等值连接（即连接条件为  =  ）**\n>\n> HASH JOIN对两个表做连接时并不一定是都进行全表扫描，其并不限制表访问方式；\n>\n> 内部连接过程简述：\n>\n> a) 取出 row source 1（驱动表，在HASH JOIN中又称为Build Table） 的数据集，然后将其构建成内存中的一个 Hash Table（Hash函数的Hash KEY就是连接操作关联列），创建Hash位图（bitmap）\n>\n> b) 取出 row source 2（匹配表）的数据集，对其中的每一条数据的连接操作关联列使用相同的Hash函数并找到对应的 a) 里的数据在 Hash Table 中的位置，在该位置上检查能否找到匹配的数据\n\n### 实验2：B树索引与位图索引的比较\n\n#### sql语句\n\n```sql\n-- 小基数\nSELECT T_MOVIE.NAME_, T_MOVIE.YEAR_\nFROM T_MOVIE,T_MOVIE_REGION,T_REGION\nWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_ID\nAND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_ID\nAND T_REGION.NAME_='美国'\nAND T_MOVIE.SCORE_>6;\n-- 大基数\nSELECT T_MOVIE.NAME_, T_MOVIE.YEAR_\nFROM T_ACTOR,T_ACT,T_MOVIE\nWHERE T_ACTOR.NAME_='Tom Byron'\nAND T_MOVIE.SCORE_>6\nAND T_ACTOR.ID_=T_ACT.ACTOR_ID\nAND T_MOVIE.ID_=T_ACT.MOVIE_ID;\n```\n\n#### 索引语句\n\n```sql\n-- B树\nCREATE INDEX IX_MOVIE_SCORE ON T_MOVIE(SCORE_);\nCREATE INDEX IX_MOVIE_NAME ON T_MOVIE(NAME_);\nCREATE INDEX IX_ACTOR_NAME ON T_ACTOR(NAME_);\n-- BitMap\nCREATE BITMAP INDEX IXBM_MOVIE_NAME ON T_MOVIE(NAME_);\nCREATE BITMAP INDEX IXBM_MOVIE_SCORE ON T_MOVIE(SCORE_);\nCREATE BITMAP INDEX IXBM_ACTOR_NAME ON T_ACTOR(NAME_);\n```\n\n#### 查询消耗\n\nB树索引（小基数）\n\n![B树索引](/images/1-B%E6%A0%91%E7%B4%A2%E5%BC%95.png)\n\n位图索引（小基数）\n\n![位图索引](/images/1-%E4%BD%8D%E5%9B%BE%E7%B4%A2%E5%BC%95.png)\n\n不加索引（大基数）\n\n![image-20190113230831573](/images/image-20190113230831573.png)\n\nB树索引（大基数）\n\n![image-20190113230717837](/images/image-20190113230717837.png)\n\n位图索引（大基数）\n\n![image-20190113230627090](/images/image-20190113230627090.png)\n\n#### 分析\n\n即使在字段基数较大的情况下，位图索引依然有比B树索引更好的表现。但是有个问题，创建位图索引时所需的时间更长。此外，由于表中该字段的更改都会导致对位图的修改，所以位图索引不适用于并发的情况。\n\n### 实验3：Oracle优化器对索引的选择\n\n> ## 关于索引\n>\n> #### 索引类型\n>\n> - B树索引（默认的索引）\n>\n> ```sql\n> CREATE INDEX IX_MOVIE_SCORE ON T_MOVIE(SCORE_);\n> ```\n>\n> - 位图索引：以位图的形式存储每个值对应的的一组rowid\n>\n> ```sql\n> CREATE BITMAP INDEX IXBM_REGION_NAME ON T_REGION(NAME_);\n> ```\n>\n> - 基于函数的索引：利于对某个字段查询时需要同时使用函数或计算的情景\n>\n> ```sql\n> CREATE INDEX upper_ix ON employees (UPPER(last_name)); \n> ```\n>\n> - 分区索引：本地分区索引的分区完全依赖于其索引所在表，而全局分区索引的分区机制和表分区可能一样也可能不一样\n>\n>   - range范围分区\n>\n>   ```sql\n>   CREATE INDEX cost_ix ON sales (amount_sold)\n>    GLOBAL PARTITION BY RANGE (amount_sold)\n>       (PARTITION p1 VALUES LESS THAN (1000),\n>        PARTITION p2 VALUES LESS THAN (2500),\n>        PARTITION p3 VALUES LESS THAN (MAXVALUE));\n>   ```\n>\n>   - hash哈希分区\n>\n>   ```sql\n>   CREATE INDEX cust_last_name_ix ON customers (cust_last_name)\n>   GLOBAL PARTITION BY HASH (cust_last_name)\n>   PARTITIONS 4;\n>   ```\n>\n>   - list列表分区：一个分区对应指定列的特定的值，以列举的方式进行分区\n>   - 组合分区（range-hash，range-list）\n>\n> #### 什么时候用索引\n>\n> 对于Oracle的CBO来说，只有在使用索引能提高效率（估算的效率）时才会使用索引。对于程序员自己进行数据库管理的时候，一般有：\n>\n> **需要使用索引来优化查询的情况：**\n>\n> - 一个属性的值分布非常广，变化的范围跨度很大。\n> - 一般来说，常常需要被用在SQL语句的where中的限制条件的属性最好为其建立索引。\n> - 表经常被访问且需要访问的数据量仅占一部分。\n>\n> **不适合用索引的情况：**\n>\n> - 表很小\n> - 表经常被更新\n> - 属性不经常作为where中的限制条件的属性存在\n> - 查询得到的数据占总量的很大部分\n>\n> 对于数据经常更新的情况，DBA要定时进行索引的重构（rebuild）以维持索引的可用性。\n>\n> #### 影响优化器决策的因素\n>\n> - 进行全表扫描需要读取的数据块数量；\n> - 进行索引查询需要读取的数据块数量，这主要是基于对WHERE子句谓词返回的记录数目估计；\n> - 进行全表扫描时多块读的相关开销，以及为满足索引查询进行的单块读的开销；\n> - 内存中对缓存中的索引块和数据块数目的假设。\n>\n> #### 索引失效的可能原因\n>\n> 以下是一些常见的定义了索引当Oracle并未使用的原因：\n>\n> - 不等于情况，即“<>”\n> - 字符串匹配like中百分号在第一位的情况，即“%XXX”\n> - 表没有进行分析更新统计信息\n> - 使用复合索引但单独引用且非复合索引的第一属性\n> - 对索引进行计算，此时需要建立索引函数\n> - 属性为字符串但在where中没有加引号\n> - 使用not in，not exists\n> - 使用了其他索引\n>\n> #### 强制使用索引\n>\n> 如果想要强制使用索引，则可以在查询语句的select单词后加上/\\*+index (tablename indexname)*/，这样可以规定Oracle选择使用indexname的索引的执行计划。该方法已在前面实验中使用，不再赘述。\n\n#### sql语句\n\n```sql\nSELECT T_MOVIE.NAME_, T_MOVIE.YEAR_\nFROM T_MOVIE,T_MOVIE_REGION,T_REGION\nWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_ID\nAND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_ID\nAND T_REGION.NAME_='美国'\nAND T_MOVIE.SCORE_>6;\n```\n\n#### 查询消耗\n\n不用索引（不论是B树索引还是位图索引都不使用）\n\n![3-不用索引](/images/3-%E4%B8%8D%E7%94%A8%E7%B4%A2%E5%BC%95.png)\n\n强制使用B树索引\n\n![3-强制B树](/images/3-%E5%BC%BA%E5%88%B6B%E6%A0%91.png)\n\n强制使用位图索引\n\n![3-强制位图](/images/3-%E5%BC%BA%E5%88%B6%E4%BD%8D%E5%9B%BE.png)\n\n#### sql语句\n\n```sql\nSELECT T_MOVIE.NAME_, T_MOVIE.YEAR_\nFROM T_MOVIE,T_MOVIE_REGION,T_REGION\nWHERE T_REGION.ID_=T_MOVIE_REGION.REGION_ID\nAND T_MOVIE.ID_=T_MOVIE_REGION.MOVIE_ID\nAND T_REGION.NAME_='美国'\nAND T_MOVIE.SCORE_>9;\n```\n\n#### 查询消耗\n\nB树索引（未使用）\n\n![3-B树](/images/3-B%E6%A0%91.png)\n\n位图索引\n\n![3-位图](/images/3-%E4%BD%8D%E5%9B%BE.png)\n\n#### 分析\n\n由此可见，即使在有索引的情况下，oracle优化器也可能选择不使用索引。CBO优化器会对每种执行计划计算一个COST，并采用COST最小的执行计划。如果一个表有索引或多种索引，其会选择最好的一种索引方式扫描表，或者甚至不用索引而用全局扫描方式。\n\n另外对于符合筛选条件的数据，当占全表的比例越小、数据量越小时，使用索引的可能性越大。如在这次实验中，条件为\"T_MOVIE.SCORE_ >9\"时会使用索引，而\"T_MOVIE.SCORE_ >6\"时不会。\n\n此外，由于位图索引导致的COST要小于B树索引，因此在相同的查询中，使用位图索引的可能性比B树索引更大。\n\n### 实验4：Oracle分区索引\n\n#### sql语句\n\n```sql\nSELECT T_COMMENT.SUMMARY_,T_COMMENT.SCORE_,T_COMMENT.TIME_\nFROM T_COMMENT,T_MOVIE\nWHERE T_MOVIE.ID_=T_COMMENT.MOVIE_ID\nAND T_COMMENT.SCORE_>6\nAND T_MOVIE.NAME_='Blindsided';\n```\n\n#### 实验结果\n\n1. 未分区表+无索引\n\n   ![5-1-1](/images/5-1-1.png)\n\n2. 未分区表+B树索引\n\n   ![5-2](/images/5-2.png)\n\n3. 未分区表+位图索引\n\n   ![5-3](/images/5-3.png)\n\n4. 分区表+无索引\n\n   ![5-4-1](/images/5-4-1.png)\n\n5. 分区表+全局不分区B树索引\n\n   ![5-5-1](/images/5-5-1.png)\n\n6. 分区表+本地(哈希分区)B树索引\n\n   ![5-6](/images/5-6.png)\n\n7. 分区表+本地(哈希分区)位图索引\n\n   ![5-7](/images/5-7.png)\n\n8. 分区表+全局哈希分区索引\n\n   ![5-8](/images/5-8.png)\n\n9. 分区表+全局范围分区索引\n\n   ![5-9](/images/5-9.png)\n\n#### 分析\n\n1. 在未建索引时，分区表的COST是未分区表的十倍多。原因是分区所依据的键（字段）不是直接的查询条件——我们以评论表的movie_id字段为依据建哈希分区表，但在查询的时候并不直接以movie_id为查询条件。导致连接表的时候，需要访问多个分区，反而造成COST大大增长。\n\n   后来我们重新设计一个以movie_id为查询条件的sql语句，结果显示分区表的COST大约是未分区表的1/4（一共分了4个区），证明在以分区依据的字段为直接查询条件时，分区表能够体现比较好的性能，能够避免对一部分数据的访问。\n\n2. 在分区表上建索引比在未分区表上建索引后的开销更小，不论分区表上的索引是全局还是本地，不论是否是分区索引。在我们的实验场景中，尽管movie_id不是直接的查询条件而是join表的条件，但是在添加索引后，依然能够大大减少join表的开销从而提升效率。\n\n3. 在我们的实验场景中，全局的分区索引，不论是哈希分区还是范围分区，COST是一样的。\n\n4. 本地索引的效率略微比全局索引的效率好。根据查到的资料，本地索引的可维护性好，能够自动维护，不需要人工干预，但因把索引分成多个分区导致每次的索引访问都需要遍历所有索引分区，所以索引访问性能下降。因此比较适合OLAP系统。而全局索引的可维护性差，分区表发生改变时，需要用命令手动更新索引，但索引访问性能比本地分区索引要好。因此比较适合OLTP系统。\n\n### 实验5：Oracle使用复合索引\n\n#### SQL语句\n\n```SQL\nselect T_COMMENT_1.SUMMARY_, T_COMMENT_1.SCORE_\nfrom T_COMMENT_1, T_MOVIE\nwhere T_MOVIE.ID_ = T_COMMENT_1.MOVIE_ID and T_COMMENT_1.SCORE_ > 7 and T_MOVIE.NAME_ = 'The Notebook';\n```\n\n第一次查询：T_COMMENT_1上只有主键的唯一索引。\n\n第二次查询：在MOVIE_ID上建立一个B-tree索引COMMENT_1_MOVIE。\n\n```sql\ncreate index COMMENT_1_MOVIE on T_COMMENT_1(MOVIE_ID);\n```\n\n第三次查询：使第二次的索引invisible，在SCORE_上建立一个B-tree索引T_COMMENT_SCORE_INDEX。\n\n```SQL\nalter index COMMENT_1_MOVIE invisible;\ncreate index T_COMMENT_SCORE_INDEX on T_COMMENT_1(SCORE_);\n```\n\n第四次查询：将第二次和第三次的索引都保持为visible，在MOVIE_ID和SCORE_上建立一个复合索引COMMENT_1_MOVIE_SCORE。\n\n```SQL\nalter index COMMENT_1_MOVIE visible;\ncreate index COMMENT_1_MOVIE_SCORE on T_COMMENT_1(MOVIE_ID, SCORE_);\n```\n\n#### 实验结果\n\n**第一次查询：**\n\n![屏幕快照 2019-01-13 下午10.48.45](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%8810.48.45.png)\n\n全表扫描，花销很大\n\n**第二次查询：**\n\n![屏幕快照 2019-01-13 下午10.47.49](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%8810.47.49.png)\n\n利用在MOVIE_ID上的索引，在T_COMMENT_1中访问的数据量和花销都大幅度下降。\n\n**第三次查询：**\n\n![屏幕快照 2019-01-13 下午10.50.07](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%8810.50.07.png)\n\n如果只有在SCORE_上的索引，根据CBO，Oracle并没有使用这个索引，而是依旧使用全表扫描，可知该索引并没有提升性能。\n\n易知，如果在这个时候将MOVIE_ID上的索引设为visible，Oracle会使用MOVIE_ID上的索引。\n\n**第四次查询：**\n\n![屏幕快照 2019-01-13 下午10.57.10](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%8810.57.10.png)\n\nOracle使用了复合索引，尽管在当前问题下COST花销与只有MOVIE_ID的索引差不多，但是其访问的记录数（CARDINALITY）显著减小，体现了复合索引给查询带来的性能提升。\n\n### 实验6：物化视图对SQL查询性能的提升\n\n#### SQL语句\n\n**原始查询语句：**\n\n```SQL\nselect T_DIRECTOR.NAME_, T_MOVIE.NAME_ MOVIE_NAME, AVG(T_COMMENT_1.SCORE_) SCORE\nfrom T_DIRECTOR, T_DIRECT, T_MOVIE, T_COMMENT_1\nwhere T_DIRECTOR.ID_ = T_DIRECT.DIRECTOR_ID and T_DIRECT.MOVIE_ID = T_MOVIE.ID_ and T_COMMENT_1.MOVIE_ID = T_MOVIE.ID_ and T_DIRECTOR.NAME_ like '黑泽明%'\ngroup by T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_, T_MOVIE.ID_, T_MOVIE.YEAR_ ;\n```\n\n创建一个**普通视图**：\n\n```SQL\nCREATE VIEW DIRECTOR_MOVIE_FAKE\nAS\nselect T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_ MOVIE_NAME, T_MOVIE.ID_ MOVIE_ID, T_MOVIE.YEAR_, AVG(T_COMMENT_1.SCORE_) SCORE\nfrom T_DIRECTOR, T_DIRECT, T_MOVIE, T_COMMENT_1\nwhere T_DIRECTOR.ID_ = T_DIRECT.DIRECTOR_ID and T_DIRECT.MOVIE_ID = T_MOVIE.ID_ and T_COMMENT_1.MOVIE_ID = T_MOVIE.ID_\ngroup by T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_, T_MOVIE.ID_, T_MOVIE.YEAR_;\n```\n\n使用普通视图进行查询：\n\n```SQL\nselect NAME_, MOVIE_NAME, SCORE from DIRECTOR_MOVIE_FAKE where NAME_ like '黑泽明%';\n```\n\n创建**物化视图**：\n\n```SQL\nCREATE MATERIALIZED VIEW DIRECTOR_MOVIE\nBUILD IMMEDIATE\nREFRESH FORCE\nON DEMAND\nENABLE QUERY REWRITE\nAS\nselect T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_ MOVIE_NAME, T_MOVIE.ID_ MOVIE_ID, T_MOVIE.YEAR_, AVG(T_COMMENT_1.SCORE_) SCORE\nfrom T_DIRECTOR, T_DIRECT, T_MOVIE, T_COMMENT_1\nwhere T_DIRECTOR.ID_ = T_DIRECT.DIRECTOR_ID and T_DIRECT.MOVIE_ID = T_MOVIE.ID_ and T_COMMENT_1.MOVIE_ID = T_MOVIE.ID_\ngroup by T_DIRECTOR.NAME_, T_DIRECTOR.ID_, T_MOVIE.NAME_, T_MOVIE.ID_, T_MOVIE.YEAR_;\n```\n\n设置**创建时生成数据**，**按需要刷新**，**刷新方式为FORCE**。\n\n根据视图进行如上查询：\n\n```SQL\nselect NAME_, MOVIE_NAME, SCORE from DIRECTOR_MOVIE where NAME_ like '黑泽明%';\n```\n\n由于物化视图与表类似，可以给其建立索引，以下给导演名**建立索引**：\n\n```sql\nCREATE BITMAP INDEX DIRECTOR_MOVIE_INAME_INDEX ON DIRECTOR_MOVIE (NAME_);\n```\n\n**再次使用物化视图查询**：\n\n```SQL\nselect NAME_, MOVIE_NAME, SCORE from DIRECTOR_MOVIE where NAME_ like '黑泽明%';\n```\n\n#### 实验结果\n\n**使用原始查询：**\n\n![屏幕快照 2019-01-14 上午12.27.37](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-14%20%E4%B8%8A%E5%8D%8812.30.46.png)\n\n具有极大的花销。\n\n**创建视图后的查询：**\n\n![屏幕快照 2019-01-14 上午12.30.46](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-14%20%E4%B8%8A%E5%8D%8812.30.46.png)\n\n其执行计划与**原始查询**一致。\n\n**创建物化视图后的查询：**\n\n![屏幕快照 2019-01-14 上午12.33.27](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-14%20%E4%B8%8A%E5%8D%8812.33.27.png)\n\n其**直接在物化视图中进行查询**，执行计划即为简单，花销大幅度减小。\n\n**给物化视图创建索引后的查询：**\n\n![屏幕快照 2019-01-14 上午12.35.22](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-14%20%E4%B8%8A%E5%8D%8812.35.22.png)\n\n建立索引后通过范围索引扫描该物化视图进行查询，其COST数字小得令人惊奇。\n\n#### 分析\n\n1.建立普通视图并不能提升性能。因为普通是虚拟的，对视图的操作实际都转变为了对各表的SQL操作，其与原始查询完全一致。\n\n2.物化视图是一种物理表，对于物化视图的查询是直接的，跟表一样。因此建立物化视图可以大幅度减小花销，但是同时，物化视图也会产生大量的维护成本。因此程序员应该根据实际情况建立物化视图以优化查询。\n\n3.物化视图同样可以增添索引，增加索引后Oracle对物化视图可以通过索引进行扫描，进一步提高效率。\n\n> ### 物化视图与普通视图\n>\n> 视图只是一种虚拟表。实际上，**对视图的查询真正转换成了相应的SQL语句再对各表进行连接查询，因此其性能提升有限，只是方便了使用**。\n>\n> 而物化视图是实质化的视图，是**物理表**，可以像表一样进行查询，建立索引，占用真正的存储空间，需要被刷新。\n>\n> ### 刷新模式\n>\n> **on demand：**顾名思义，仅在该物化视图“需要”被刷新了，才进行刷新(REFRESH)，即更新物化视图，以保证和基表数据的一致性;\n>\n> **on commit**：提交触发，一旦基表有了commit，即事务提交，则立刻刷新，立刻更新物化视图，使得数据和基表一致。一般用这种方法在操作基表时速度会比较慢。\n>\n> 创建物化视图时未作指定，则Oracle按 on demand 模式来创建。\n>\n> ### 刷新方法\n>\n> **完全刷新（COMPLETE）**： 会删除表中所有的记录（如果是单表刷新，可能会采用TRUNCATE的方式），然后根据物化视图中查询语句的定义重新生成物化视图。 \n>\n> **快速刷新（FAST）**： 采用增量刷新的机制，只将自上次刷新以后对基表进行的所有操作刷新到物化视图中去。FAST必须创建基于主表的视图日志。对于增量刷新选项，如果在子查询中存在分析函数，则物化视图不起作用。\n>\n> **FORCE方式**： 这是默认的数据刷新方式。Oracle会自动判断是否满足快速刷新的条件，如果满足则进行快速刷新，否则进行完全刷新。\n\n### 实验7：Oracle In Memory性能分析\n\n#### Sql语句\n\n```sql\nSELECT T_MOVIE.NAME_, SUM(T_COMMENT_2.SCORE_) s FROM T_MOVIE,T_COMMENT_2 WHERE T_MOVIE.ID_=T_COMMENT_2.MOVIE_ID GROUP BY T_MOVIE.NAME_ ORDER BY s DESC;\n```\n\n#### 设置In Memory\n\n```sql\nALTER TABLE T_MOVIE.NAME_ IN MEMORY;\n```\n\n#### 实验结果\n\n**原始查询**：\n\n![no-inmemory](/images/no-inmemory.png)\n\n**In Memory查询：**\n\n![inmemory](/images/inmemory.png)\n\n#### 结果分析\n\n遗憾的是与想象的不同，Oracle和Oracle In Memory在COST上面结果相同，但是事实上在我们同样的实验环境下测试二者时间时，In Memory确实会比Oracle好很多。其实简单思考一下，这是应该的，前面我们说过执行时间`t = Block数量 * Block处理时间`，不难知道差距还是出在Block处理时间上。\n\n### 实验8：Oracle执行计划浅析(Oracle表的访问方式)\n\n对T_MOVIE表进行查询，其本身有在其主码(ID_)上的UNIQUE INDEX和LENGTH\\_上的B-tree INDEX。\n\n#### 根据UNIQUE INDEX（ID_）返回唯一记录\n\n```SQL\nselect * from T_MOVIE where ID_ = 20050;\n```\n\n![屏幕快照 2019-01-13 下午9.14.59](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%889.14.59.png)\n\n使用的是索引唯一扫描\n\n#### 根据ID_返回少部分记录\n\n```SQL\nselect * from T_MOVIE where ID_ < 10;\n```\n\n![屏幕快照 2019-01-13 下午9.25.22](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%889.25.22.png)\n\n使用的是索引范围扫描\n\n#### 根据LENGTH_返回大量数据\n\n```SQL\nselect * from T_MOVIE where LENGTH_ <100;\n```\n\n![image-20190114004746346](/images/image-20190114004746346.png)\n\n#### 全查询MOVIE\\_和TYPE\\_返回其ID_\n\n**全查询MOVIE_：**\n\n```SQL\nselect ID_ from T_MOVIE;\n```\n\n![屏幕快照 2019-01-13 下午9.32.45](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%889.32.45.png)\n\n采用的是索引快速扫描（因为数据量较多）\n\n![屏幕快照 2019-01-13 下午9.38.39](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%889.38.39.png)\n\n且返回结果无顺序（从578开始，一段有序，即代表是一个索引数据块）。\n\n**全查询TYPE_:**\n\n```SQL\nselect ID_ from T_TYPE;\n```\n\n![屏幕快照 2019-01-13 下午9.35.11](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%889.35.11.png)\n\n采用的是索引全扫描（因为数据量较小）\n\n![屏幕快照 2019-01-13 下午9.37.57](/images/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-13%20%E4%B8%8B%E5%8D%889.37.57.png)\n\n返回结果有顺序\n\n> ### 执行计划中的访问方式\n>\n> 访问方式即分为全表扫描（TABLE ACCESS FULL）和各种类型索引扫描（TABLE INDEX SCAN）。Oracle会根据表和索引的信息，推算执行的SQL语句从表中取多少数据以及这些数据是怎么分布的。\n>\n> #### TABLE ACCESS FULL（全表扫描）\n>\n> **Oracle会读取表中所有的行，并检查每一行是否满足SQL语句中的 where限制条件**。全表扫描时可以使用多块读（即一次I/O读取多块数据块）操作来提升吞吐量。**数据量太大的表不建议使用全表扫描，除非本身需要取出的数据较多，占到表数据总量的 5% ~ 10% 或以上**。\n>\n> #### TABLE ACCESS ROWID（通过ROWID的表存取）\n>\n> **ROWID是由Oracle自动加在表中每行最后的一列伪列**，表中并不会物理存储ROWID的值。程序员可以像使用其它列一样使用它，但不能对该列的值进行增、删、改操作。一旦一行数据插入后，则其对应的ROWID在该行的生命周期内是唯一的，即使发生行迁移，该行的ROWID值也不变。\n>\n> ROWID可以被视为每条记录的“指针”。**它指出了该行所在的数据文件、数据块以及行在该块中的位置，所以通过ROWID可以快速定位到目标数据上，这也是Oracle中存取单行数据最快的方法**。\n>\n> #### TABLE ACCESS BY INDEX SCAN（索引扫描）\n>\n> 在索引块中，既存储每个索引的键值，也存储具有该键值的行的ROWID。因此索引扫描其实分为两步：扫描索引得到对应的ROWID；通过ROWID定位到具体的行读取数据。\n>\n> 索引扫描主要分为以下几种：\n>\n> ##### INDEX UNIQUE SCAN 索引唯一扫描\n>\n> 对应UNIQUE INDEX（唯一性索引）的扫描方式，其**只会应用在返回一条记录的情况下**。该点在之前的实验中已经描述。\n>\n> ##### INDEX RANGE SCAN 索引范围扫描\n>\n> 主要是使用在需要返回多行记录的情况下，常见为以下三种：\n>\n> - 在唯一索引列上使用了范围操作符（如：>   <   <>   >=   <=   between）\n> - 在组合索引上，只使用部分列进行查询（查询时必须包含前导列，否则会走全表扫描）\n> - 对非唯一索引列上进行的任何查询\n>\n> 如果在查询的过程中需要访问的记录数很多，分布很广，这个时候Oracle会根据CBO原则认为使用索引的花销可能比全表扫描大，会使用全表扫描。\n>\n> ##### INDEX FULL SCAN 索引全扫描\n>\n> 进行全索引扫描时，查询出的数据都必须从索引中可以直接得到。其常发生在要查询的列包含唯一索引且需要对表中的所有数据都要查询。**索引全扫描返回的结果有顺序。**\n>\n> ##### INDEX FAST FULL SCAN 索引快速全扫描\n>\n> 索引快速全扫描与索引全扫描类似，只是其在查找索引时会用一种更为快速的方式（简单来说是根据索引块的物理顺序而省去较为繁琐的逻辑顺序），其更适合于数据量大的表进行全查询，**其一个特点就是返回的记录不按照顺序。**\n\n## 四、TimesTen实验过程\n\n### 实验概述\n\n调用自己改写的 AliTT11.sql，查看 SQLPrepare，SQLExecute，FetchLoop 的查询时间；\n\n所有实验中，查询时间分为增加索引前、增加索引后、按照 timesten 建议添加索引三类，针对每一类时间分别有第一次执行时间和之后的平均查询时间两种；\n\n在首次执行查询语句时，timesten首先需要对语句进行预编译，因此首次执行的 SQLPrepare 时间相比之后的时间较长，之后的准备时间就相应缩短了很多。\n\n### 实验1\n\n#### 实验内容\n\n某地区评分6以上的所有电影的名字和上映时间\n\n#### 查询语句\n\n```sql\nSELECT DBIM.T_MOVIE.NAME_, DBIM.T_MOVIE.YEAR_\nFROM DBIM.T_MOVIE, DBIM.T_MOVIE_REGION, DBIM.T_REGION\nWHERE DBIM.T_REGION.ID_ = DBIM.T_MOVIE_REGION.REGION_ID\nAND DBIM.T_MOVIE.ID_ = DBIM.T_MOVIE_REGION.MOVIE_ID\nAND DBIM.T_REGION.NAME_ = '美国'\nAND DBIM.T_MOVIE.SCORE_ > 6;\n```\n\n#### 添加的索引\n\n| 表明         | 列名      | 索引类型 | 是否唯一 |\n| ------------ | --------- | -------- | -------- |\n| Movie        | id_       | hash     | unique   |\n| Movie        | score_    | range    |          |\n| Region       | id_       | hash     | unique   |\n| Movie_region | region_id | hash     |          |\n| Movie_region | movie_id  | hash     |          |\n\n#### 查询时间\n\n| 时间类型   | Before1  | Before2  | After1   | After2   | 建议1    | 建议2    | 提高百分比 |\n| ---------- | -------- | -------- | -------- | -------- | -------- | -------- | ---------- |\n| SQLPrepare | 0.001845 | 0.000059 | 0.000878 | 0.000054 | 0.000807 | 0.000055 |            |\n| SQLExecute | 0.075809 | 0.061819 | 0.000037 | 0.000025 | 0.000034 | 0.000025 | 99.96%     |\n| FetchLoop  | 0.000004 | 0.000002 | 0.000002 | 0.000001 | 0.000003 | 0.000002 |            |\n\n- 执行计划 (before)\n\n![11b](/images/11b.PNG)\n\n- 执行计划 (after)\n\n![11a](/images/11a.PNG)\n\n#### 原因分析\n\n添加索引后速度大大提升，因为在 region 表中指定了查询条件，添加索引后可以快速从表项中匹配到指定条件的项；在添加之前，timesten 自动帮我们在 movie 表上的 id 字段上添加了临时哈希索引，除此之外，我们额外为几个 where 条件语句的查询字段都增加了索引， 因此提高了效率。\n\n执行计划\n\n- before\n\n  在两层嵌套循环中，顺序执行在region表中的查询、region表与联系表的join，循环结束后生成一个指定地区内的所有电影联系表；内层嵌套完成后，通过散列索引匹配movie表与内存循环生成的联系表，join筛选后生成结果列表\n\n- after\n\n  添加索引之后，过程与添加之前相同，但由于内层循环内使用散列索引而不是顺序执行，因此查询速度比较快，加上没有临时创建索引的时间开销，所以相比之下大大提高了查询效率。\n\n### 实验2\n\n#### 实验内容\n\n所有地区全部电影的平均评分排行榜（前100）\n\n#### 查询语句\n\n```sql\nSELECT * FROM (SELECT DBIM.T_REGION.NAME_, SUM(DBIM.T_MOVIE.SCORE_) s\nFROM DBIM.T_REGION, DBIM.T_MOVIE_REGION, DBIM.T_MOVIE\nWHERE DBIM.T_MOVIE.ID_ = DBIM.T_MOVIE_REGION.MOVIE_ID\nAND DBIM.T_REGION.ID_ = DBIM.T_MOVIE_REGION.REGION_ID\nGROUP BY DBIM.T_REGION.NAME_\nORDER BY s DESC) WHERE ROWNUM < 101;\n```\n\n#### 添加的索引\n\n| 表明         | 列名      | 索引类型 | 是否唯一 |\n| ------------ | --------- | -------- | -------- |\n| Movie        | id_       | hash     | unique   |\n| Movie        | score_    | range    |          |\n| Region       | name_     | hash     | unique   |\n| Region       | id_       | hash     | unique   |\n| Movie_region | region_id | hash     |          |\n| Movie_region | movie_id  | hash     |          |\n\n#### 查询时间\n\n| 时间类型   | Before(1) | Before(2) | After(1) | After(2) | 建议(1)  | 建议(2)  | 提高百分比 |\n| ---------- | --------- | --------- | -------- | -------- | -------- | -------- | ---------- |\n| SQLPrepare | 0.001253  | 0.000081  | 0.001004 | 0.000054 | 0.000985 | 0.000056 |            |\n| SQLExecute | 0.353111  | 0.335902  | 0.337983 | 0.313458 | 0.313004 | 0.312695 | 7%         |\n| FetchLoop  | 0.000045  | 0.000020  | 0.000018 | 0.000018 | 0.000018 | 0.000017 |            |\n\n- 执行计划 (before)\n\n![12b](/images/12b.PNG)\n\n- 执行计划 (after)\n\n![12a](/images/12a.PNG)\n\n#### 原因分析\n\n添加索引之前，timesten 自动在 movie 和 region 表的 id 字段上都设置了相应的哈希索引，而我们添加索引后与添加之前的执行计划中的索引项没有差别，因此效率几乎没有变化，加上 sum 聚合操作、group by、order by 操作都要进行费时间的全表扫描，所以需要较长时间完成查询。\n\n> #### 实验1和2分析总结\n>\n> 指定条件的查询：\n>\n> - 建立索引之前\n>\n>   timesten在某个相对较小的表上建立临时索引（散列索引或范围索引），在其他表上进行顺序扫描，执行查询语句中的条件匹配，建立索引的过程会造成时间上的消耗；\n>\n> - 建立索引之后\n>\n>   自己建立的索引覆盖timesten优化建立的索引，由于索引提前建立，因此没有建立索引带来的额外时间开销，而且在此类查询中我们在所有查询涉及字段上都建立了索引（tt自身优化通常只在一个表上建立索引），所以与建立索引之前相比有极大的性能提升。\n>\n> 聚合查询：\n>\n> - 执行计划Before：\n>\n>   先顺序扫描关系表act的记录字段id，利用临时HASH索引 actor.id_，将act表中对应记录与act的记录通过字段相连；对(这些/该)拼接记录逐条利用临时HASH索引 movie.id ,接上movie表中符合条件的记录字段。\n>\n> - 执行计划After：\n>\n>   先顺序扫描关系表movie的记录字段id ，利用HASH索引 act.id_，将act表中对应记录与act的记录通过字段相连；针对第一次hash检索出的 act.id，再对(这些/该)拼接记录逐条利用临时HASH索引 actor.id ,接上actor表中符合条件的记录字段。\n>\n> - 主要原因在于：第一次顺序扫描的关系表act，外码引用actor表的主码(1:1)，movie表(1:1)，hash索引查询唯一记录快；第二次顺序扫描的表为movie表，将对应多条act表里的记录（1:many），对应多个演员(1:many)。\n\n### 实验3：AWT\n\n#### 创建 AWT 直写缓存组\n\n- 缓存表\n  - t_moive\n  - t_comment_1\n- 选择理由\n  - 动态缓存组适用于不从 oracle 中预加载数据的场景\n  - Movie 表和评论表体量较大，不需要从 oracle 中提前加载\n\n#### 测试 AWT 修改数据\n\n- 修改电影评论表\n\n- 修改语句\n\n  ```mysql\n  UPDATE DBIM.T_COMMENT_1\n  SET SUMMARY_='A'\n  WHERE DBIM.T_COMMENT_1.SCORE_>8\n  AND DBIM.T_COMMENT_1.MOVIE_ID = 1;\n  ```\n\n- 踩坑\n\n  - update语句指定修改的表名后，set字段不需要再次声明表名（否则报错）\n  - 修改数据前要开启 replication agent\n  - 执行update语句后要提交事务\n\n### 实验4：查看不同数据类型对查询效率的影响\n\n#### 表字节大小\n\n| 表名    | 行数    | 字节大小                | 有数据类型映射的字节大小 | 节约百分比 |\n| ------- | ------- | ----------------------- | ------------------------ | ---------- |\n| Movie   | 292352  | 47301232（nomapping）   | 26293000（optimal）      | 45%        |\n| Comment | 9805336 | 2528884600（nomapping） | 404967952（optimal）     | 84%        |\n\n#### 压缩设置\n\n![image-20190114062154430](/images/image-20190114062154430.png)\n\n#### 数据类型映射结果\n\n| 表     | 字段  | noMapping         | standardMapping   | aggressive       |\n| ------ | ----- | ----------------- | ----------------- | ---------------- |\n| Region | id_   | NUMBER(11,0)      | TT_BIGINT         | TT_SMALINT       |\n| Region | name_ | VARCHAR(255 BYTE) | VARCHAR(255 BYTE) | VARCHAR(80 BYTE) |\n\n#### 结果分析\n\n- 对相同的表来说，从 oracle 导入 timesten 中如果不进行压缩（nomapping），与进行最优化数据类型映射+aggressive mapping + optimal compression 相比，大约浪费了45%的空间；\n- 对于不同数量级的表来说，千万数量级的 comment 表不进行压缩时浪费84%所有的空间，比十万数量级的 movie 表浪费的空间多了接近一倍。\n\n### 实验5：根据优化建议建立索引\n\n#### SQL语句\n\n```sql\nCommand> call ttIndexAdviceCaptureOutput(0);\n< 6, create index T_MOVIE_i1 on DBIM.T_MOVIE(ID_); >\n< 7, create index T_COMMENT_1_i2 on DBIM.T_COMMENT_1(MOVIE_ID,SCORE_); >\n2 rows found.\n```\n\n#### 实验对象\n\n- 实验3.2语句\n\n#### 实验结果\n\n- Before：自己建立索引后的查询时间\n- After：根据 timesten 查询优化建议建立索引后的查询时间\n\n| 时间类型   | Before(1) | Before(2) | After(1) | After(2) | 提高百分比 |\n| ---------- | --------- | --------- | -------- | -------- | ---------- |\n| SQLPrepare | 0.001527  | 0.000049  | 0.000822 | 0.000049 |            |\n| SQLExecute | 4.139655  | 3.556375  | 3.301318 | 3.302092 | 7.18%      |\n| FetchLoop  | 0.000047  | 0.000027  | 0.000018 | 0.000017 |            |\n\n\n\n\n\n\n\n\n\n\n","tags":["Oracle","Timesten"],"categories":["archives"]},{"title":"数据仓库期末项目文档","url":"/2018/12/31/数据仓库期末项目文档/","content":"\n## 简介\n\n本项目我们基于Stanford University中的Amazon Movie Comment数据，利用爬虫技术爬取了数十万的电影信息数据以及数百万计的电影评论数据，并通过搭建Neo4j图数据库、MySQL关系型数据库、Influx时序数据库及Hive分布式数据库对数据进行存储、分析及实现功能，同时对于部分功能需求针对这4种数据库进行效率对比分析。\n\n<!-- more -->\n\n## 系统架构\n\n### Neo4j\n\n- 操作系统：macOS Mojave 10.14.1\n\n- 硬件：Core i5 & 16GB RAM\n\n- 软件：Neo4j Desktop Version 1.1.10 (1.1.10.436)\n\n- 选择理由：\n  - 高性能：Neo4j以图的遍历算法来帮助查询数据，查询时从一个节点开始，根据其连接的关系，快速和方便地找出它的邻近节点。这种查找数据的方法并不受数据量的大小所影响，因为邻近查询始终查找的是有限的局部数据，不会对整个数据库进行搜索。所以，Neo4j具有非常高效的查询性能，相比于RDBMS可以提高数倍乃至数十倍的查询速度。而且查询速度不会因数据量的增长而下降。\n  - 灵活性：图数据结构的自然伸展特性及其非结构化的数据格式让Neo4j的数据库设计可以具有很大的伸缩性和灵活性，使其可以随着需求的变化而增加的节点、关系及其属性并不会影响到原来数据的正常使用，因此在项目后期的推进中，我们也可以不断的快速修改neo4j数据库中的内容来满足我们的查询需求。\n  - 直观性：图数据库使用图的形式作为数据库最主要的展现形式，可以更清楚的帮助我们理解整个数据库中数据之间的联系，Cypher语言的灵活性也帮助我们更轻松的操控数据库\n- 存储模型简介：\n  - 本项目中主要建立了Neo4j的两个不同的库，一个库是围绕电影的相关信息，我们在其中存储了和电影有关的所有信息，包括导演，制片人，演员，类别，语言，字幕，编剧等等，节点与节点之间通过不同的关系相连接。第二个库针对合作关系，分别存储了导演，演员，以及类别，通过节点与节点之间的关系，记录他们彼此的合作次数，类别的引入也帮助我们分析导演的执导风格。\n\n- 存储模型：图\n- 性能对比分析：\n  - 数据存储：Neo4j对于图的存储自然是经过特别优化的。不像传统数据库的一条记录一条数据的存储方式，Neo4j的存储方式是：节点的类别，属性，边的类别，属性等都是分开存储的，这将大大有助于提高图形数据库的性能。在Neo4j 中属性，关系等文件是以数组作为核心存储结构；同时对节点，属性，关系等类型的每个数据项都会分配一个唯一的ID，在存储时以该ID 为数组的下标。这样，在访问时通过其ID作为下标，实现快速定位。\n  - 数据读写：在Neo4j中，存储节点时，每个节点都有指向其邻居节点的指针，可以让我们在O(1)的时间内找到邻居节点。另外，按照官方的说法，在Neo4j中边是最重要的,是\"first-class entities\"，所以单独存储，这有利于在图遍历的时候提高速度，也可以很方便地以任何方向进行遍历。邻近查询帮助Neo4j始终查找的是有限的局部数据，不会对整个数据库进行搜索。所以，Neo4j具有非常高效的查询性能，相比于RDBMS可以提高数倍乃至数十倍的查询速度。而且查询速度不会因数据量的增长而下降。\n\n### MySQL\n\n- 操作系统：macOS Mojave 10.14.1 Beta\n\n- 硬件：Intel(R) Core(TM) i5-3470 CPU @ 3.20GHz/ 4 GB 1600 MHz DDR3\n\n- 软件：Docker 1.13.1/ MySQL 5.7\n\n- 选择理由：\n\n  MySQL是时下使用率最高的几款关系型数据库之一，且其体积相较其他关系型数据库更小巧且性能不输大型关系型数据库。关系型数据库是我们最常接触也是在对数据进行存储时会最先想到的数据库类型。我们想要借助关系型数据库以及行式存储对我们的数据进行存储，并通过对应的数据库操作对存储对数据进行分析/查询，实现我们对应的目的。\n\n- 存储模型简介：\n\n  在本项目中我们选择雪花模型作为我们关系型数据库的存储模型。雪花存储模型使用规范化的数据，数据在数据库内部是组织好的，消除冗余以减少数据量。相比之下，星型模型使用的是反规范化的数据，会在存储时存储大量的冗余数据。规范化存储数据同时也带来查询时间上的消耗，其查询更新速度会慢于星型存储模型。但是考虑到我们项目到数据单表最大12万左右，对于这个数量级到数据星型模型的查询速度相比雪花模型没有非常明显的差距，而雪花模型能够帮助我们减少了很多不必要的冗余数据的存储，所以我们选用了雪花模型。我们的数据库设计了实体表与关系表，各个实体表有自己的唯一的主键，实体表之间的联系使用关系表进行关联，减少了很多实体数据的存储，符合第三范式。\n\n- 性能分析：\n\n  在一开始，我们并没有对每个表建立相应的索引，在这种情况下我们单表的query速度在一个可接受的范围内，但是一旦涉及多表联合查询，如查询每个导演执导的电影数量时，需要关联三张表，在这种情况下查询速度非常的慢，因为其中涉及来表的结合与数据的聚合查询。针对联合查询过慢的速度下，我们为每张实体表以及关系表建立主码索引，并且在常用的搜索字段，如电影的上映日期上建立对应的索引，并且在这种大量数据的情况需要先对表建立索引再将数据导入，因为导入数据之后再建立索引会消耗大量的时间。索引建立之后再进行同样的多表联合查询操作，可以发现速度得到了明显的提升，在当前十万级别的数据量下查询耗时基本在五十毫秒之内。所以在MySQL中建立适当的索引能够在很大程度上提升查询的速度，同时也会牺牲一定的查询/更新效率。\n\n  ![ERFinal](/images/ERFinal.png)\n\n\n### Influx\n\n- 操作系统：windows10\n- 硬件：Intel(R) Core(TM) i5-6300HQ CPU @2.30GHz & 8GB RAM\n- 软件：influx1.7.1\n- 选择理由：\n  首先，查询场景中有用到对世界特性比较敏感的数据，例如，根据时间查询等，所以使用influxDB。influxDB继承了LSM Tree的顺序写入的特点，所以写入性能很好（先把大量的数据顺序写，然后持久化到磁盘。）时序数据库每次读取数据都是读取固定series的指定时间范围的连续数据，因为是顺序写入，所以这种读取比较快速。\n- 存储模型简介：\n  influxdb中我们主要存 电影id，电影类别，电影语言，电影观看人数，电影上映时间。其中，将电影类别与电影语言当做tag存储，电影id以及电影观看人数当做field存储，其中上映时间就是时间戳存储。\n- 存储模型：\n ![527DE0D27244EE625AD2D099AACDF4BA](/images/527DE0D27244EE625AD2D099AACDF4BA-6182656.png)\n- 性能对比分析：\n  \n  InfluxDB用于存储大量的时间序列数据，并对这些数据进行快速的实时分析。SQL数据库也可以提供时序的功能，但时序并不是其目的。\n  在InfluxDB中，timestamp标识了在任何给定数据series中的单个点。就像关系型数据库中的主键。\n  InfluxDB考虑到schema可能随时间而改变，因此赋予了其便利的动态能力。但是由于在项目中，时间相关的数据较为固定，因此其性能的体现并不是特别好。\n\n### Hive\n\n- 操作系统：macOS Mojave 10.14.1\n\n- 硬件：Core i7 & 16GB RAM\n\n- 软件：Hive 3.1.1 & Hadoop 3.1.1 & MySQL 5.7\n\n- 选择理由：\n\n  Hive首先有很多以上数据库所不具有的优点，如扩展性和容错性，本项目我们选择hive来处理一部分数据主要是作为MySQL数据库的对照。针对我们项目的百万级的数据量来对比分析关系型数据库和分布式数据库在数据量较大时的性能优劣性，以此窥见数据仓库对比于数据库的所展现出来的优点。同时对于项目中的部分功能需求组合采用hive与其他数据库分治的方式，来实现复杂的功能需求，以此来学习工程中数据仓库与普通数据库结合的实现方法。而由于数据量及需求的限制，我们只可窥见数据仓库其作用的冰山一角，希望藉此加深我们对数据仓库的理解。\n\n- 存储模型简介：\n  \n  在hive中我们存储的数据与MySQL中一样。因此建立了与MySQL完全相同的存储结构。另外针对hive本身自带的不同的存储模型，我们还创建了textfile和ORCfile两种表存储结构。\n\n- 分布式架构：\n  \n  ![h](/images/hive_arg.png)\n\n- 性能对比分析：\n\n  \b\b从我们对于MySQL和Hive这两种比较有可比性的数据库之间的对比来说，MySQL的执行时间基本上是远远快于Hive的执行时间的。\n  首先，考虑我们在这两种数据库中执行的操作，如果对于一开始数据从文件进入数据库中这一过程忽略的话，我们整个项目执行的都是OLAP即联机分析处理操作。Hive作为一个经典的数据仓库工具，本身应该是擅长执行OLAP操作的，因此暂且认为\"操作\"不是造成二者执行时间差异的原因；\n  其次，Hive官网有句话\b\"Hive在大型数据集上会表现出优越的性能\"，考虑到我们的项目数据集\b中，最多的数据集是700多万条的用户评论数据，而基本功能的实现都是操作在数据量仅有10万余条的电影数据，我们猜测是数据量限制了Hive体现其\b优越性。因此我们作了如下实验：在等量的数据量变化上，我们比较二者变化前后的执行的时间，得到下表：\n  ![表1](/images/表1.png)\n  就时间来说，很显然MySQL更胜一筹，但从增长比例来说，MySQL从9ms增长至271ms增长约为30倍，而\bHive增长约为5倍，由此我们可窥见Hive在大量数据集时性能会更加优越。然而在这过程中，\b我们所使用的Hive所采用的为textfile存储结构，意即内容即文件，表数据完全按照表结构存储成为文本文件，我们创建了t_comment表存储用户评论信息，表数据文件如下：\n  ![h1](/images/hive_textfile1.png)\n  ![h2](/images/hive_textfile2.png)\n  \b从Hive官方文档我们得知Hive有其他更加优越的存储格式，它包含SequenceFile、RCFile、ORCFile，我们采取了所谓最优的ORCFile来Duplicate了用户评论表，想以此对比ORCFile之于TextFile的优点，我们创建了\bt_comment_orc表，并从t_comment中把数据原封不动的导入进来，可见表数据文件如下：\n  ![h3](/images/hive_orc1.png)\n  不难看到\bORC表文件(260MB)明显比TextFile表文件(705MB)小多了，至于性能，同样对于上述实验，我们添加了ORC表的结果：\n  ![表2](/images/表2.png)\n  结果显而易见，当数据达到\b数百万量级时，Hive**较优**的使用方法下已经要比MySQL要稍显胜势了。\n  通过以上两点以及常识我们不难看出：\n\n  - 限制Hive的效率的因素：\n\n    - 数据量\n\n    - \b计算框架\n\n      Hive在我们项目中使用的是MapReduce框架来执行分布式计算，然而比\b现在已经有很多比MapReduce快得多的计算框架例如Spark等，因此若使用这些框架必定会使\n\n    - 网络通信\n\n      由于我们的集群搭建在Docker容器中，其间数据通过程序写定的程序通道传输而非真实的网络通信，因此暂且看不出网络对执行的影响，而真实场景中，这必是一项重要的考虑因素\n\n  - 百万级数据的OLAP场景或者OLTP操作需求较多的场景下，MySQL(关系型数据库)是优选\n  - 千万乃至亿万级数据的批处理、分析场景，Hive(数据仓库/分布式数据库)在存储、读取、分析效率上都要更优\n\n  其三，上述操作均是在单表查询的前提下，但是在多表查询情况下Hive的效率如何呢？先看测试结果，我们仅在\"导演-执导-电影\"三表上做了多表查询，执行\"某导演执导电影的数量\"的操作，执行时间记录如下：\n  ![表3](/images/表3.png)\n  此现象引出了数据仓库在实际应用中的一种常见处理方式：为了提高速度而产生数据冗余。Hive中的表是很特殊的，其没有主键、外键同时库中各个表之间的冗余会很明显，这使得\b管理人员方便针对各种功能设计所需的信息表，这也是数据仓库作为大量数据集的OLAP最佳选择的原因之一。\n  \n## \b性能对比\n\n![image-20181231003424471](/images/image-20181231003424471.png)![image-20181231003442918](/images/image-20181231003442918-6187682.png)\n\n![image-20181231003457997](/images/image-20181231003457997-6187698.png)![image-20181231003513281](/images/image-20181231003513281-6187713.png)\n\n- 走势变化：\n\n  由图可见，四种数据库中执行时间都是先较多然后减少最后趋于稳定，我们对其分析可能是jdbc在首次连接时需要较多时间进行网络通信，当一次连接建立后，我们并没有关闭该连接，在此基础上程序执行后续的事务才应当是其真实的操作时间。\n\n- 功能对比：\n\n  不同的数据库，在不同的功能需求下各有优劣。举个例子，在查询实体间的关系时，对于完全符合3NF的关系型数据库来说，可能需要多表连接查询，这明显会消耗大量时间，而对于基于relation的数据库例如Neo4j来说，类似查询正是其强项。\n\n## 总结\n\n- 本项目使用了JavaWeb框架，并基于sementicUI进行前端开发。\n- 在数据库选择上，我们使用了Mysql，hive，Neo4j以及influxDB四个不同的数据库进行横向纵向比对，通过实现一定的基本功能搜索以及多表联查，统计他们的性能，查询时间等数据并进行相应的分析，对于不同数据库的优劣势有了更为清晰的了解。\n- 在项目过程中，我们将上课学到的知识应用到实践中，尝试了雪花，星型等不同的存储结构，并根据自己的项目实情选择了最适合我们的项目存储结构。针对不同的实验现象，我们也通过网络等资源来进行辅助学习，帮助我们更好的了解不同数据库以及其不同的存储，读取等方式。\n- 项目过程中，特别感谢老师和助教们的帮助，让我们更为深入了解了数据仓库技术，为我们今后的项目实践打下了扎实的基础。\n\n","tags":["大三上笔记","数据仓库"],"categories":["archives"]},{"title":"云计算期末项目","url":"/2018/12/31/云计算期末项目文档/","content":"\n# 云计算期末项目文档\n\n\n## 系统架构\n\n### 集群架构图\n\n![image-20181228192856958](/images/image-20181228192856958-5996536.png)\n\n### <a name=\"a1\">集群机器</a>\n\n| 主机名  | 内存 |       IP        |       软件        |                           运行进程                           |\n| :-----: |  :-----: | :-------------: | :---------------: | :----------------------------------------------------------: |\n|  node0  |  512MB  | 192.168.137.200 |     ZooKeeper     |                        QuorumPeerMain                        |\n|  node1  |  512MB  | 192.168.137.201 |     ZooKeeper     |                        QuorumPeerMain                        |\n|  node2  |  512MB  | 192.168.137.202 |     ZooKeeper     |                        QuorumPeerMain                        |\n| master  |  2GB  | 192.168.137.100 | Hadoop,Hive,MySql | JournalNode,NameNode,ResourceManager,<br/>DFSZKFailoverController,HiveServer2,MySql |\n| master1 |  2GB  | 192.168.137.10  |    Hadoop,Hive    | JournalNode,NameNode,ResourceManager,<br/>DFSZKFailoverController,HiveServer2 |\n| slave1  |  1GB  | 192.168.137.101 |      Hadoop       |               JournalNode,DataNode,NodeManager               |\n| slave2  |  1GB  | 192.168.137.102 |      Hadoop       |                     DataNode,NodeManager                     |\n| slave3  |  1GB  | 192.168.137.103 |      Hadoop       |                     DataNode,NodeManager                     |\n|  host   |  8GB  |  192.168.137.1  |    应用服务器     |                                                              |\n\n## 集群搭建\n\n### 简介\n\n集群使用VirtualBox创建了8台虚拟机模拟真实环境中的分布式集群<sub>~~(因机器内存不够，特地为此买了内存条及SSD)~~</sub>，虚拟机全部使用CentOS7-x86_64系统，其中3台ZooKeeper集群，5台Hadoop集群（2台Master，3台Slave），Windows本机作为应用程序服务器用于连接此集群。\n\n### 虚拟机创建\n\n此集群中机器的系统基本配置几乎是一样的，只是在后期所担任的角色不同，因此这里我创建了一台虚拟机，而后将环境配好后复制了7台，而后针对其所担任角色进行针对性修改。\n\n首先创建了一台裸机，要解决的第一个问题是虚拟机与主机的网络通信，这里我采用VirtualBox中的`Host-Only`连接方式，以保证虚拟机与主机之间正常的网络通信，同时需要在主机上共享网络，以保证虚拟机同时还能访问互联网。\n\n在主机网络设置中共享网络：\n\n![image-20181228201105314](/images/image-20181228201105314-5999065.png)\n\n在VirtualBox中执行以下操作设置主机连接方式：\n\n![image-20181228200129326](/images/image-20181228200129326-5998489.png)\n\n在虚拟机终端执行以下操作：\n\n```sh\n# 修改虚拟机的IP、子网掩码\nvim /etc/sysconfig/network-scripts/ifcfg-enp0s3\n# 修改为以下内容\nTYPE=Ethernet\nIPADDR=192.168.137.100\nNETMASK=255.255.255.0\n# 保存退出\n# 修改网关地址\nvim /etc/sysconfig/network\n# 修改为以下内容\nNETWORKING=yes\nGATEWAY=192.168.137.1\n# 保存退出\n# 修改主机名为master，后续过程中访问本机只需要主机名而不用敲IP\nhostnamectl set-hostname master\n# 关闭并停用防火墙，由于这里使用的是局域网，因此无需太多考虑网络安全\nsystemctl stop firewalld\nsystemctl disable firewalld\n# 重启网络服务\nsystemctl restart network\n# 尝试从虚拟机ping网关以及从主机ping虚拟机hostname或者ip，若都能ping通说明网络配置成功\nping 192.168.137.1\n# 从虚拟机ping外网查看是否可以连接互联网，这里测试百度IP：61.135.169.105\nping 61.135.169.105\n# 修改hosts文件，添加局域网中其他主机的主机名与ip的映射\nvim /etc/hosts\n# 修改为以下内容\n192.168.137.100 master\n192.168.137.10 master1\n192.168.137.101 slave1\n192.168.137.102 slave2\n192.168.137.103 slave3\n192.168.137.200 node0\n192.168.137.201 node1\n192.168.137.202 node2\n0.0.0.0 localhost\n# 保存退出\n```\n\n至此，虚拟机网络配置已完成，下面安装Hadoop 2.9.2及Hive 2.3.4（下载、解压步骤省略），并执行一些准备工作：\n\n```sh\n# 首先添加Hadoop和Hive相关环境变量\nvim /etc/profile\n# 添加下列内容\nexport HADOOP_MAPRED_HOME=/usr/local/hadoop\nexport HADOOP_HOME=/usr/local/hadoop\nexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nexport HIVE_HOME=/usr/local/hive\nexport PATH=$HIVE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH\n# 保存退出，并使环境变量生效\nsource /etc/profile\n```\n\nHadoop和Hive的配置需放到各台虚拟机上分别执行，因为不同虚拟机所需要的配置不同。\n\n### 虚拟机复制\n\n上述步骤已经创建好了一个虚拟机，下面需要复制出7个，并对每台机器针对性的进行一些修改。\n\n#### 网络配置\n\n对于每台虚拟机需要执行以下几个步骤以保证9台机器之间形成一个网络：\n\n- 修改IP\n\n  ```sh\n  vim /etc/sysconfig/network-scripts/ifcfg-enp0s3\n  ```\n\n  针对<a href=\"#a1\">集群机器</a>中定义的IP将`IPADDR`项修改为对应的IP\n\n- 修改主机名\n\n  ```sh\n  hostnamectl set-hostname XXX\n  ```\n\n  针对<a href=\"#a1\">集群机器</a>中定义的主机名执行以上命令修改为特定的主机名\n\n- 重启网络服务\n\n  ```sh\n  systemctl restart network\n  ```\n  \n- ping各个节点测试是否成功\n\n  ```sh\n  ping master\n  ping master1\n  ping slave1\n  ping slave2\n  ping slave3\n  ping node0\n  ping node1\n  ping node2\n  ping 192.168.137.1\n  ping 61.135.169.105\n  ```\n\n#### Hadoop配置\n\n##### 修改core-site.xml\n\n```sh\nvim $HADOOP_HOME/etc/hadoop/core-site.xml\n```\n\n- 作用：Hadoop集群的核心配置文件\n\n- 需要修改的机器：master、master1、slave1、slave2、slave3\n\n- 内容：\n\n  ```xml\n  <configuration>\n          <property>\n                  <name>fs.defaultFS</name>\n                  <value>hdfs://ns</value>\n          </property>\n          <property>\n                  <name>hadoop.tmp.dir</name>\n                  <value>/var/hadoop</value>\n          </property> \n          <property>\n                  <name>dfs.permissions.enabled</name>\n                  <value>true</value>\n          </property> \n          <!-- 指定zookeeper地址 -->\n          <property>\n                  <name>ha.zookeeper.quorum</name>\n                  <value>node0:2181,node1:2182,node2:2181</value>\n          </property>\n      \t<!-- 允许访问此hdfs的主机和群组，此处设置为任意 -->\n          <property>\n                  <name>hadoop.proxyuser.root.hosts</name>\n                  <value>*</value>\n          </property>\n          <property>\n                  <name>hadoop.proxyuser.root.groups</name>\n                  <value>*</value>\n          </property>\n  </configuration>\n  ```\n\n##### 修改hdfs-site.xml\n\n```sh\nvim $HADOOP_HOME/etc/hadoop/hdfs-site.xml\n```\n\n-  作用：hdfs集群配置文件\n\n-  需要修改的机器：master、master1、slave1、slave2、slave3\n\n- 内容：\n\n  ```xml\n  <configuration>\n      \t<!-- 指定dfs文件存储位置 -->\n          <property>\n                  <name>dfs.data.dir</name>\n                  <value>/var/hadoop-data</value>\n          </property>\n      \t<!-- 指定文件备份份数 -->\n          <property>\n                  <name>dfs.replication</name>\n                  <value>2</value>\n          </property>\n      \t<!-- 指定机器运行情况检查时间间隔 -->\n          <property>\n                  <name>dfs.namenode.heartbead.recheck-interval</name>\n                  <value>3000000ms</value>\n          </property>\n          <!-- 指定hdfs的nameservice为ns，和core-site.xml保持一致 -->\n          <property>\n                  <name>dfs.nameservices</name>\n                  <value>ns</value>\n          </property>\n          <!-- NS下面的NameNode -->\n          <property>\n                  <name>dfs.ha.namenodes.ns</name>\n                  <value>nn1,nn2</value>\n          </property>\n          <!-- nn1的RPC通信地址 -->\n          <property>\n                  <name>dfs.namenode.rpc-address.ns.nn1</name>\n                  <value>master:9000</value>\n          </property>\n          <!-- nn1的http通信地址 -->\n          <property>\n                  <name>dfs.namenode.http-address.ns.nn1</name>\n                  <value>master:50070</value>\n          </property>\n          <!-- nn2的RPC通信地址 -->\n          <property>\n                  <name>dfs.namenode.rpc-address.ns.nn2</name>\n                  <value>master1:9000</value>\n          </property>\n          <!-- nn2的http通信地址 -->\n          <property>\n                  <name>dfs.namenode.http-address.ns.nn2</name>\n                  <value>master1:50070</value>\n          </property>\n          <!-- 指定NameNode的元数据在JournalNode上的存放位置 -->\n          <property>\n                  <name>dfs.namenode.shared.edits.dir</name>\n                  <value>qjournal://master:8485;master1:8485;slave1:8485/ns</value>\n          </property>\n          <!-- 指定JournalNode在本地磁盘存放数据的位置 -->\n          <property>\n                  <name>dfs.journalnode.edits.dir</name>\n                  <value>/usr/local/hadoop/journaldata</value>\n          </property>\n      \t<!-- 开启机器故障自动切换主从机器 -->\n          <property>\n                  <name>dfs.ha.automatic-failover.enabled</name>\n                  <value>true</value>\n          </property>\n      \t<!-- 指定failover切换的方法(java类的名称) -->\n          <property>\n                  <name>dfs.client.failover.proxy.provider.ns</name>\n              <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n          </property>\n      \t<!-- 指定failover切换的方法，这里使用ssh通信方式交换 -->\n          <property>\n                  <name>dfs.ha.fencing.methods</name>\n                  <value>\n                  sshfence\n                  shell(/bin/true)\n                  </value>\n          </property>\n      \t<!-- ssh切换方法需要指定私钥文件位置 -->\n          <property>\n                  <name>dfs.ha.fencing.ssh.private-key-files</name>\n                  <value>/root/.ssh/id_rsa</value>\n          </property>\n  </configuration>\n  ```\n\n-  注意\n\n   -  假设当备份份数为2时，现在有三台DataNode机器，文件被分为2个block，block1位于1和2上，block2位于1和3上，这是若机器3宕机了，hdfs会在设定的`dfs.namenode.heartbead.recheck-interval`时间间隔内检查出机器3(在此时间间隔内可能会出现文件数量紊乱的现象)，此时block2数量变为1，hdfs会自动将1中的block2复制一份到另外一台可用机器上（此处为2）。当机器3恢复运行时，3中备份的block2会自动删除。\n   -  当使用jdbc访问hdfs时，不会使用`hdfs-site.xml`中的`dfs.replication`，而会默认使用3，可在java的`configuration`中配置为指定值\n\n##### 修改slaves文件\n\n```sh\nvim $HADOOP_HOME/etc/hadoop/slaves\n```\n\n- 作用：为各个master指定为其工作的slave\n\n- 需要修改的机器：master、master1\n\n- 内容\n\n  ```txt\n  slave1\n  slave2\n  slave3\n  ```\n\n##### 修改yarn-site.xml\n\n```sh\nvim $HADOOP_HOME/etc/hadoop/yarn-site.xml\n```\n\n- 作用：yarn集群的核心配置文件\n\n- 需要修改的机器：master、master1、slave1、slave2、slave3\n\n- 内容：\n\n  ```xml\n  <configuration>\n      <!-- 启用yarn集群的高可用机制 -->\n      <property>\n          <name>yarn.resourcemanager.ha.enabled</name>\n          <value>true</value>\n      </property>\n      <!-- 指定ResourceManager集群id，可为任意字串 -->\n      <property>\n          <name>yarn.resourcemanager.cluster-id</name>\n          <value>yrc</value>\n      </property>\n      <!-- 指定两台ResourceManager的名称 -->\n      <property>\n          <name>yarn.resourcemanager.ha.rm-ids</name>\n          <value>rm1,rm2</value>\n      </property>\n      <!-- 指定两台ResourceManager的主机名 -->\n      <property>\n          <name>yarn.resourcemanager.hostname.rm1</name>\n          <value>master</value>\n      </property>\n      <property>\n          <name>yarn.resourcemanager.hostname.rm2</name>\n          <value>master1</value>\n      </property>\n      <!-- 指定两台ResourceManager的web端口，正常情况为8088 -->\n      <property>\n          <name>yarn.resourcemanager.webapp.address.rm1</name>\n          <value>master:8088</value>\n      </property>\n      <property>\n          <name>yarn.resourcemanager.webapp.address.rm2</name>\n          <value>master1:8088</value>\n      </property>\n      <!-- 指定管理集群的Zookeeper集群的地址及对应端口 -->\n      <property>\n          <name>yarn.resourcemanager.zk-address</name>\n          <value>node0:2181,node1:2181,node2:2181</value>\n      </property>\n      <property>\n          <name>yarn.nodemanager.aux-services</name>\n          <value>mapreduce_shuffle</value>\n      </property>\n      <property>\n          <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>\n          <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n      </property>\n      <!-- 指定jar包路径 -->\n      <property>\n          <name>yarn.application.classpath</name>\n          <value>/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar</value>\n      </property>\n  </configuration>\n  ```\n\n##### 修改mapred-site.xml\n\n- 作用：指定MapReduce操作的基本属性\n\n- 需要修改的机器：master、master1\n\n- 内容\n\n  ```xml\n  <configuration>\n  <property>\n      <name>mapreduce.framework.name</name>\n      <value>yarn</value>\n  </property>\n  <property>\n      <name>mapreduce.application.classpath</name>\n      <value>/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/contrib/capacity-scheduler/*.jar</value>\n  </property>\n  </configuration>\n  ```\n\n- 注意：\n\n  - MapReduce是不一定依赖yarn的，但一般使用yarn框架来实现MapReduce\n  - 此项若是不配，一些job只会在本机跑，而不会分发给其他机器\n\n##### 修改hive-site.xml\n\n```sh\nvim $HIVE_HOME/conf/hive-site.xml\n```\n\n- 作用：hive的基本配置\n\n- 需要修改的机器：master、master1\n\n- 内容：\n\n  - 修改`hive.server2.webui.host`\n\n      ```xml\n      <property>\n          <name>hive.server2.webui.host</name>\n          <value>${hostname}</value>\n          <description>The host address the HiveServer2 WebUI will listen on</description>\n      </property>\n      ```\n\n      其中`${hostname}`需要改成对应的主机名称(master与master1)，或者都改为`0.0.0.0`\n\n  - 修改`hive.server2.bind.host`\n\n      ```xml\n      <property>\n          <name>hive.server2.thrift.bind.host</name>\n          <value>${hostname}</value>\n          <description>Bind host on which to run the HiveServer2 Thrift service.</description>\n      </property>\n      ```\n\n      其中`${hostname}`需要改成对应的主机名称(master与master1)，或者都改为`0.0.0.0`\n\n  - 修改`hive.server2.zookeeper.namespace`\n\n      ```xml\n      <property>\n          <name>hive.server2.zookeeper.namespace</name>\n          <value>hiveserver2</value>\n          <description>The parent node in ZooKeeper used by HiveServer2 when supporting dynamic service discovery.</description>\n      </property>\n      ```\n\n      注意两个hiveserver节点的该值应设置为一样，指定了改值后，每当一个hiveserver节点启动时，在Zookeeper集群中，目录树下的hiveserver2文件夹下就可以看到该节点注册到Zookeeper中。\n\n  - 修改`javax.jdo.option.ConnectionURL`、`javax.jdo.option.ConnectionPassword`和`javax.jdo.option.ConnectionDriverName`\n\n      ```xml\n      <property>\n          <name>javax.jdo.option.ConnectionURL</name>\n              <value>jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false&amp;allowPublicKeyRetrieval=true</value>\n          <description>\n            JDBC connect string for a JDBC metastore.\n            To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.\n            For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.\n          </description>\n      </property>\n      <property>\n          <name>javax.jdo.option.ConnectionPassword</name>\n              <value>root</value>\n          <description>password to use against metastore database</description>\n      </property>\n      <property>\n          <name>javax.jdo.option.ConnectionDriverName</name>\n              <value>com.mysql.jdbc.Driver</value>\n          <description>Driver class name for a JDBC metastore</description>\n      </property>\n      ```\n\n      这里两个节点的数据库连接字符串也应该是一样的，需要知道的是这里只有master节点安装并运行了mysql服务，存储hive元数据的均在此mysql数据库中，意即存储元数据信息是与master1无关的，实际上mysql服务器可以在网络上的任意位置(~~此处我一开始也误解了，以为master和master1节点都需要存储hive的元数据~~)。\n\n      另外，mysql的连接jar包需要下载并复制到hive的lib目录下。\n\n至此整个Hadoop集群已经搭建完毕，却未完，需要使用Zookeeper集群来实现集群的高可用性（HA）。\n\n#### Zookeeper配置\n\n对于剩下的node0、node1、node2三台机器是用于搭建Zookeeper集群的，因此需要安装并配置Zookeeper-3.4.10：\n\n```sh\nvim /usr/local/zookeeper/conf/zoo.cfg\n# 添加一下内容\nserver.1=192.168.137.200:2888:3888\nserver.2=192.168.137.201:2888:3888\nserver.3=192.168.137.202:2888:3888\n# 保存并关闭\n```\n\n#### ssh免密登录配置\n\n- 作用：保证任何一台机器都可通过ssh免密访问其他机器，这对于使用sshfence策略的failover机制是很必要的\n\n- 需要修改的机器：所有机器\n\n- 内容：\n\n  ```sh\n  # 进入用户目录下的`.ssh`目录\n  cd\n  cd .ssh/\n  # 创建公钥私钥对\n  ssh-keygen -t rsa\n  # 将公钥发送给其他所有节点，hostname需对应每一台机器更改为其主机名执行一遍\n  ssh-copy-id ${hostname}\n  ```\n\n至此，Hadoop集群与Zookeeper集群已搭建完毕，接下来需要启动之。\n\n### 集群启动\n\n#### 初始化数据库\n\n在master机器上执行以下操作以初始化数据库：\n\n```sh\ncd $HIVE_HOME\nschematool -initSchema -dbType mysql\n```\n\n此命令执行完之后将会在mysql中创建hive的元数据表，以存储hive的表结构及其他属性。\n\n#### 启动集群\n\n在master机器上执行以下操作以启动集群：\n\n```sh\n\n```\n\n## 项目功能需求\n\n### 项目主题\n\n**超市销售管理系统**\n\n### 功能简介\n\n#### 商品进货\n\n**功能点说明**：超市管理员查询供应商，并根据结果输入从该供应商进货的商品信息\n\n**数据需求**：查询供应商，新增进货记录，新增商品\n\n#### 查询商品\n\n**功能点说明**：超市管理员通过商品名搜索库存中的所有相关商品\n\n**数据需求**：查询商品\n\n#### 生成订单\n\n功能点说明：超市管理员查询相应商品并将其添加至订单中，添加完毕后生成订单\n\n数据需求：查询商品，新增购买记录，新增订单\n\n### 概念设计\n\n基于面向对象的思想，我们在分析数据需求的时候简单地将我们的系统分为两个模块：进货和购买，这两个模块都以商品为核心。因此在构建实体-联系模型时，我们也根据这个思想出发，将E-R图分为了两个模块。\n\n#### 总体E-R图\n\n![image-20181231170852678](/images/image-20181231170852678-6247332.png)\n\n#### 进货模块E-R图\n\n![image-20181231170913607](/images/image-20181231170913607-6247353.png)\n\n进货模块主要包含两个实体集，公司（Corporation）和商品（Commodity）。商品中包含着超市库存商品的信息如商品名称、数量、价格，公司类包含供应商的信息如公司名称、地址、国家等。两个实体之间有着关系集供应（Supply），表示某商品从某公司进货。由于一种商品可能从多个公司进货，一个公司也可能供应多种商品，因此他们之间的关系应该是多对多。供应关系集同时还具有属性，表示进货的信息包括数量、成本、时间。\n\n#### 购买模块E-R图\n\n![image-20181231170937495](/images/image-20181231170937495-6247377.png)\n\n购买模块包含的实体集有商品（Commodity）和订单（Bill）。订单表示一次完整购买的总订单（包含购买的所有商品情况），包含的信息有总价、折扣、实际价格等。商品和订单之间有关系集购买（Purchase），由于一个订单包含多个商品，一个商品也会被多次购买，因此这个关系是多对多的。同时，购买关系还具有属性，表示订单中的每一种商品购买的数量和小计价格。\n\n### 逻辑设计\n\n#### 表设计\n\n根据E-R模型的转化，我们生成了5张表，分别是：Corporation（公司），Supply（供应），Commodity（商品），Purchase（购买），Bill（订单）。表的详细设计如下：\n\n###### Commodity表\n\n| 字段名   | 数据类型 | 长度 | 说明       | 备注 |\n| -------- | -------- | ---- | ---------- | ---- |\n| ID       | number   | 10   | 商品的ID   | PK   |\n| name     | varchar  | 20   | 商品名称   |      |\n| quantity | decimal  | 10,2 | 商品库存量 |      |\n| price    | decimal  | 10,2 | 商品单价   |      |\n\n###### Corporation表\n\n| 字段名   | 数据类型 | 长度 | 说明         | 备注 |\n| -------- | -------- | ---- | ------------ | ---- |\n| ID       | number   | 10   | 公司的ID     | PK   |\n| name     | varchar  | 20   | 公司名称     |      |\n| address  | varchar  | 20   | 公司地址     |      |\n| country  | varchar  | 10   | 公司所在国家 |      |\n| business | varchar  | 10   | 公司业务     |      |\n\n###### Bill表\n\n| 字段名     | 数据类型 | 长度 | 说明         | 备注 |\n| ---------- | -------- | ---- | ------------ | ---- |\n| ID         | number   | 10   | 订单的ID     | PK   |\n| totalprice | decimal  | 10,2 | 订单总价     |      |\n| discount   | decimal  | 10,2 | 订单折扣     |      |\n| finalprice | decimal  | 10,2 | 订单实际总价 |      |\n| realpay    | decimal  | 10,2 | 顾客付款     |      |\n| charge     | decimal  | 10,2 | 找钱         |      |\n\n###### Supply表\n\n|  字段名   | 数据类型 | 长度 | 说明           | 备注                            |\n| :---------- | :--------- | ---- | :---------------- | --------------------------- |\n|   corID   | number   | 10   | 供应公司的ID   | PK;   FK，参照于Corporation的ID |\n| productID | number   | 10   | 商品的ID       | PK；FK，参照于Commodity的ID     |\n|  amount   | decimal  | 10,2 | 商品供应数量   |                                 |\n| totalcost | number   | 6    | 商品供应总成本 |                                 |\n| supplydate | datetime | 0 | 供应日期 |  |\n\n###### Purchase表\n\n| 字段名    | 数据类型 | 长度 | 说明               | 备注                    |\n| --------- | -------- | ---- | ------------------ | ----------------------- |\n| productID | number   | 10   | 购买商品的ID      | PK；参照于Commodity的ID |\n| billID    | number   | 10   | 订单ID           | PK；参照于Bill的ID      |\n| amount    | decimal  | 10,2 | 购买该商品数量     |                         |\n| sumprice  | decimal  | 10,2 | 购买该商品小计价格 |                         |\n\n#### 数据库关系图\n\n根据表的设计和之间的外码约束，绘制出数据库的关系图：\n\n![image-20181231171547272](/images/image-20181231171547272-6247747.png)\n\n### Hive中的实际存储\n\n经过多次尝试与实验，发现Hive中实际上是不支持表间外键联系的，因此我们在实际存储上述的表结构时将所有的外键均去除了。\n\n> 这引出了数据仓库在实际应用中的一种常见处理方式：为了提高速度而产生数据冗余。Hive中的表结构的特殊性，使得\b使用人员方便针对各种功能设计所需的信息表，而非使用传统的符合3NF或者其他范式的表结构，这也是数据仓库作为大量数据集的OLAP最佳选择的原因之一(其消除了由于大量表间连接时而产生的冗余操作，这是很典型的以**空间**换取**时间**的策略)。\n\n## 项目实现方法\n\n整个项目我们使用传统的JavaWeb框架。后端使用Servlet处理数据交互，使用JDBC连接Zookeeper管理的Hiveserver2集群；前端使用Bootstrap框架完成基本的项目展示功能：\n\n![1](/images/1.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t图1：查看库存\n\n![2](/images/2.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t图2：查看历史账单\n\n![3](/images/3.png)\n\n​\t\t\t\t\t\t\t\t\t\t\t图3：创建新账单\n\n我们深知本项目重点在分布式集群而非前端展示上，因此我们组将95%的精力放在项目的理论理解、环境搭建、性能提升以及实践使用上。\n\n## 项目亮点\n\n### HA的原理理解及实现\n\nHA的实现是我们组在搭建集群时遇到的最大的难题，如何协调其主次关系、如何保证网络通信、如何确定哪些进程应该运行在哪些合适的机器上，举个例子：在我们完成集群搭建到了最后启动Hive时，启动了两个Hive客户端进程和两个Hiveserver2服务端进程，而两个Hive客户端又共用了同一个MySQL服务器，导致jdbc在连接Zookeeper时会随机访问到两个Hive客户端，这导致了数据库数据时而一致、时而不一致，后来我们在Hive的配置文件将其连接Hive客户端改为同一个后将其解决了。诸如此类的小问题我们遇到了很多很多，最后都一一得到了解决。\n\n### Hive与MySQL的横向对比\n\n我们发现Hadoop集群启动后，前端与后端进行数据交互的速度很慢，于是我们使用MySQL与Hive做了简单的对比，结果很让我们困惑：MySQL的执行时间基本上是远远快于Hive的执行时间的。\n\n我们从以下角度进行了思考与实验：\n\n首先，考虑我们在这两种数据库中执行的操作，如果对于一开始数据从文件进入数据库中这一过程忽略的话，我们整个项目执行的都是OLAP即联机分析处理操作。Hive作为一个经典的数据仓库工具，本身应该是擅长执行OLAP操作的，因此暂且认为\"操作\"不是造成二者执行时间差异的原因；\n\n其次，Hive官网有句话\b\"Hive在大型数据集上会表现出优越的性能\"，考虑到我们的项目数据集\b中，最多的数据集是数百万条的商品库存数据，我们猜测是数据量限制了Hive体现其\b优越性。因此我们作了如下实验：将数据量从10W变化到1000W，然后观察在等量的数据量变化上，二者执行时间的变化，得到下表：\n\n| 数据库类型     | 10W数据 | 1000W数据 |\n| -------------- | ------: | :-------: |\n| MySQL          |     9ms |   271ms   |\n| Hive(textfile) |  1428ms |  5100ms   |\n\n就时间来说，很显然MySQL更胜一筹，但从增长比例来说，MySQL从9ms增长至271ms增长约为30倍，而\bHive增长约为5倍，由此我们可窥见Hive在大量数据集时性能会更加优越。\n\n然而在这过程中，\b我们所使用的Hive所采用的为textfile存储结构，意即内容即文件，表数据完全按照表结构存储成为文本文件。\b从Hive官方文档我们得知Hive有其他更加优越的存储格式，它包含SequenceFile、RCFile、ORCFile，因此我们采取了所谓最优的ORCFile来Duplicate了用户评论表，想以此对比ORCFile之于TextFile的优点。存储中源数据文件大小为872MB，当使用textfile格式存储时，Hive会将我们导入的文件原封不动的移动到hdfs的Hive数据文件目录下，而使用ORCFile格式存储时文件大小只有260MB大小，这是其优点之一：**文件压缩**。至于性能，我们执行了上述同样的实验：\n\n| 数据库类型     | 10W数据 | 1000W数据 |\n| -------------- | ------: | :-------: |\n| MySQL          |     9ms |   271ms   |\n| Hive(textfile) |  1428ms |  5100ms   |\n| Hive(ORC)      |   110ms |   126ms   |\n\n结果显而易见，当数据达到\b数百万量级时，Hive在存储模式**较优**的使用方法下已经要比MySQL要稍显胜势了。\n\n通过以上两点我们不难总结出以下几点：\n\n- 限制Hive的效率的因素：\n\n  - 数据量\n\n    在百万数据量以下时，Hadoop是很难发挥出其优点的\n\n  - \b计算框架\n\n    Hive在我们项目中使用的是MapReduce框架来执行分布式计算，然而比\b现在已经有很多比MapReduce快得多的计算框架例如Spark等，因此若使用这些框架必定会使Hive执行效率更上一层\n\n  - 网络通信\n\n    由于我们的集群搭建在虚拟机中，其间数据通过真实的网络通信传输，虽然少了中间光纤传递的过程，但是在建立连接到发送数据到取消连接这一过程所耗费的时间都是很难被忽略的，因此生产环境下的Hadoop集群对网络带宽的要求是很高的\n\n- 百万级数据的OLAP场景或者OLTP操作需求较多的场景下，MySQL(关系型数据库)是优选\n\n- 千万乃至亿万级数据的批处理、分析场景，Hive(数据仓库/分布式数据库)在存储、读取、分析效率上都要更优\n","tags":["Hadoop","云计算","大三上笔记"],"categories":["archives"]},{"title":"Hadoop-Tags","url":"/2018/12/12/Hadoop-Tags/","content":"\n> 更新中……\n\n<!-- more -->\n\n# Hadoop Tags\n\n## HDFS\n\n1. NameNode内存要求较高，存储文件系统元结构（文件目录结构、分块情况、每块位置、权限等）\n\n2. 文件分块默认最小块128M\n\n3. `jps`命令查看NameNode/DataNode是否启动\n\n   1. ~~jps在jdk8u191中好像不适用，暂未找到解决方法~~\n\n4. `ip:9870`利用web界面查看Hadoop节点信息（Mac上端口号为`50070`）\n\n5. 进入用户目录下的`.ssh`目录，执行`ssh-keygen -t rsa`创建公钥私钥，使用`ssh-copy-id ${hostname}`将公钥传给每个节点（NameNode和DataNode都需要）\n\n6. 使用`hadoop fs -ls /`查看Hadoop上所有文件，使用`hadoop fs -put ${filename} /`上传文件…\n\n7. `hdfs-site.xml`中修改`dfs.replication`配置可修改文件备份份数（默认为3），修改`dfs.namenode.heartbead.recheck-interval`指定Hadoop检查机器运行情况的时间间隔（默认3000000ms）\n\n   注意：\n\n   1. 例如当备份份数为2时，现在有三台DataNode机器，文件被分为2个block，block1位于1和2上，block2位于1和3上，这是若机器3宕机了，hdfs会在设定的`dfs.namenode.heartbead.recheck-interval`时间间隔内检查出机器3，此时block2数量变为1，hdfs会自动将1中的block2复制一份到另外一台可用机器上（此处为2）。当机器3恢复运行时，3中备份的block2会自动删除。\n   2. 当使用java访问hdfs时，不会使用`hdfs-site.xml`中的`dfs.replication`，而会默认使用3，可在java的`configuration`中配置为指定值\n\n8. `分鱼展`:分块、冗余、可扩展\n\n## Yarn\n\n1. ResourceManage\n\n2. NodeManage一般与DataNode放一起 \n\n3. Yarn逻辑上与HDFS完全分离，但一般绑定HDFS一起使用\n\n4. `yarn-site.xml`的配置\n\n   **注意：master与slaves都需要进行配置。**\n\n   ```xml\n    <property>\n        <name>yarn.resourcemanager.hostname</name>\n        <value>master</value>\n    </property>\n   ```\n\n5. `mapred-site.xml`的配置\n\n   **注意：**\n\n   - 仅NameNode需要配置\n   - MapReduce不一定需要Yarn\n   - 若不配MapReduce，其会仅在单机跑\n\n   ```xml\n   <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n   </property>\n   ```\n\n# Hive\n\n1. 创建Hive、Hadoop环境变量，方便敲命令\n\n2. 修改`hive-site.xml`\n\n   1. hive的conf目录下刚初始化时没有\bhive-site.xml，需要将`hive-default.xml.template`复制一份更名为hive-site.xml\n   2. 将hive-site.xml中所有的(4个)`${system:java.io.tmpdir}`替换为`/usr/local/hive/tmp`，将所有的(4个)`${system:user.name}`替换为`root`\n\n3. 进入hive根目录，执行\n\n    ```shell\n    schematool -initSchema -dbType derby\n    ```\n    - 上述命令执行完毕后会在对应目录下新建metastore_db目录，用于存储数据目录\n    - derby是hive自带的小数据库，后续需要将derby更换成mysql(TODO)\n\n4. \b在该目录下启动\b执行`hive`\n\n   **注意：**\n   - hive命令执行时，必须与metastore_db在同一目录下\n   - hive启动前需要将hdfs也启动，不然会报错\n\n5. hive连接mysql\n\n    - 关于\b虚拟机安装了mysql数据库，主机无法连接的问题如下：\n\n    ```plsql\n    mysql> use mysql;\n    Database changed\n    mysql> select 'host' from user where user='root'\n        -> ;\n    +------+\n    | host |\n    +------+\n    | localhost |\n    +------+\n    1 row in set (0.00 sec)\n\n    mysql> update user set host = '%' where user ='root';\n    Query OK, 1 row affected (0.00 sec)\n    Rows matched: 1  Changed: 1  Warnings: 0\n\n    mysql> flush privileges;\n    Query OK, 0 rows affected (0.01 sec)\n\n    mysql> select 'host'   from user where user='root';\n    +------+\n    | host |\n    +------+\n    |  %   |\n    +------+\n    1 row in set (0.00 sec)\n    ```\n\n    - 解决jdbc连接hive时出现`Open Session Error`\n\n    ```xml\n    <property>\n        <name>hadoop.proxyuser.hadoop.hosts</name>\n        <value>*</value>\n    </property>\n    <property>\n        <name>hadoop.proxyuser.hadoop.groups</name>\n        <value>*</value>\n    </property>\n    ```\n\n6. hive表存储格式\n\n   1. TextFile\n   2. SequenceFile\n   3. RCFile\n   4. ORCFile\n\n# HA的实现\n\n## 集群环境\n\n- Hadoop 2.9.2\n- \bHive 2.3.4\n- MySQL 5.7\n- Zookeeper 3.4.10\n- JDK 8u191\n\n## 集群结构图\n\n> 共9台机器，其中3台ZooKeeper集群，5台Hadoop集群（2台Master，3台Slave），1台应用服务器\n\n| 主机名 | IP | 软件 | 运行进程 |\n| :--------: | :--------:| :--: | :--: |\n| node0 | 192.168.137.200 | ZooKeeper | QuorumPeerMain |\n| node1 | 192.168.137.201 | ZooKeeper | QuorumPeerMain |\n| node2 | 192.168.137.202 | ZooKeeper | QuorumPeerMain |\n| master | 192.168.137.100 | Hadoop,Hive,MySql | JournalNode,NameNode,ResourceManager,<br/>DFSZKFailoverController,HiveServer2,MySql |\n| master1 | 192.168.137.10 | Hadoop,Hive | JournalNode,NameNode,ResourceManager,<br/>DFSZKFailoverController,HiveServer2 |\n| slave1 | 192.168.137.101 | Hadoop | JournalNode,DataNode,NodeManager |\n| slave2 | 192.168.137.102 | Hadoop | DataNode,NodeManager |\n| slave3 | 192.168.137.103 | Hadoop | DataNode,NodeManager |\n| host | 192.168.137.1 | 应用服务器 | |\n\n## 集群启动步骤\n\n```shell\n# 在三台zookeeper上启动zkServer\nzkServer.sh start\n\n# master上执行hdfs和yarn集群的启动\nstart-dfs.sh\nstart-yarn.sh\n\n# master1上的ResourceManager不知道为何不会自动启动，因此手动\nyarn-daemon.sh start resourcemanager\n\n# master和master1上\b都要启动hiveserver2\nhiveserver2\n```\n\n## 关于[二级缓存](http://www.datanucleus.org/products/accessplatform_3_0/jpa/cache.html)的若干事宜\n\n在集群启动完毕之后，我在master的hive中使用`create table test(...)`语句创建了一个表并导入了一些数据，而后通过应用执行该表的相关查询后，发现时不时提示表`test`不存在，通过hive查看master和master1的表结构，发现master1中竟然没有表test，查阅资料后看到一篇博文[《hive datanucleus cache 不一致问题》](https://blog.csdn.net/lalaguozhe/article/details/9184593)，是关于hive中的DataNucleus二级缓存的设置，`datanucleus.cache.level2.type`的设置(`none`,`soft`,`weak`)直接影响二级缓存是否启用，关于二级缓存的具体机制我还没弄清楚，之后我又在[Hortonworks](https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_command-line-installation/content/set_up_hive_hcat_configuration_files.html)的文档中看到下面的话：\n\n> **Important**:\n> Hortonworks recommends that deployments <font color=red>**disable the DataNucleus cache**</font> by setting the value of the datanucleus.cache.level2.type configuration parameter to none. The datanucleus.cache.level2 configuration parameter is ignored, and assigning a value of none to this parameter does not have the desired effect.\n\n可能是\bHiveserver2本身在HA的层面就不建议修改库、表结构，因此若要更改表结构或者创建新表同时实现数据同步，我试了以下两种方式均可实现：\n\n1. 第一种关闭并重新初始化集群，启动master和所有的DataNode，在master上执行建库建表导入数据，而后启动master1将其作为standby初始化，这时master1会同步master的数据，最后启动master和master1的hiveserver2\n\n2. 第二种是同时在master和master1的hive客户端上执行同样的建表语句，而后在master(或者master1)上执行`load`命令加载数据，即可同步数据\n\n    > \b第二种方法又出现了个有趣的问题：导入数据完成后，在两台机器上分别执行`count`操作会发现由于加载数据的机器count正常，另一台机器count结果为0，但是执行`select *`又确实能发现数据存在，就很玄学。\n\n# TODO List\n\n- 安全与权限（kerberos）\n- Secondary NameNode（check point NameNode）\n- HA（High Ability）实现\n- Federation，超大规模数据中心","tags":["Hadoop","云计算"],"categories":["archives"]},{"title":"Best Practice","url":"/2018/11/24/Practice/","content":"\n> Oracle专家的三次授课。\n\n<!--more-->\n\n# Lesson 1\n\n## 创建用户并分配权限\n\n### 创建测试schema，命名为test\n\n```plsql\ncreate user test identified by test;\n```\n\n### 分配连接资源\n\n```plsql\ngrant connect,resource to test;\ngrant execute on dbms_lock to test;\ngrant execute on UTL_FILE to test;\n```\n\n### 为test用户创建external_data目录以及分配权限\n\n```plsql\ncreate directory external_data as '/home/oracle/data';\ngrant read,write on directory external_data to test;\n```\n\n> 要注意oracle用户必须拥有对这里的external_data路径读写的权限。\n\n### 分配表空间权限\n\n我们知道oracle中没有库的概念，取而代之的是表空间（Tablespace），在oracle初次被安装时，数据库中只有系统本身内置的表空间：\n\n- **SYSTEM** - 存储数据字典\n- **SYSAUX** - 存储辅助应用程序的数据\n- **TEMP** - 存储数据库临时对象\n- **USERS** - 存储各个用户创建的对象\n- **UNDOTBS** - 存储不一致数据，用于事物回滚、数据库恢复、读一致性、闪回查询\n- ……\n\n而当第一次通过管理员创建一个用户且未为其创建并指定表空间时，数据库系统会为其指定默认的表空间为SYSTEM，而他并没有使用SYSTEM表空间的权限，因此该用户无法完成建表等操作，可通过执行以下操作：\n\n```plsql\n-- DBA下执行：\n-- 查看数据库中的所有表空间\nselect * from v$tablespace;\n-- 查看当前用户所在的表空间(注意oracle系统表中存储的用户名字段都是大写，要注意这与“oracle中不区分大小写”这一概念区分开来)\nselect username,default_tablespace from dba_users where username='TEST';\n-- 为用户赋予当前表空间下的权限\nalter user test quota unlimited on users;\n--  或者制定用户可用大小：\nalter user test quota 50M on users;\n```\n\n\n\n## 连接用户，建表，跑存储过程和函数\n\n### 连接test用户\n\n```shell\n-- 在系统命令下连接\ncd $ORACLE_HOME/bin\n./sqlplus test/test\n```\n\n```plsql\n-- 在进入sqlplus后的连接\nconn test/test\n```\n\n### 创建表\n\n```plsql\ncreate table t_mobiles(f_id number(6),f_mobile_head varchar2(50),f_province varchar2(50),f_city varchar2(50),f_platform varchar2(50),f_tel_head varchar2(50),f_zipcode varchar2(50),primary key(f_id));\nCOMMENT ON COLUMN T_MOBILES.F_ID IS '主键';\nCOMMENT ON COLUMN T_MOBILES.F_MOBILE_HEAD IS '手机号段';\nCOMMENT ON COLUMN T_MOBILES.F_PROVINCE IS '省份地区';\nCOMMENT ON COLUMN T_MOBILES.F_CITY IS '城市';\nCOMMENT ON COLUMN T_MOBILES.F_PLATFORM IS '运营商';\nCOMMENT ON COLUMN T_MOBILES.F_TEL_HEAD IS '固话区号';\nCOMMENT ON COLUMN T_MOBILES.F_ZIPCODE IS '邮政编码';\nCOMMENT ON TABLE T_MOBILES  IS '号段表';\n\ncreate table t_records(f_id number(6),f_no varchar2(50),f_begin_time date,f_end_time date,f_duration number(10,0),f_province VARCHAR2(50), f_platform varchar2(50), f_mobile NUMBER(1) DEFAULT -1);\n--*注：因f_id导入时缺少数据，所有先不设置为PK.\nCOMMENT ON COLUMN T_RECORDS.F_ID IS '主键';\nCOMMENT ON COLUMN T_RECORDS.F_NO IS '通话号码';\nCOMMENT ON COLUMN T_RECORDS.F_BEGIN_TIME IS '开始时间';\nCOMMENT ON COLUMN T_RECORDS.F_END_TIME IS '结束时间';\nCOMMENT ON COLUMN T_RECORDS.F_DURATION IS '通话时长';\nCOMMENT ON COLUMN T_RECORDS.F_PROVINCE IS '省份地区';\nCOMMENT ON COLUMN T_RECORDS.F_PLATFORM IS '运营商';\nCOMMENT ON COLUMN T_RECORDS.F_MOBILE IS '手机号码标志';\nCOMMENT ON TABLE T_RECORDS  IS '通话清单表';\n```\n\n### 创建ctl文件导入csv数据\n\n进入`external_data`路径下并创建以下文件：\n\n```shell\n$ cd /home/oracle/data\n$ vi control_mobiles.ctl\n$ vi control_records.ctl\n```\n\n`control_mobiles.ctl:`\n\n```ctl\nLOAD DATA\nCHARACTERSET UTF8\nINFILE '/home/oracle/data/mobiles.csv'\nTRUNCATE INTO TABLE t_mobiles\nFIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"'\nTRAILING NULLCOLS\n(\n\tF_ID,\n\tF_MOBILE_HEAD,\n\tF_PROVINCE,\n\tF_CITY,\n\tF_PLATFORM,\n\tF_TEL_HEAD,\n\tF_ZIPCODE\n)\n```\n\n`control_records.ctl:`\n\n```\nLOAD DATA\nCHARACTERSET UTF8\nINFILE '/home/oracle/data/records.csv'\nTRUNCATE INTO TABLE t_records\nFIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"'\nTRAILING NULLCOLS\n(\n\tF_NO,\n\tF_BEGIN_TIME DATE \"YYYY-MM-DD HH24:MI:SS\",\n\tF_END_TIME DATE \"YYYY-MM-DD HH24:MI:SS\",\n\tF_DURATION INTEGER EXTERNAL\n)\n```\n\n在该路径下执行导入操作：\n\n```shell\n$ $ORACLE_HOME/bin/sqlldr userid=test/test control=control_mobiles.ctl\n$ $ORACLE_HOME/bin/sqlldr userid=test/test control=control_records.ctl\n```\n\n> 教程中命令为：\n>\n> ```shell\n> $ sqlldr userid=test/test@orcl control=control_mobiles.ctl\n> ```\n>\n> 即在导入时指定`连接字符串`（这里的orcl实际上是连接字符串的别名），其在`$ORACLE_HOME/network/admin/tnsname.ora`中被声明，但是默认状态下oracle中并没有配置该连接字符串，意味着我们在连接时不需要为其指定值。\n>\n> 既然如此，应用程序该如何在未进行上述配置的情况下连接到该字符串呢？这里就是`连接字符串`和`服务名`的区别，oracle有个默认服务名`XE`，实际上oracle中还有多个备用服务，当XE服务崩掉的时候会自动切换到备用服务。连接字符串如下：\n>\n> ```\n> jdbc:oracle:thin:@localhost:1521:XE\n> ```\n>\n> 那么没有配置连接字符串别名时，sqlplus如何通过此方法连接呢？如下直接将连接字符串全部写全：\n>\n> ```shell\n> # 命令格式：sqlplus username/password@host:port/service_name\n> $ sqlplus tanrui/tanrui@127.0.0.1:1521/xe\n> ```\n>\n\n\n\n## 数据预处理\n\n```plsql\n-- 1、创建序列seq_records_pk用于生成通话记录表t_records的主键\ncreate sequence seq_records increment by 1 start with 1 ;\n\n-- 2、修补通话记录表t_records的主键数据，并把f_id改为主键\nupdate t_records set f_id=seq_records.nextval;\nalter table t_records add constraint t_records_pk primary key (f_id);\n\n-- 3、创建并初始化同步锁表，用于多线程同步控制\nCREATE TABLE T_LOCK(F_NAME VARCHAR2(30),F_INDEX NUMBER(20,0),PRIMARY KEY(F_NAME));\nCOMMENT ON COLUMN T_LOCK.F_NAME IS '锁名';\nCOMMENT ON COLUMN T_LOCK.F_INDEX IS '锁的当前值';\nCOMMENT ON TABLE T_LOCK  IS '同步锁表';\ninsert into T_LOCK values('_RECORD_INDEX',0);\n\n-- 4、在电话号段表中创建唯一性索引，提高号段检索速度\ncreate unique index uniq_mobile_head on t_mobiles(f_mobile_head);\nupdate t_mobiles set f_province = '内蒙古' where f_province = '内蒙';\n\n-- 5、创建日志表，用于记录程序执行过程中的日志信息。\ncreate table t_log(f_time date, f_head varchar2(20), f_content varchar2(500));\nCOMMENT ON COLUMN T_LOG.F_TIME IS '日志时间';\nCOMMENT ON COLUMN T_LOG.F_HEAD IS '日志类型标志';\nCOMMENT ON COLUMN T_LOG.F_CONTENT IS '日志内容';\nCOMMENT ON TABLE T_LOG  IS '日志表';\n```\n\n\n\n## 创建函数和存储过程\n\n### 声明函数和存储过程\n\n- 函数is_mobile，判断通话号码是否为手机号码\n\n```plsql\n--函数：判断通话号码是否为手机号码\nCREATE OR REPLACE FUNCTION is_mobile(phone VARCHAR2)\n    RETURN BOOLEAN IS\n\n    v_phone VARCHAR2(20);\n    v_head VARCHAR2(2);\nBEGIN\n    --检查参数func\n    IF phone IS NULL THEN\n        RETURN FALSE;\n    END IF;\n\n\t--去除前后空格\n    v_phone := TRIM(phone);\n\n\t--去除号码前面的0\n    IF substr(v_phone,0,1) = '0' THEN\n        v_phone := substr(v_phone, 2);\n    END IF;\n\n\t--检查手机号码长度\n    IF substr(v_phone,0,1) <> '1' OR LENGTH(v_phone) <> 11 THEN\n        RETURN FALSE;\n    END IF;\n\n\t--截取号码前两位\n    v_head := substr(v_phone,1,2);\n\n    IF v_head = '13' OR v_head = '14' OR v_head ='15' OR v_head ='17' OR v_head = '18' THEN\n        RETURN TRUE;\n    ELSE\n        RETURN FALSE;\n    END IF;\nEND;\n/\n```\n\n- 存储过程init，清空t_log，同时t_lock置零\n\n```plsql\n--存储过程：初始化测试数据\nCREATE OR REPLACE PROCEDURE init IS\n    CURSOR job_cursor IS SELECT JOB FROM user_jobs;\nBEGIN\n\t--重置处理位置为0\n    EXECUTE IMMEDIATE 'update t_lock set f_index=0';\n\n\t--清除日志表中的记录\n    EXECUTE IMMEDIATE 'truncate table t_log';\n\n\t--重置话单表中的记录\n    EXECUTE IMMEDIATE 'update t_records set f_province = NULL,f_platform=NULL, f_mobile=-1';\n    COMMIT;\n\n    FOR tmp_job IN job_cursor LOOP\n        dbms_job.broken(tmp_job.JOB,TRUE,sysdate);\n        dbms_job.REMOVE(tmp_job.JOB);\n    END LOOP;\nEND;\n/\n```\n\n- 存储过程print，打印日志，存到T_LOG表中\n\n```plsql\n--存储过程：打印日志\nCREATE OR REPLACE PROCEDURE print(prefix VARCHAR2, content VARCHAR2) IS\nBEGIN\n\t--dbms_output.put_line(to_char('yyyy-mm-dd hh24:mi:ss')||','||prefix||','||content);\n\tINSERT INTO t_log VALUES(sysdate,prefix, content);\n\tCOMMIT;\nEXCEPTION\n\tWHEN OTHERS THEN\n\t\tdbms_output.put_line('Error code: '||SQLCODE);\n\t\tdbms_output.put_line('Error mesg: '||sqlerrm);\nEND;\n/\n```\n\n- 存储过程show，显示当前处理情况\n\n```plsql\n--存储过程：显示当前处理情况\nCREATE OR REPLACE PROCEDURE show IS\n\t--待处理记录总数\n    v_record_count NUMBER;\n\n\t--当前日志表记录总数\n    v_log_count NUMBER;\n\n\t--当前数据处理位置\n    v_current_index NUMBER;\n\n\t--用户Job表游标\n    CURSOR job_cursor IS SELECT * FROM user_jobs;\n\nBEGIN\n    SELECT COUNT(1) INTO v_log_count FROM t_log;\n    SELECT f_index INTO v_current_index FROM t_lock;\n    SELECT COUNT(1) INTO v_record_count FROM t_records;\n\n\tdbms_output.put_line('log count: '||v_log_count);\n    dbms_output.put_line('record count: '||v_record_count);\n    dbms_output.put_line('current index: '||v_current_index);\n\n\t--清除用户job记录\n    FOR tmp_job IN job_cursor LOOP\n        dbms_output.put_line('job:'||tmp_job.JOB||',broken:'||tmp_job.broken||',total_time:'||tmp_job.total_time||',failures:'||tmp_job.failures||',interval:'||tmp_job.INTERVAL||',last_sec:'||tmp_job.last_sec||',next_sec:'||tmp_job.next_sec);\n\n    END LOOP;\nEND;\n/\n```\n\n- 存储过程process_data，提交一个job处理数据\n\n> **共享锁和排它锁:**\n>\n> - 当某事务对数据添加共享锁时，此时该事务`只能读不能写`，其他事务只能对该数据添加共享锁，而不能添加排它锁\n>\n> - 当某事务对数据添加排它锁时，此时该事务`既能读又能写`，其他事务不能对该数据添加任何锁\n>\n> **autocommit需要关掉:**\n>\n>\n> 假设现在有三个job对T_LOCK表进行并发读写，如下：\n>\n> ![image-20181124202306595](/images/image-20181124202306595.png)\n>\n> 步骤如下：\n>\n> ![锁](/images/锁.png)\n>\n> 阻塞情况：\n>\n> ![锁2](/images/锁2.png)\n\n```plsql\n--存储过程：处理数据\nCREATE OR REPLACE PROCEDURE process_data(process_no IN NUMBER, batch_size IN NUMBER) IS\n    --定义常量\n    c_record_index CONSTANT VARCHAR2(20)   :='_RECORD_INDEX';\n    c_process_prefix CONSTANT VARCHAR2(20) := '[  PROCESS ]';\n    c_select_record_sql VARCHAR2(100)  := 'select * from t_records where f_id >= :x and f_id <= :y';\n    c_select_mobile_sql VARCHAR2(100)  := 'select * from t_mobiles where f_mobile_head = :x';\n    c_update_mobile_sql VARCHAR2(100)  := 'update t_records set f_province = :x, f_platform = :y, f_mobile = 1 where f_id = :z';\n    c_update_record_sql VARCHAR2(100)  := 'update t_records set f_mobile = 0 where f_id = :n';\n    v_record_count NUMBER;\n    v_current_index NUMBER;\n    v_begin_index NUMBER;\n    v_end_index NUMBER;\n    v_id NUMBER;\n    v_phone VARCHAR2(20);\n    v_province VARCHAR2(20);\n    v_platform VARCHAR2(20);\n    --定义动态游标\n    TYPE ty_record_cursor IS REF CURSOR;\n    record_cursor ty_record_cursor;\n    mobile_cursor ty_record_cursor;\n    v_record_row t_records%rowtype;\n    v_mobile_row t_mobiles%rowtype;\nBEGIN\n    PRINT(c_process_prefix, 'process['||process_no||'], running...');\n    --获取待处理的记录总数\n    SELECT COUNT(1) INTO v_record_count FROM t_records;\n    PRINT(c_process_prefix, 'process['||process_no||'], records count: '||v_record_count);\n    LOOP\n        --获取记录锁\n        SELECT f_index INTO v_current_index FROM t_lock WHERE f_name = c_record_index FOR UPDATE;\n        PRINT(c_process_prefix, 'process['||process_no||'], current index: '||v_current_index);\n        IF v_current_index = v_record_count THEN\n            PRINT(c_process_prefix, 'process['||process_no||'], finished.');\n            EXIT;\n        END IF;\n        --记录本次处理的开始和结束记录位置\n        v_end_index := v_current_index + batch_size;\n        IF v_end_index > v_record_count THEN\n            v_end_index := v_record_count;\n        END IF;\n        --提交事务，释放锁\n        UPDATE t_lock SET f_index = v_end_index WHERE f_name =c_record_index;\n        COMMIT;\n        --计算开始位置\n        v_begin_index := v_current_index +1;\n        PRINT(c_process_prefix, 'process['||process_no||'], begin index:'||v_begin_index||', end index:'||v_end_index);\n        --test：dbms_lock.sleep(5);\n        --查询一批记录进行逐个处理\n        OPEN record_cursor FOR c_select_record_sql USING v_begin_index, v_end_index;\n        LOOP\n            FETCH record_cursor INTO v_record_row;\n            EXIT WHEN record_cursor%notfound;\n            v_id    := v_record_row.f_id;\n            v_phone := v_record_row.f_no;\n            IF is_mobile(v_phone) THEN\n                v_phone := TRIM(v_phone);\n                IF substr(v_phone,0,1) = '0' THEN\n                    v_phone := substr(v_phone, 2);\n                END IF;\n                --PRINT(c_process_prefix, 'process['||process_no||'], id:'||v_id||', phone:'||v_phone);\n                --更新话单记录中的省份、运营商以及手机类型标志\n                OPEN mobile_cursor FOR c_select_mobile_sql USING substr(v_phone,1,7);\n                    FETCH mobile_cursor INTO v_mobile_row;\n                    v_province := v_mobile_row.f_province;\n                    v_platform := v_mobile_row.f_platform;\n                    --FETCH mobile_cursor INTO v_province, v_platform;\n                CLOSE mobile_cursor;\n\t\t\t\t--更新话单记录的运营商、省份地区信息\n                EXECUTE IMMEDIATE c_update_mobile_sql USING v_province,v_platform,v_id;\n            ELSE\n                --更新话单记录为非移动号码类型\n                EXECUTE IMMEDIATE c_update_record_sql USING v_id;\n            END IF;\n\t\t\t--提交事务\n            COMMIT;\n        END LOOP;\n        CLOSE record_cursor;\n        PRINT(c_process_prefix, 'process['||process_no||'], processed index: '||v_end_index);\n    END LOOP;\nEXCEPTION\n    WHEN OTHERS THEN\n        dbms_output.put_line('Error code: '||SQLCODE);\n        dbms_output.put_line('Error mesg: '||sqlerrm);\nEND;\n/\n```\n\n- 存储过程generate_csv_report，生成报表\n\n```plsql\n--存储过程：生成报表\nCREATE OR REPLACE PROCEDURE generate_csv_report IS\n\tc_report_prefix CONSTANT VARCHAR2(20) := '[  REPORT  ]';\n    v_report_1  UTL_FILE.FILE_TYPE;\n    v_report_2  UTL_FILE.FILE_TYPE;\n    CURSOR report_1_cursor IS SELECT f_platform,f_province,SUM(f_duration) total FROM t_records WHERE f_mobile=1 GROUP BY f_platform,f_province ORDER BY f_platform ASC,SUM(f_duration) DESC;\n    cursor report_2_cursor is select f_province,f_platform,sum(f_duration) total from t_records where f_mobile=1 group by f_province,f_platform order by f_province asc,sum(f_duration) desc;\nBEGIN\n    --生成报表1，根据运营商分类汇总各省份地区的通话量\n    v_report_1 := UTL_FILE.FOPEN( LOCATION => 'EXTERNAL_DATA', filename => 'report1.csv', open_mode => 'w', max_linesize => 32767);\n    FOR cur_tmp IN report_1_cursor LOOP\n        UTL_FILE.PUT_LINE(v_report_1, cur_tmp.f_platform || ',' || cur_tmp.f_province || ',' || cur_tmp.total);\n    END LOOP;\n    UTL_FILE.FCLOSE(v_report_1);\n    --生成报表2，根据各省份地区汇总各运营商的通话量\n    v_report_2 := UTL_FILE.FOPEN( LOCATION => 'EXTERNAL_DATA', filename => 'report2.csv', open_mode => 'w', max_linesize => 32767);\n    FOR cur_tmp IN report_2_cursor LOOP\n        UTL_FILE.PUT_LINE(v_report_2, cur_tmp.f_province || ',' || cur_tmp.f_platform || ',' ||  cur_tmp.total);\n    END LOOP;\n    UTL_FILE.FCLOSE(v_report_2);\n    PRINT(c_report_prefix, 'generated reports.');\n    EXCEPTION\n        WHEN OTHERS THEN\n            dbms_output.put_line('Error code: '||SQLCODE);\n            dbms_output.put_line('Error mesg: '||sqlerrm);\nEND;\n/\n```\n\n- 存储过程analysis，调用上述函数，完成任务逻辑，支持指定任务个数和一批数量\n\n> **[dbms_job](https://docs.oracle.com/cd/B28359_01/appdev.111/b28419/d_job.htm#BABHCBFD):**\n>\n> 用于管理job的package\n>\n> **oracle限定的job_queue_processes:**\n>\n> oracle中有一个对任务可启动进程的数量进行限制的参数：\n>\n> ```plsql\n> SQL> show parameter job_queue_processes;\n> NAME\t\t\t\t     TYPE\t VALUE\n> ----------------------------------------------------------\n> job_queue_processeses\t\t integer\t 10\n>\n> SQL> alter system set job_queue_processes=0...1000;\n> ```\n>\n> **使用ctrl+c是无法停止job的:**\n>\n> 可使用`top`命令查看当前进程详情，如果需要结束特定job可kill对应job的进程号\n\n```plsql\nCREATE OR REPLACE PROCEDURE analysis (job_count IN NUMBER, batch_size IN NUMBER)IS\n    --定义常量\n    c_record_index CONSTANT VARCHAR2(20)\t:='_RECORD_INDEX';\n\t  c_analysis_prefix CONSTANT VARCHAR2(20)\t:= '[ ANALYSIS ]';\n    --当前处理位置\n    v_record_index NUMBER;\n    --待处理的记录总数\n    v_record_count NUMBER;\n    --保存临时创建的job no\n    v_tmp_jobno NUMBER;\n    --开始结束时间\n    v_begin_time NUMBER;\n    v_process_end_time NUMBER;\n    v_analysis_end_time NUMBER;\n    --异常变量\n    e_invalid_input EXCEPTION;\nBEGIN\n    PRINT(c_analysis_prefix, ' start analysis...');\n    --输入参数检查\n    IF job_count < 1 OR batch_size<1 THEN\n        RAISE e_invalid_input;\n    END IF;\n    PRINT(c_analysis_prefix, ' checked input parameters.');\n    --记录开始时间\n    v_begin_time := dbms_utility.get_time;\n    --获取待处理的记录总数\n    SELECT COUNT(1) INTO v_record_count FROM t_records;\n    PRINT(c_analysis_prefix, ' records count: '||v_record_count);\n    --开始计算重置为0\n    UPDATE t_lock SET f_index=0 WHERE f_name=c_record_index;\n    COMMIT;\n    PRINT(c_analysis_prefix, ' reset index to zero.');\n    --提交多个job\n    FOR I IN 1.. job_count LOOP\n        dbms_job.submit(v_tmp_jobno,'begin process_data('||I||','||batch_size||'); end;');\n        PRINT(c_analysis_prefix, ' submitted new job, no: '||v_tmp_jobno);\n    END LOOP;\n    PRINT(c_analysis_prefix, ' created '||job_count||' jobs.');\n    --定时检查处理进度\n    LOOP\n        SELECT f_index INTO v_record_index FROM t_lock WHERE f_name = c_record_index;\n        PRINT(c_analysis_prefix, ' current index: '||v_record_index);\n        IF v_record_index = v_record_count THEN\n            PRINT(c_analysis_prefix, ' processed all records, exiting...');\n            EXIT;\n        ELSE\n            dbms_lock.sleep(5);--暂停等待5秒\n        END IF;\n    END LOOP;\n    v_process_end_time := dbms_utility.get_time;\n    PRINT(c_analysis_prefix, 'process, elapsed time: '||(v_process_end_time-v_begin_time)/100||' seconds.');\n    dbms_output.put_line('process, elapsed time: '||(v_process_end_time-v_begin_time)/100||' seconds.');\n    --分类汇总产生报表\n    generate_csv_report;\n    --结束时间\n    v_analysis_end_time := dbms_utility.get_time;\n    PRINT(c_analysis_prefix, 'report, elapsed time: '||(v_analysis_end_time-v_process_end_time)/100||' seconds.');\n    dbms_output.put_line('report, elapsed time: '||(v_analysis_end_time-v_process_end_time)/100||' seconds.');\n--异常捕获部分\nEXCEPTION\n    WHEN e_invalid_input THEN\n        dbms_output.put_line('Invalid input values, job_count:'||job_count||', batch_size:'||batch_size);\n    WHEN OTHERS THEN\n        dbms_output.put_line('Error code: '||SQLCODE);\n        dbms_output.put_line('Error mesg: '||sqlerrm);\nEND;\n/\n```\n\n- 存储过程mul_analysis，循环调用analysis，指定不同的任务个数和批数量，并将运行时间存入T_RESULT中\n\n```plsql\n-- 调用多次analysis，指定不同的job数和批数\ncreate or replace procedure mul_analysis is\n    -- 最小job数\n    v_begin_job_no NUMBER := 3;\n    -- 最大job数\n    v_end_job_no NUMBER := 8;\n    -- 每次增长的batch数量\n    v_range NUMBER := 2000;\n    -- 最小batch数量\n    v_begin_range NUMBER := 1000;\n    -- 最大batch数量\n    v_end_range NUMBER := 10000;\n    -- 当前range\n    range NUMBER;\n    begin\n        for I in v_begin_job_no..v_end_job_no LOOP\n            range := v_begin_range;\n            LOOP\n                -- 清洗表\n                init();\n                -- 分析\n                analysis(I, range);\n                range := range+v_range;\n\t\t\t\t-- range增长到10000则停止\n                if range > v_end_range then\n                    exit;\n                end if;\n            end loop;\n        end loop;\n    end;\n/\n```\n\n### 执行函数和存储过程\n\n> 在sqlplus中执行函数和存储过程之前需先打开serveroutput，即：\n>\n> ```plsql\n> SQL> set serveroutput on;\n> ```\n>\n> 这是因为存储过程中用到了`dbms_output.put_line`，上述语句是相当于告诉pl/sql引擎将`dbms_output.put_line`传递到缓冲区的内容输出到主控制台上。\n\n```\ncall init();\ncall analysis(4,1000);\n```\n\n\n\n## 结果分析\n\n通过执行`mul_analysis()`对一系列job和batch组合值进行测试，结果如下：\n\n![image-20181124205409162](/images/image-20181124205409162.png)\n\n\n# Lesson 2\n\n## 创建用户并分配权限\n\n### 创建用户\n\n```plsql\ncreate user audittest identified by audittest;\n```\n\n### 分配权限\n\n```plsql\ngrant connect,resource to audittest;\ngrant execute on dbms_lock to audittest;\nalter user audittest quota unlimited on users;\nconn audittest/audittest;\n```\n\n## 创建表及其他对象\n\n### 创建表\n\n> 注意：\n>\n> 这里在创建表时添加了`ENABLE`限制条件，oracle中对表和列的约束有`Enable`/`Disable`(启用/禁用)和`Validate`/`NoValidate`(验证/不验证)\n>\n> 举两个例子：\n>\n> **需更改的错误：**\n>\n> ```plsql\n> -- 创建表，对name字段添加唯一性约束\n> drop table T_TEST;\n> create table T_TEST(\n>   id int primary key ,\n>   name varchar2(10) constraint unique_name unique disable\n> );\n> -- 由于某些错误，添加的记录违反了唯一性约束，但添加不会报错\n> begin\n>   insert into T_TEST values (1, 'tan');\n>   insert into T_TEST values (2, 'rui');\n>   insert into T_TEST values (3, 'tan');\n> end;\n> select * from T_TEST;\n> -- 修改掉违反唯一性约束的值\n> update T_TEST set name='chen' where id=3;\n> -- 使得唯一性约束生效\n> alter table T_TEST modify constraint unique_name enable;\n> select * from T_TEST;\n>\n> ```\n>\n> **需保留的错误：**\n>\n> ```plsql\n> -- 创建表，无约束\n> drop table T_TEST;\n> create table T_TEST(\n>   id int primary key ,\n>   name varchar2(10)\n> );\n> -- 一些old的记录本身可能存在重复数据\n> begin\n>   insert into T_TEST values (1, 'tan');\n>   insert into T_TEST values (2, 'rui');\n>   insert into T_TEST values (3, 'tan');\n> end;\n> select * from T_TEST;\n> -- 对name列创建非唯一性索引\n> create index i_name on T_TEST(name);\n> -- 新要求需要对name添加唯一性约束unique_name，但保留旧值，注意这里一定要使用非唯一性索引\n> alter table T_TEST add constraint unique_name unique(name) using index i_name ENABLE NOVALIDATE ;\n> -- 此时无法插入name相同的数据了\n> insert into T_TEST values (4, 'tan');\n> ```\n\n```plsql\n--部门表\nCREATE TABLE \"AUDITTEST\".\"T_DEPARTMENT\"\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_CODE\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_PARENT_ID\" NUMBER(6,0),\n\t\"F_MANAGER\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_REMARK\" VARCHAR2(200 BYTE),\n\t CONSTRAINT \"T_DEPARTMENT_PK\" PRIMARY KEY (\"F_ID\")\n) ;\n\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_DEPARTMENT\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_DEPARTMENT\".\"F_NAME\" IS '部门名称';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_DEPARTMENT\".\"F_CODE\" IS '部门编号';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_DEPARTMENT\".\"F_PARENT_ID\" IS '上级部门ID';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_DEPARTMENT\".\"F_MANAGER\" IS '部门经理';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_DEPARTMENT\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON TABLE \"AUDITTEST\".\"T_DEPARTMENT\"  IS '部门表';\n\n--用户表\nCREATE TABLE \"AUDITTEST\".\"T_USER\"\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_DEPT_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_CODE\" VARCHAR2(20 BYTE),\n\t\"F_SEX\" VARCHAR2(5 BYTE) DEFAULT NULL,\n\t\"F_MOBILE\" VARCHAR2(20 BYTE),\n\t\"F_TELEPHONE\" VARCHAR2(20 BYTE),\n\t\"F_EMAIL\" VARCHAR2(50 BYTE),\n\t\"F_REMARK\" VARCHAR2(200 BYTE),\n\t CONSTRAINT \"T_USER_PK\" PRIMARY KEY (\"F_ID\")\n);\n\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_DEPT_ID\" IS '部门ID';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_NAME\" IS '用户名';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_CODE\" IS '员工编号';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_SEX\" IS '性别';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_MOBILE\" IS '手机';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_TELEPHONE\" IS '固话';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_EMAIL\" IS '邮箱';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_USER\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON TABLE \"AUDITTEST\".\"T_USER\"  IS '用户表';\n\n--客户信息表\nCREATE TABLE \"AUDITTEST\".\"T_CUSTOMER\"\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_CODE\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n\t\"F_FULL_NAME\" VARCHAR2(145 BYTE) NOT NULL ENABLE,\n\t\"F_LINKMAN\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n\t\"F_MOBILE\" VARCHAR2(11 BYTE) NOT NULL ENABLE,\n\t\"F_TELEPHONE\" VARCHAR2(20 BYTE),\n\t\"F_EMAIL\" VARCHAR2(60 BYTE),\n\t\"F_ADDRESS\" VARCHAR2(200 BYTE),\n\t\"F_CITY\" VARCHAR2(45 BYTE),\n\t\"F_BALANCE\" NUMBER(10,2) NOT NULL ENABLE,\n\t\"F_PARTNER\" VARCHAR2(45 BYTE),\n\t\"F_REMARK\" VARCHAR2(200 BYTE),\n\t\"F_SALESMAN\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n\t\"F_DELETED_TAG\" NUMBER(1,0) DEFAULT 0 NOT NULL ENABLE,\n\t\"F_CREATED_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_CREATED_TIME\" TIMESTAMP (6) NOT NULL ENABLE,\n\t\"F_MODIFIED_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_MODIFIED_TIME\" TIMESTAMP (6) NOT NULL ENABLE,\n\t\"F_VERSION\" NUMBER(6,0) DEFAULT 1 NOT NULL ENABLE,\n\t PRIMARY KEY (\"F_ID\")\n);\n\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_ID\" IS '主键';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_CODE\" IS '客户编码';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_FULL_NAME\" IS '客户全名';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_LINKMAN\" IS '联系人';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_MOBILE\" IS '联系手机';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_TELEPHONE\" IS '联系固话';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_EMAIL\" IS '联系邮箱';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_ADDRESS\" IS '地址';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_CITY\" IS '城市';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_BALANCE\" IS '余额';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_PARTNER\" IS '所属合作伙伴';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_SALESMAN\" IS '业务员';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_DELETED_TAG\" IS '删除标志，0：可用，1：已删除';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_CREATED_ID\" IS '创建人';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_CREATED_TIME\" IS '创建时间';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_MODIFIED_ID\" IS '最后修改人';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_MODIFIED_TIME\" IS '最后修改时间';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER\".\"F_VERSION\" IS '版本号';\nCOMMENT ON TABLE \"AUDITTEST\".\"T_CUSTOMER\"  IS '客户信息表';\n\n--\nCREATE TABLE \"AUDITTEST\".\"T_CUSTOMER_HISTORY\"\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_CODE\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n\t\"F_FULL_NAME\" VARCHAR2(145 BYTE) NOT NULL ENABLE,\n\t\"F_LINKMAN\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n\t\"F_MOBILE\" VARCHAR2(11 BYTE) NOT NULL ENABLE,\n\t\"F_TELEPHONE\" VARCHAR2(20 BYTE),\n\t\"F_EMAIL\" VARCHAR2(60 BYTE),\n\t\"F_ADDRESS\" VARCHAR2(200 BYTE),\n\t\"F_CITY\" VARCHAR2(45 BYTE),\n\t\"F_BALANCE\" NUMBER(10,2) NOT NULL ENABLE,\n\t\"F_PARTNER\" VARCHAR2(45 BYTE),\n\t\"F_REMARK\" VARCHAR2(200 BYTE),\n\t\"F_SALESMAN\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n\t\"F_DELETED_TAG\" NUMBER(1,0) DEFAULT 0 NOT NULL ENABLE,\n\t\"F_CREATED_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_CREATED_TIME\" TIMESTAMP (6) NOT NULL ENABLE,\n\t\"F_MODIFIED_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_MODIFIED_TIME\" TIMESTAMP (6) NOT NULL ENABLE,\n\t\"F_VERSION\" NUMBER(6,0) DEFAULT 1 NOT NULL ENABLE,\n\t CONSTRAINT \"T_CUSTOMER_HISTORY_PK\" PRIMARY KEY (\"F_ID\", \"F_VERSION\")\n);\n\n--客户信息历史表\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_ID\" IS '主键';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_CODE\" IS '客户编码';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_FULL_NAME\" IS '客户全名';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_LINKMAN\" IS '联系人';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_MOBILE\" IS '联系手机';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_TELEPHONE\" IS '联系固话';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_EMAIL\" IS '联系邮箱';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_ADDRESS\" IS '地址';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_CITY\" IS '城市';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_BALANCE\" IS '余额';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_PARTNER\" IS '所属合作伙伴';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_SALESMAN\" IS '业务员';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_DELETED_TAG\" IS '删除标志，0：可用，1：已删除';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_CREATED_ID\" IS '创建人';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_CREATED_TIME\" IS '创建时间';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_MODIFIED_ID\" IS '最后修改人';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_MODIFIED_TIME\" IS '最后修改时间';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_CUSTOMER_HISTORY\".\"F_VERSION\" IS '版本号';\nCOMMENT ON TABLE \"AUDITTEST\".\"T_CUSTOMER_HISTORY\"  IS '客户信息历史表';\n\n--审计表\nCREATE TABLE \"AUDITTEST\".\"T_AUDIT\"\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_TABLE_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_ROW_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_NEW_VERSION\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_COLUMN_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_OLD_VALUE\" VARCHAR2(200 BYTE),\n\t\"F_NEW_VALUE\" VARCHAR2(200 BYTE),\n\t\"F_OPERATOR_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_OPERATION_TIME\" TIMESTAMP (6) NOT NULL ENABLE,\n\t CONSTRAINT \"T_AUDIT_PK\" PRIMARY KEY (\"F_ID\")\n);\n\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_ID\" IS '主键';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_TABLE_NAME\" IS '表名';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_ROW_ID\" IS '业务数据主键';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_NEW_VERSION\" IS '新的版本号';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_COLUMN_NAME\" IS '字段';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_OLD_VALUE\" IS '原值';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_NEW_VALUE\" IS '新值';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_OPERATOR_ID\" IS '操作用户';\nCOMMENT ON COLUMN \"AUDITTEST\".\"T_AUDIT\".\"F_OPERATION_TIME\" IS '操作时间';\nCOMMENT ON TABLE \"AUDITTEST\".\"T_AUDIT\"  IS '审计表';\n```\n\n### 创建索引、序列\n\n```plsql\n-- 创建复合索引\nCREATE INDEX \"AUDITTEST\".\"IDX_TABLE_ROWID\" ON \"AUDITTEST\".\"T_AUDIT\" (\"F_TABLE_NAME\", \"F_ROW_ID\") ;\n-- 创建序列\nCREATE SEQUENCE  SEQ_AUDIT_PK  INCREMENT BY 1 START WITH 1;\n```\n\n### 创建触发器\n\n```plsql\n--创建触发器\ncreate or replace trigger trg_customer_audit\nbefore update on t_customer\nfor each row\ndeclare\n    c_insert_sql constant varchar2(100) := 'insert into t_audit values(:1,:2,:3,:4,:5,:6,:7,:8,systimestamp)';\n    c_table_name constant varchar2(20)  := 'T_CUSTOMER';\n    v_column_name varchar2(20);\nbegin\n    --记录当前数据到历史表\n    insert into t_customer_history values(:old.f_id,:old.f_code,:old.f_full_name,:old.f_linkman,:old.f_mobile,:old.f_telephone,:old.f_email,:old.f_address,:old.f_city,:old.f_balance,:old.f_partner,:old.f_remark,:old.f_salesman,:old.f_deleted_tag,:old.f_created_id,:old.f_created_time,:old.f_modified_id,:old.f_modified_time,:old.f_version);\n\n    --递增记录的版本号\n    :new.f_version := :old.f_version+1;\n\n    --判断字段变化\n    if updating('F_LINKMAN') then\n        v_column_name := '联系人';\n        execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_linkman,:new.f_linkman,:new.f_modified_id;\n    end if;\n\n    if updating('F_MOBILE') then\n        v_column_name := '手机号码';\n        execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_mobile,:new.f_mobile,:new.f_modified_id;\n    end if;\n\n    if updating('F_TELEPHONE') then\n        v_column_name := '固定电话';\n        execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_telephone,:new.f_telephone,:new.f_modified_id;\n    end if;\n\n    if updating('F_EMAIL') then\n        v_column_name := '电子邮箱';\n        execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_email,:new.f_email,:new.f_modified_id;\n    end if;\n\n    if updating('F_ADDRESS') then\n        v_column_name := '联系地址';\n        execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_address,:new.f_address,:new.f_modified_id;\n    end if;\n\n    if updating('F_BALANCE') then\n        v_column_name := '余额';\n        execute immediate c_insert_sql using seq_audit_pk.nextval,c_table_name,:new.f_id,:old.f_version,v_column_name,:old.f_balance,:new.f_balance,:new.f_modified_id;\n    end if;\nend;\n/\n\n--创建过程\n--过程：重设序列值\ncreate or replace PROCEDURE reset_seq( seq_name IN VARCHAR2 )\nIS\n    v_val NUMBER;\nBEGIN\n    EXECUTE IMMEDIATE 'SELECT ' || seq_name || '.NEXTVAL FROM dual' INTO v_val;\n\n    EXECUTE IMMEDIATE 'ALTER SEQUENCE ' || seq_name || ' INCREMENT BY -' || v_val ||' MINVALUE 0';\n\n    EXECUTE IMMEDIATE 'SELECT ' || seq_name || '.NEXTVAL FROM dual' INTO v_val;\n\n    EXECUTE IMMEDIATE 'ALTER SEQUENCE ' || seq_name || ' INCREMENT BY 1 MINVALUE 0';\nend;\n/\n```\n\n### 创建过程\n\n#### 过程reset_seq\n\n> 将序列为输入参数seq_name的值重置\n\n```plsql\n--过程：重设序列值\ncreate or replace PROCEDURE reset_seq( seq_name IN VARCHAR2 )\nIS\n    v_val NUMBER;\nBEGIN\n    EXECUTE IMMEDIATE 'SELECT ' || seq_name || '.NEXTVAL FROM dual' INTO v_val;\n\n    EXECUTE IMMEDIATE 'ALTER SEQUENCE ' || seq_name || ' INCREMENT BY -' || v_val ||' MINVALUE 0';\n\n    EXECUTE IMMEDIATE 'SELECT ' || seq_name || '.NEXTVAL FROM dual' INTO v_val;\n\n    EXECUTE IMMEDIATE 'ALTER SEQUENCE ' || seq_name || ' INCREMENT BY 1 MINVALUE 0';\nend;\n/\n```\n\n#### 过程init\n\n> truncate(截断)所有表，重设序列，并添加初始值\n>\n> 注意：\n>\n> **`truncate`与`delete`的区别**：delete通常用于删除表中的某些行或者所有行，且delete支持回滚，删除掉的记录的物理空间在commit前并不会被回收。truncate只能删除表的所有行且不支持回滚，删除掉的记录的物理空间也会被立刻回收。\n>\n> truncate的好处在于当需要删除所有行它比delete要快，尤其在包含大量触发器、索引和其他依赖项的情况下；且它不会改变表结构、表依赖等关系，这一特性又使得它比重建表更有效，删除和重建表会使得表的依赖关系断开，因此需要重新创建依赖、创建约束、赋予权限等等操作。\n>\n> 但是truncate也有不好的地方，比如说当被truncate的表被依赖时，举例：\n>\n> ```plsql\n> -- 创建表，f_id字段引用T_TEST的主码id\n> drop table T_TEST2;\n> create table T_TEST2(\n>   id1 int primary key ,\n>   f_id int,\n>   constraint fk\n>   foreign key (f_id)\n>     references T_TEST(id) on delete cascade\n> );\n> select *\n> from T_TEST2;\n> insert into T_TEST2 values(1, 1);\n> -- 可级联删除\n> delete from T_TEST;\n> -- 将外码置为禁用\n> alter table T_TEST2 modify constraint fk disable validate ;\n> -- 可截断（当不禁用外码时无法截断）\n> truncate table T_TEST;\n> ```\n>\n> 可见，可通过禁用约束来完成truncate，但是这些主外键约束应是创建数据库时的我们定义的强制关系，上述方法可能会使得这种强制关系紊乱，因此需做好取舍决策。\n\n```plsql\n--过程：数据初始化\ncreate or replace procedure init is\nbegin\n    --清除数据\n    execute immediate 'truncate table t_audit';\n    execute immediate 'truncate table t_customer_history';\n    execute immediate 'truncate table t_customer';\n    execute immediate 'truncate table t_user';\n    execute immediate 'truncate table t_department';\n    --重调序列\n    reset_seq('seq_audit_pk');\n\n    --插入部门\n    insert into t_department values(1,'销售部','D01',NULL,'李明','备注1...');\n    insert into t_department values(2,'销售部-北京分部','D0101',1,'赵军','备注2...');\n    insert into t_department values(3,'销售部-上海分部','D0102',1,'张华','备注3...');\n    insert into t_department values(4,'销售部-深圳分部','D0103',1,'王兵','备注4...');\n\n    --插入用户\n    insert into t_user values(1,1,'仲芳芳','U8201','女','13771234101','02131231011','use1@samtech.com','备注1...');\n    insert into t_user values(2,1,'李明申','U8202','男','13771234102','02131231012','use2@samtech.com','备注2...');\n    insert into t_user values(3,2,'张雪', 'U8203','女','13771234103','02131231013','use3@samtech.com','备注3...');\n    insert into t_user values(4,2,'王刚', 'U8204','男','13771234104','02131231014','use4@samtech.com','备注4...');\n    insert into t_user values(5,3,'赵昌日','U8205','男','13771234105','02131231015','use5@samtech.com','备注5...');\n    insert into t_user values(6,3,'孙晓华','U8206','男','13771234106','02131231016','use6@samtech.com','备注6...');\n    insert into t_user values(7,4,'陈亚男','U8207','女','13771234107','02131231017','use7@samtech.com','备注7...');\n    insert into t_user values(8,4,'刘兵超','U8208','男','13771234108','02131231018','use8@samtech.com','备注8...');\n\n    --插入客户\n    insert into t_customer\n    values(1,'C1808001','上海市永辉电子股份有限公司','张明升','15352678121','02135681589','ming@google.com','上海市静安区城区安泰路1108号','上海市',12082,'上海中远','备注...','张娜',0,1,sysdate,1,sysdate,1);\n    commit;\nend;\n/\n```\n\n#### 修改客户信息过程\n\n```plsql\n--过程：修改客户地址\ncreate or replace procedure modify_address\n(p_row_id in number,p_address in varchar2, p_operator in number)\nas\nbegin\n    --校验参数省略\n    --...\n    execute immediate 'update t_customer set f_address=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3'\n    using p_address,p_operator,p_row_id;\n    commit;\n    dbms_output.put_line('Updated address successfully.');\n\n    --异常捕获省略\n    --...\nend;\n/\n\n--过程：修改客户余额\ncreate or replace procedure modify_balance\n(p_row_id in number,p_balance in number, p_operator in number)\nas\nbegin\n    --校验参数省略\n    --...\n    execute immediate 'update t_customer set f_balance=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3'\n    using p_balance,p_operator,p_row_id;\n    commit;\n    dbms_output.put_line('Updated balance successfully.');\n\n    --异常捕获省略\n    --...\nend;\n/\n\n--过程：修改客户电子邮箱\ncreate or replace procedure modify_email\n(p_row_id in number,p_email in varchar2, p_operator in number)\nas\nbegin\n    --校验参数省略\n    --...\n    execute immediate 'update t_customer set f_email=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3'\n    using p_email,p_operator,p_row_id;\n    commit;\n    dbms_output.put_line('Updated email successfully.');\n\n    --异常捕获省略\n    --...\nend;\n/\n\n--过程：修改客户联系人\ncreate or replace procedure modify_linkman\n(p_row_id in number,p_linkman_name in varchar2, p_operator in number)\nas\nbegin\n    --校验参数省略\n    --...\n    execute immediate 'update t_customer set f_linkman=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3'\n    using p_linkman_name,p_operator,p_row_id;\n    commit;\n    dbms_output.put_line('Updated linkman name successfully.');\n\n    --异常捕获省略\n    --...\nend;\n/\n\n--过程：修改客户联系人信息\ncreate or replace procedure modify_linkman_info\n(p_row_id in number,p_linkman_name in varchar2,p_mobile in varchar2,\n p_telephone in varchar2,p_email in varchar2,p_operator in number)\nas\nbegin\n    --校验参数省略\n    --...\n    execute immediate 'update t_customer set f_linkman=:1, f_mobile=:2,\n    f_telephone=:3, f_email=:4, f_modified_id=:5, f_modified_time=sysdate where f_id=:6'\n    using p_linkman_name,p_mobile,p_telephone,p_email,p_operator,p_row_id;\n    commit;\n    dbms_output.put_line('Updated linkman info successfully.');\n\n    --异常捕获省略\n    --...\nend;\n/\n\n--过程：修改联系手机\ncreate or replace procedure modify_mobile\n(p_row_id in number,p_mobile in varchar2,p_operator in number)\nas\nbegin\n    --校验参数省略\n    --...\n    execute immediate 'update t_customer set f_mobile=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3'\n    using p_mobile,p_operator,p_row_id;\n    commit;\n    dbms_output.put_line('Updated mobile successfully.');\n\n    --异常捕获省略\n    --...\nend;\n/\n\n--过程：修改联系固话\ncreate or replace procedure modify_telephone\n(p_row_id in number,p_telephone in varchar2,p_operator in number)\nas\nbegin\n    --校验参数省略\n    --...\n    execute immediate 'update t_customer set f_telephone=:1,f_modified_id=:2, f_modified_time=sysdate where f_id=:3'\n    using p_telephone,p_operator,p_row_id;\n    commit;\n    dbms_output.put_line('Updated mobile successfully.');\n\n    --异常捕获省略\n    --...\nend;\n/\n```\n\n### 执行\n\n```plsql\n-- 初始化\ncall init();\n\n-- 更改客户信息\nbegin\n\tmodify_linkman(1,'李明顺',1);\n\tdbms_lock.sleep(1);\n\tmodify_mobile(1,'13771083211',2);\n\tdbms_lock.sleep(1);\n\tmodify_balance(1,20020,3);\n\tdbms_lock.sleep(1);\n\tmodify_address(1,'中国上海市嘉定区xxx路',4);\n\tdbms_lock.sleep(1);\n\tmodify_email(1,'test1@163.com',5);\n\tdbms_lock.sleep(1);\n\tmodify_telephone(1,'02183652145',6);\n\tdbms_lock.sleep(1);\n\tmodify_linkman_info(1,'张雨轩','15332892301','02188881111','zhangyx@gmail.com',7);\nend;\n/\n\n-- 审计\nselect * from T_AUDIT;\n\n-- 回滚客户信息\n-- 方法1：\nupdate t_customer a\nset(\na.f_full_name,a.f_linkman,a.f_mobile,a.f_telephone,a.f_email,a.f_address,\na.f_city,a.f_balance,a.f_partner,a.f_remark,a.f_salesman,a.f_deleted_tag,\na.f_modified_id,a.f_modified_time\n)\n=\n(\nselect b.f_full_name,b.f_linkman,b.f_mobile,b.f_telephone,b.f_email,\nb.f_address,b.f_city,b.f_balance,b.f_partner,b.f_remark,b.f_salesman,\nb.f_deleted_tag,5,sysdate\nfrom t_customer_history b where b.f_id=a.f_id and b.f_version=3\n)\nwhere a.f_id=1;\n-- 方法2：\nmerge into t_customer a using t_customer_history b on (a.f_id=1 and a.f_id=b.f_id and b.f_version=3)\nwhen matched then\nupdate set a.f_full_name=b.f_full_name,a.f_linkman=b.f_linkman,a.f_mobile=b.f_mobile,a.f_telephone=b.f_telephone,\na.f_email=b.f_email,a.f_address=b.f_address,a.f_city=b.f_city,a.f_balance=b.f_balance,a.f_partner=b.f_partner,\na.f_remark=b.f_remark,a.f_salesman=b.f_salesman,a.f_deleted_tag=b.f_deleted_tag,a.f_modified_id=5,a.f_modified_time=sysdate;\n\n-- 查看验证数据\nselect * from t_customer where f_id=1\nunion\nselect * from t_customer_history where f_id=1 and f_version=3;\n```\n\n# Lesson 3\n\n## 创建用户并分配权限\n\n### 创建用户\n\n```plsql\ncreate user permission identified by permission;\n```\n\n### 分配权限\n\n```plsql\ngrant connect,resource to permission;\nalter user permisson quota unlimited on users;\nconn permission/permission;\n```\n\n## 创建表及其他对象\n\n### 方案一\n\n> 方案一在T_CUSTOMER表中存放创建人员ID，以查询该客户的直接负责人，在T_USER表中存放直属领导的ID，用于查询某领导所有下属的客户。\n\n#### 创建表\n\n```plsql\n\n--方案一\n--部门表\nCREATE TABLE T_DEPARTMENT\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_PARENT_ID\" NUMBER(6,0),\n\t\"F_MANAGER_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_REMARK\" VARCHAR2(200 BYTE),\n\t CONSTRAINT \"T_DEPARTMENT_PK\" PRIMARY KEY (\"F_ID\")\n) ;\n\nCOMMENT ON COLUMN \"T_DEPARTMENT\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"T_DEPARTMENT\".\"F_NAME\" IS '部门名称';\nCOMMENT ON COLUMN \"T_DEPARTMENT\".\"F_PARENT_ID\" IS '上级部门ID';\nCOMMENT ON COLUMN \"T_DEPARTMENT\".\"F_MANAGER_ID\" IS '部门经理';\nCOMMENT ON COLUMN \"T_DEPARTMENT\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON TABLE \"T_DEPARTMENT\"  IS '部门表';\n\n--用户表\nCREATE TABLE \"T_USER\"\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_DEPT_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n\t\"F_SEX\" VARCHAR2(5 BYTE) DEFAULT NULL,\n\t\"F_MOBILE\" VARCHAR2(20 BYTE),\n\t\"F_EMAIL\" VARCHAR2(50 BYTE),\n\t\"F_REMARK\" VARCHAR2(200 BYTE),\n\t CONSTRAINT \"T_USER_PK\" PRIMARY KEY (\"F_ID\")\n);\n\nCOMMENT ON COLUMN \"T_USER\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"T_USER\".\"F_DEPT_ID\" IS '部门ID';\nCOMMENT ON COLUMN \"T_USER\".\"F_NAME\" IS '用户名';\nCOMMENT ON COLUMN \"T_USER\".\"F_SEX\" IS '性别';\nCOMMENT ON COLUMN \"T_USER\".\"F_MOBILE\" IS '手机';\nCOMMENT ON COLUMN \"T_USER\".\"F_EMAIL\" IS '邮箱';\nCOMMENT ON COLUMN \"T_USER\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON TABLE \"T_USER\"  IS '用户表';\n\n--客户信息表\nCREATE TABLE \"T_CUSTOMER\"\n(\t\"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_NAME\" VARCHAR2(145 BYTE) NOT NULL ENABLE,\n\t\"F_LINKMAN\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n\t\"F_MOBILE\" VARCHAR2(11 BYTE) NOT NULL ENABLE,\n\t\"F_EMAIL\" VARCHAR2(60 BYTE),\n\t\"F_ADDRESS\" VARCHAR2(200 BYTE),\n\t\"F_REMARK\" VARCHAR2(200 BYTE),\n\t\"F_CREATED_ID\" NUMBER(6,0) NOT NULL ENABLE,\n\t\"F_CREATED_TIME\" TIMESTAMP (6) NOT NULL ENABLE,\n\t PRIMARY KEY (\"F_ID\")\n);\n\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_NAME\" IS '客户全名';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_LINKMAN\" IS '联系人';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_MOBILE\" IS '联系手机';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_EMAIL\" IS '联系邮箱';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_ADDRESS\" IS '地址';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_CREATED_ID\" IS '创建人';\nCOMMENT ON COLUMN \"T_CUSTOMER\".\"F_CREATED_TIME\" IS '创建时间';\nCOMMENT ON TABLE \"T_CUSTOMER\"  IS '客户信息表';\n```\n\n#### 创建过程\n\n##### 初始化\n\n```plsql\n--过程：数据初始化\nCREATE OR REPLACE PROCEDURE INIT IS\nBEGIN\n    --清除数据\n    EXECUTE IMMEDIATE 'TRUNCATE TABLE T_CUSTOMER';\n    EXECUTE IMMEDIATE 'TRUNCATE TABLE T_USER';\n    EXECUTE IMMEDIATE 'TRUNCATE TABLE T_DEPARTMENT';\n\n    --插入部门\n    INSERT INTO T_DEPARTMENT VALUES(1,'公司',NULL,1,'REMARK...');\n    INSERT INTO T_DEPARTMENT VALUES(2,'行政部',1,1,'REMARK...');\n    INSERT INTO T_DEPARTMENT VALUES(3,'销售部',1,2,'REMARK...');\n    INSERT INTO T_DEPARTMENT VALUES(4,'电销组',3,3,'销售部电销组');\n    INSERT INTO T_DEPARTMENT VALUES(5,'推销组',3,6,'销售部推销组');\n\n    --插入用户\n    INSERT INTO T_USER VALUES(1,1,'管理员','男','13771234101','USE1@SAMTECH.COM','系统管理员');\n    INSERT INTO T_USER VALUES(2,3,'李明申','男','13771234102','USE2@SAMTECH.COM','销售部经理');\n    INSERT INTO T_USER VALUES(3,4,'张雪', '女','13771234103','USE3@SAMTECH.COM','销售部电销组主管');\n    INSERT INTO T_USER VALUES(4,4,'王刚', '男','13771234104','USE4@SAMTECH.COM','销售部电销组业务员1');\n    INSERT INTO T_USER VALUES(5,4,'赵昌日','男','13771234105','USE5@SAMTECH.COM','销售部电销组业务员2');\n    INSERT INTO T_USER VALUES(6,5,'孙晓华','男','13771234106','USE6@SAMTECH.COM','销售部推销组主管');\n    INSERT INTO T_USER VALUES(7,5,'陈亚男','女','13771234107','USE7@SAMTECH.COM','销售部推销组业务员3');\n    INSERT INTO T_USER VALUES(8,5,'刘兵超','男','13771234108','USE8@SAMTECH.COM','销售部推销组业务员4');\n    INSERT INTO T_USER VALUES(9,3,'陈彬','女','13771234109','USE9@SAMTECH.COM','销售部业务员X1');\n    INSERT INTO T_USER VALUES(10,3,'王军','男','13771234110','USE10@SAMTECH.COM','销售部业务员X2');\n\n    --插入客户\n    INSERT INTO T_CUSTOMER VALUES(1,'上海市永辉电子股份有限公司'     ,'张明升','15352678121','MING1@GOOGLE.COM','上海市静安区城区安泰路1108号','电销组主管创建',3,SYSDATE);\n    INSERT INTO T_CUSTOMER VALUES(2,'上海博运汽车销售有限公司'      ,'朱荣荣' ,'13231289212','MING2@GOOGLE.COM','上海市徐汇区钦江路256号','电销组业务员1创建',4,SYSDATE);\n    INSERT INTO T_CUSTOMER VALUES(3,'安徽广宏顶管装备制造有限公司'   ,'邱阳阳' ,'15328921231','MING3@GOOGLE.COM','安徽省广德县经济开发区东纬路5号','电销组业务员2创建',5,SYSDATE);\n    INSERT INTO T_CUSTOMER VALUES(4,'上海定丰霖贸易有限公司'        ,'赵兰'  ,'15532212322','MING4@GOOGLE.COM','上海市浦东新区东延路112号408室','推销组主管创建',6,SYSDATE);\n    INSERT INTO T_CUSTOMER VALUES(5,'上海东俊科技有限公司'          ,'张军'  ,'15367823660','MING5@GOOGLE.COM','上海市长宁区王安路135号','推销组业务员1创建',7,SYSDATE);\n    INSERT INTO T_CUSTOMER VALUES(6,'中科创客（深圳）智能工业设备公司','李明'  ,'17723180234','MING6@GOOGLE.COM','深圳市龙岗区富民工业园致康路301号','推销组业务员2创建',8,SYSDATE);\n    INSERT INTO T_CUSTOMER VALUES(7,'南宁云讯科技有限公司'          ,'王永成','13568932166','MING7@GOOGLE.COM','广东省深圳市福田区长川路102号','销售部业务员X1创建',9,SYSDATE);\n    INSERT INTO T_CUSTOMER VALUES(8,'沈阳优速家政服务有限公司'       ,'李东升','13392312343','MING8@GOOGLE.COM','辽宁省沈阳市铁西区北二路青年易居东门32号','销售部业务员X2创建',10,SYSDATE);\n    COMMIT;\nEND;\n/\n```\n\n#### 执行\n\n##### 初始化\n\n```\nset serveroutput on;\nexec init;\n```\n\n##### 查询自己的客户\n\n```plsql\nSELECT * FROM t_customer A WHERE A.f_created_id=&id;\n```\n\n> `&id`是所查询人员的ID\n\n##### 查询某领导下属人员的所有客户\n\n```plsql\nselect * from t_user a  where exists(\nSELECT 1 FROM t_department b\nWHERE a.f_dept_id=b.f_id and b.f_manager_id=&id\nCONNECT BY b.F_PARENT_ID = PRIOR b.F_ID\nstart with b.F_ID = (select c.f_dept_id from t_user c where c.f_id=&id));\n```\n\n> `&id`是该领导的ID\n\n#### 当部门结构或员工归属调整时，权限编码如何处理？\n\n对于方案一，只需要更改员工直属领导ID即可\n\n### 方案二\n\n> 方案二取消在T_USER中添加直属领导ID，改为在员工、部门、客户表中添加权限码，查看时直接搜索对应权限码即可\n\n#### 创建表\n\n```plsql\n--方案二\n--部门表\nCREATE TABLE T_DEPARTMENT_2\n(  \"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n \"F_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n    \"F_CODE\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n \"F_PARENT_ID\" NUMBER(6,0),\n \"F_MANAGER_ID\" NUMBER(6,0) NOT NULL ENABLE,\n \"F_REMARK\" VARCHAR2(200 BYTE),\n  CONSTRAINT \"T_DEPARTMENT_PK2\" PRIMARY KEY (\"F_ID\")\n) ;\n\nCOMMENT ON COLUMN \"T_DEPARTMENT_2\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"T_DEPARTMENT_2\".\"F_NAME\" IS '部门名称';\nCOMMENT ON COLUMN \"T_DEPARTMENT_2\".\"F_CODE\" IS '部门编码';\nCOMMENT ON COLUMN \"T_DEPARTMENT_2\".\"F_PARENT_ID\" IS '上级部门ID';\nCOMMENT ON COLUMN \"T_DEPARTMENT_2\".\"F_MANAGER_ID\" IS '部门经理';\nCOMMENT ON COLUMN \"T_DEPARTMENT_2\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON TABLE \"T_DEPARTMENT_2\"  IS '部门表2';\n\n--用户表\nCREATE TABLE \"T_USER_2\"\n(  \"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n \"F_DEPT_ID\" NUMBER(6,0) NOT NULL ENABLE,\n \"F_NAME\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n    \"F_CODE\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n \"F_SEX\" VARCHAR2(5 BYTE) DEFAULT NULL,\n \"F_MOBILE\" VARCHAR2(20 BYTE),\n \"F_EMAIL\" VARCHAR2(50 BYTE),\n \"F_REMARK\" VARCHAR2(200 BYTE),\n  CONSTRAINT \"T_USER_PK2\" PRIMARY KEY (\"F_ID\")\n);\n\nCOMMENT ON COLUMN \"T_USER_2\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"T_USER_2\".\"F_DEPT_ID\" IS '部门ID';\nCOMMENT ON COLUMN \"T_USER_2\".\"F_NAME\" IS '用户名';\nCOMMENT ON COLUMN \"T_USER_2\".\"F_CODE\" IS '用户编码';\nCOMMENT ON COLUMN \"T_USER_2\".\"F_SEX\" IS '性别';\nCOMMENT ON COLUMN \"T_USER_2\".\"F_MOBILE\" IS '手机';\nCOMMENT ON COLUMN \"T_USER_2\".\"F_EMAIL\" IS '邮箱';\nCOMMENT ON COLUMN \"T_USER_2\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON TABLE \"T_USER_2\"  IS '用户表2';\n\n--客户信息表\nCREATE TABLE \"T_CUSTOMER_2\"\n(  \"F_ID\" NUMBER(6,0) NOT NULL ENABLE,\n \"F_NAME\" VARCHAR2(145 BYTE) NOT NULL ENABLE,\n \"F_LINKMAN\" VARCHAR2(45 BYTE) NOT NULL ENABLE,\n \"F_MOBILE\" VARCHAR2(11 BYTE) NOT NULL ENABLE,\n \"F_EMAIL\" VARCHAR2(60 BYTE),\n \"F_ADDRESS\" VARCHAR2(200 BYTE),\n \"F_REMARK\" VARCHAR2(200 BYTE),\n    \"F_ACCESS_CODE\" VARCHAR2(50 BYTE) NOT NULL ENABLE,\n \"F_CREATED_ID\" NUMBER(6,0) NOT NULL ENABLE,\n \"F_CREATED_TIME\" TIMESTAMP (6) NOT NULL ENABLE,\n  PRIMARY KEY (\"F_ID\")\n);\n\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_ID\" IS 'PK';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_NAME\" IS '客户全名';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_LINKMAN\" IS '联系人';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_MOBILE\" IS '联系手机';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_EMAIL\" IS '联系邮箱';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_ADDRESS\" IS '地址';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_REMARK\" IS '备注信息';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_ACCESS_CODE\" IS '权限编码';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_CREATED_ID\" IS '创建人';\nCOMMENT ON COLUMN \"T_CUSTOMER_2\".\"F_CREATED_TIME\" IS '创建时间';\nCOMMENT ON TABLE \"T_CUSTOMER_2\"  IS '客户信息表2';\n\n-- 创建人员更改历史表\nCREATE TABLE T_USER_HISTORY(\n  ID NUMBER(6,0) PRIMARY KEY ,\n  F_ID NUMBER(6,0) ,\n  O_DEP_ID NUMBER(6,0) ,\n  O_ACCESS_CODE VARCHAR2(50 BYTE) ,\n  N_DEP_ID  NUMBER(6,0),\n  N_ACCESS_CODE VARCHAR2(50 BYTE),\n  TIME DATE\n);\n\nCOMMENT ON COLUMN T_USER_HISTORY.ID IS 'PK';\nCOMMENT ON COLUMN T_USER_HISTORY.F_ID IS '修改的人员ID';\nCOMMENT ON COLUMN T_USER_HISTORY.O_DEP_ID IS '旧的部门';\nCOMMENT ON COLUMN T_USER_HISTORY.O_ACCESS_CODE IS '旧的权限';\nCOMMENT ON COLUMN T_USER_HISTORY.N_DEP_ID IS '新的部门';\nCOMMENT ON COLUMN T_USER_HISTORY.N_ACCESS_CODE IS '新的权限';\nCOMMENT ON TABLE T_USER_HISTORY IS '用户权限更改历史';\n```\n\n#### 创建过程\n\n##### 初始化\n\n```plsql\n--过程：数据初始化\nCREATE OR REPLACE PROCEDURE INIT2 IS\nBEGIN\n    --清除数据\n    EXECUTE IMMEDIATE 'TRUNCATE TABLE T_CUSTOMER_2';\n    EXECUTE IMMEDIATE 'TRUNCATE TABLE T_USER_2';\n    EXECUTE IMMEDIATE 'TRUNCATE TABLE T_DEPARTMENT_2';\n    EXECUTE IMMEDIATE 'TRUNCATE TABLE T_USER_HISTORY';\n\n    --插入部门\n    INSERT INTO T_DEPARTMENT_2 VALUES(1,'公司','1',NULL,1,'REMARK...');\n    INSERT INTO T_DEPARTMENT_2 VALUES(2,'行政部','101',1,1,'REMARK...');\n    INSERT INTO T_DEPARTMENT_2 VALUES(3,'销售部','102',1,2,'REMARK...');\n    INSERT INTO T_DEPARTMENT_2 VALUES(4,'电销组','10201',3,3,'销售部电销组');\n    INSERT INTO T_DEPARTMENT_2 VALUES(5,'推销组','10202',3,6,'销售部推销组');\n\n    --插入用户\n    INSERT INTO T_USER_2 VALUES(1,1,'管理员','1','男','13771234101','USE1@SAMTECH.COM','系统管理员');\n    INSERT INTO T_USER_2 VALUES(2,3,'李明申','102','男','13771234102','USE2@SAMTECH.COM','销售部经理');\n    INSERT INTO T_USER_2 VALUES(3,4,'张雪',  '10201', '女','13771234103','USE3@SAMTECH.COM','销售部电销组主管');\n    INSERT INTO T_USER_2 VALUES(4,4,'王刚',  '1020101', '男','13771234104','USE4@SAMTECH.COM','销售部电销组业务员1');\n    INSERT INTO T_USER_2 VALUES(5,4,'赵昌日','1020102','男','13771234105','USE5@SAMTECH.COM','销售部电销组业务员2');\n    INSERT INTO T_USER_2 VALUES(6,5,'孙晓华','10202','男','13771234106','USE6@SAMTECH.COM','销售部推销组主管');\n    INSERT INTO T_USER_2 VALUES(7,5,'陈亚男','1020201','女','13771234107','USE7@SAMTECH.COM','销售部推销组业务员3');\n    INSERT INTO T_USER_2 VALUES(8,5,'刘兵超','1020202','男','13771234108','USE8@SAMTECH.COM','销售部推销组业务员4');\n    INSERT INTO T_USER_2 VALUES(9,3,'陈彬',  '10203','女','13771234109','USE9@SAMTECH.COM','销售部业务员X1');\n    INSERT INTO T_USER_2 VALUES(10,3,'王军', '10204','男','13771234110','USE10@SAMTECH.COM','销售部业务员X2');\n\n    --插入客户\n    INSERT INTO T_CUSTOMER_2 VALUES(1,'上海市永辉电子股份有限公司'     ,'张明升','15352678121','MING1@GOOGLE.COM','上海市静安区城区安泰路1108号','电销组主管创建','10201',3,SYSDATE);\n    INSERT INTO T_CUSTOMER_2 VALUES(2,'上海博运汽车销售有限公司'      ,'朱荣荣' ,'13231289212','MING2@GOOGLE.COM','上海市徐汇区钦江路256号','电销组业务员1创建','1020101',4,SYSDATE);\n    INSERT INTO T_CUSTOMER_2 VALUES(3,'安徽广宏顶管装备制造有限公司'   ,'邱阳阳' ,'15328921231','MING3@GOOGLE.COM','安徽省广德县经济开发区东纬路5号','电销组业务员2创建','1020102',5,SYSDATE);\n    INSERT INTO T_CUSTOMER_2 VALUES(4,'上海定丰霖贸易有限公司'        ,'赵兰'  ,'15532212322','MING4@GOOGLE.COM','上海市浦东新区东延路112号408室','推销组主管创建','10202',6,SYSDATE);\n    INSERT INTO T_CUSTOMER_2 VALUES(5,'上海东俊科技有限公司'          ,'张军'  ,'15367823660','MING5@GOOGLE.COM','上海市长宁区王安路135号','推销组业务员1创建','1020201',7,SYSDATE);\n    INSERT INTO T_CUSTOMER_2 VALUES(6,'中科创客（深圳）智能工业设备公司','李明'  ,'17723180234','MING6@GOOGLE.COM','深圳市龙岗区富民工业园致康路301号','推销组业务员2创建','1020202',8,SYSDATE);\n    INSERT INTO T_CUSTOMER_2 VALUES(7,'南宁云讯科技有限公司'          ,'王永成','13568932166','MING7@GOOGLE.COM','广东省深圳市福田区长川路102号','销售部业务员X1创建','10203',9,SYSDATE);\n    INSERT INTO T_CUSTOMER_2 VALUES(8,'沈阳优速家政服务有限公司'       ,'李东升','13392312343','MING8@GOOGLE.COM','辽宁省沈阳市铁西区北二路青年易居东门32号','销售部业务员X2创建','10204',10,SYSDATE);\n    COMMIT;\nEND;\n/\n```\n\n##### 将某员工调换到某部门\n\n![image-20181126025537963](/images/image-20181126025537963.png)\n\n```plsql\n-- 更改用户到特定部门\nCREATE OR REPLACE PROCEDURE CHANGE_TO_DEPARTMENT(C_F_ID IN T_USER_2.F_ID%TYPE, N_DEP_ID IN T_DEPARTMENT_2.F_ID%TYPE) IS\n  -- 旧部门\n  O_DEP_ID T_DEPARTMENT_2.F_ID%TYPE;\n  -- 旧权限\n  O_ACCESS_CODE T_USER_2.F_CODE%TYPE;\n  -- 部门权限前缀\n  DEP_ACCESS_CODE_PREFIX T_DEPARTMENT_2.F_CODE%TYPE;\n  -- 部门当前人数\n  DEP_USER_COUNT T_USER_2.F_CODE%TYPE;\n  -- 本部门下的部门数\n  DEP_DEP_COUNT T_DEPARTMENT_2.F_CODE%TYPE;\n  -- 新权限\n  N_ACCESS_CODE T_USER_2.F_CODE%TYPE;\n  -- 更新该员工权限\n  C_UPDATE_USER VARCHAR2(100) := 'UPDATE T_USER_2 SET F_CODE = :1, F_DEPT_ID = :2 WHERE F_ID = :3';\n  -- 更新所有该员工的客户的ACCESS权限\n  C_UPDATE_CUSTOMER VARCHAR2(100) := 'UPDATE T_CUSTOMER_2 SET F_ACCESS_CODE = :1 WHERE F_CREATED_ID = :2';\n  -- 插入一条修改记录\n  C_INSERT_HISTORY VARCHAR2(100) := 'INSERT INTO T_USER_HISTORY VALUES (:1, :2, :3, :4, :5, :6, :7)';\n  BEGIN\n    -- 旧部门\n    SELECT F_DEPT_ID INTO O_DEP_ID FROM T_USER_2 WHERE T_USER_2.F_ID=C_F_ID;\n    -- 旧权限\n    SELECT F_CODE INTO O_ACCESS_CODE FROM T_USER_2 WHERE T_USER_2.F_ID=C_F_ID;\n    -- 新部门权限作为前缀\n    SELECT F_CODE INTO DEP_ACCESS_CODE_PREFIX FROM T_DEPARTMENT_2 WHERE T_DEPARTMENT_2.F_ID = N_DEP_ID;\n    -- 计算该部门人员数量\n    SELECT MAX(T_USER_2.F_CODE) INTO DEP_USER_COUNT FROM T_USER_2 WHERE T_USER_2.F_DEPT_ID = N_DEP_ID;\n    -- 计算子部门数量\n    SELECT MAX(T_DEPARTMENT_2.F_CODE) INTO DEP_DEP_COUNT FROM T_DEPARTMENT_2 WHERE SUBSTR(T_DEPARTMENT_2.F_CODE, 0, LENGTH(DEP_ACCESS_CODE_PREFIX))=DEP_ACCESS_CODE_PREFIX AND LENGTH(T_DEPARTMENT_2.F_CODE)=LENGTH(DEP_ACCESS_CODE_PREFIX)+2;\n    -- 若新部门与旧部门相同，无需更改\n    IF N_DEP_ID=O_DEP_ID THEN\n      RETURN;\n    END IF;\n    -- 新权限CODE\n    IF DEP_DEP_COUNT > DEP_USER_COUNT THEN\n      N_ACCESS_CODE := TO_CHAR(TO_NUMBER(DEP_DEP_COUNT) + 1);\n    ELSE\n      N_ACCESS_CODE := TO_CHAR(TO_NUMBER(DEP_USER_COUNT) + 1);\n    end if;\n    -- 输出相关变量\n    dbms_output.put_line('DEP_USER_COUNT : ' || DEP_USER_COUNT);\n    dbms_output.put_line('DEP_DEP_COUNT : ' || DEP_DEP_COUNT);\n    -- 输出相关变量\n    dbms_output.put_line('DEP_ACCESS_CODE_PREFIX : ' || DEP_ACCESS_CODE_PREFIX);\n    dbms_output.put_line('C_F_ID : ' || C_F_ID);\n    dbms_output.put_line('O_ACCESS_CODE : ' || O_ACCESS_CODE);\n    dbms_output.put_line('N_DEP_ID : ' || N_DEP_ID);\n    dbms_output.put_line('N_ACCESS_CODE : ' || N_ACCESS_CODE);\n    -- 更新该员工权限\n    EXECUTE IMMEDIATE C_UPDATE_USER USING N_ACCESS_CODE, N_DEP_ID, C_F_ID;\n    -- 更新所有该员工的客户的ACCESS权限\n    EXECUTE IMMEDIATE C_UPDATE_CUSTOMER USING N_ACCESS_CODE, C_F_ID;\n    -- 插入一条修改记录\n    EXECUTE IMMEDIATE C_INSERT_HISTORY USING USER_HISTORY.NEXTVAL, C_F_ID, O_DEP_ID, O_ACCESS_CODE, N_DEP_ID, N_ACCESS_CODE, SYSDATE;\n    -- 提交\n    COMMIT;\n  END;\n  /\n```\n\n#### 创建序列\n\n```plsql\n-- 员工部门历史记录主码序列\nCREATE SEQUENCE USER_HISTORY INCREMENT BY 1 START WITH 1;\n```\n\n#### 执行\n\n```plsql\nselect * from t_customer_2 where f_access_code like 'xxx%';\n```\n\n> `xxx%`指匹配所有以`xxx`开头的权限码\n\n#### 当部门结构或员工归属调整时，权限编码如何处理？\n\n方案二中，调用新增的过程`CHANGE_TO_DEPARTMENT`即可级联更改权限码。\n","tags":["TimesTen","内存数据库"],"categories":["archives"]},{"title":"感谢Docker,让我远离环境配置","url":"/2018/11/12/使用Docker安装Oracle-12c/","content":"\n## Why Docker\n\n自开始用Oracle以来，环境配置一直是让我掉头发的事。而如今也只是在Windows上的安装界面点点点成功安装了Oracle，Linux上就从来没成功过，Mac的话Oracle 11g后好像就没Mac版的了，就很头疼。\n\n这学期上了门内存数据库，老师给了个镜像，RedHat+Oracle+TimesTen究极体镜像，扔到VirtualBox上打开直接登录用户名密码，无需安装组件，无需配置环境，即开即用。自由的气息。\n\n偶然间在网上看到了有关于Docker安装oracle的说法，于是便尝试了一下。真的，简洁，优雅，自由，甚至比虚拟机好用多了。\n\n<!-- more -->\n\n## 正题\n\n#### Docker安装并启动Oracle 12c\n\n##### 安装\n\n```sh\n# 在docker中寻找oracle镜像，可看到一条sath89/oracle-12c的镜像，便是我们需要安装的\ndocker search oracle\ndocker pull sath89/oracle-12c\n# 查看已安装的镜像\ndocker images\n```\n\n> 由于docker使用的是国外源，在拉取时的速度可能很慢，可参见博客切换国内源以加快拉取速度：[Docker切换国内镜像下载源](https://blog.csdn.net/huludan/article/details/52713799)\n\n##### 初始化\n\n```shell\n# 使用log记录oracle启动的容器号\nlog=$(sudo docker run -d -p 8080:8080 -p 1521:1521 -v /Users/tanrui/Oracle/oradata:/u01/app/oracle sath89/oracle-12c)\n# 显示当前容器初始化进程\ndocker logs -f $log\n# 显示docker中当前运行的容器(可查看到容器ID)\nsudo docker ps\n```\n\n> 正常情况下，第一次创建容器应称之为`初始化`，而以后创建的容器都应基于上次的历史数据，称作`容器的数据持久化`，在上述命令中`-v`后的`:`之前是当前系统想要存储持久性数据的路径，用户想要共享到容器中的文件也可放入其中，`:`后面是在容器中想要访问`当前系统的共享文件`的路径。\n>\n> 因此在初始化完成后，若仍然使用上述命令，会提示数据库未初始化，从而会重新创建持久性数据文件；因此以后的容器创建应该使用以下命令^1^：\n>\n\n```shell\nsudo docker run -it -p 8080:8080 -p 1521:1521 -v /Users/tanrui/Oracle/oradata:/u01/app/oracle sath89/oracle-12c\n```\n\n>\n> 至于上述的重复初始化是会造成文件覆盖还是文件并存我没有尝试过，猜测应该会是覆盖。\n>\n> 同时，重复执行命令^1^时，还会产生端口冲突。因此如果想创建两个Oracle容器应该执行初始化命令，执行时将持久化数据路径更改到其他地方且需将端口号修改掉。\n\n##### 进入容器\n\n```shell\n# 进入特定的容器，${ContainerID}为上述查看到的容器ID\n# env LANG=C.UTF-8 表示当前容器使用支持中文的UTF-8格式(默认为POSIX，不支持中文)\nsudo docker exec -it ${ContainerID} env LANG=C.UTF-8 /bin/bash\n```\n\n##### 连接oracle数据库\n\n```sh\nroot@1386ef844664:/# su oracle\noracle@1386ef844664:/$ cd $ORACLE_HOME\noracle@1386ef844664:/u01/app/oracle/product/12.1.0/xe$ bin/sqlplus / as sysdba\n```\n##### Oracle数据库设置字符集\n\n```shell\n## 查看数据库编码，结果最下面一行则是目前编码\nSQL> select * from nls_database_parameters where parameter ='NLS_CHARACTERSET';   \n## 关闭数据库\nSQL> shutdown immediate;               \n## 启动到 mount状态，oracle分为4个状态，详情请百度\nSQL> startup mount;                    \n## 设置session ，下同\nSQL> ALTER SYSTEM ENABLE RESTRICTED SESSION;                        \nSQL> ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;\nSQL> ALTER SYSTEM SET AQ_TM_PROCESSES=0;\n## 打开oracle到 open状态\nSQL> alter database open;                               \n## 修改编码为 ZHS16GBK\nSQL> ALTER DATABASE character set INTERNAL_USE ZHS16GBK;                \n## 重启oracle ，先关闭，再启动\nSQL> shutdown immediate;                      \nSQL> startup;\n```\n\n\n\n## 升华\n\nDocker真的好用！（俗\n","tags":["Docker","Oracle"],"categories":["archives"]},{"title":"记一次Win10+Fedora双系统的小折腾","url":"/2018/11/06/记一次Win10-Fedora双系统的小折腾/","content":"\n### 问题描述\n\n因课程需要，我在Win10上安装了Fedora双系统，结果出现了奇怪的问题，现Fedora系统可正常进入，Win10也有引导项，但无法进入Win10系统，报错信息见图。\n我在Google上搜了类似的问题，大多是诸如以下的原因：\n\n<!-- more -->\n\n- 主板供电不足（我使用的是台式机应该不会有这个问题）\n- BIOS中系统时间不正确（我也未曾修改过该时间）\n\n这些原因可能会造成与我类似的状况，但很显然这些都不是此处的问题所在\n\n### 问题出现的环境背景及自己尝试过哪些方法\n\n#### 系统相关信息：\n\n主系统Windows10专业版（安装在100G的SSD中），Fedora29（安装在由1T的HHD分出的50G硬盘中）\n\n#### 尝试过得方法：\n\n 1. 曾使用PE系统中的引导修复工具修复Win10引导，无果\n 2. 在Fedora中安装了`grub工具`尝试修复Win10引导，grub是用来配置启动时引导的系统，而我这里启动后切换到grub界面是有Win10引导的，因此问题应该不是出在这儿，而是出在Win10的引导文件`\\Windows\\System32\\winload.efi`上，感觉此方法应该是行不通的（到此处我排除了grub引导出错的可能性）\n 3. 至此，我想既然问题出在引导文件上，我从我室友电脑上拷贝了一份该文件替换了我的引导文件，然后再使用PE中的引导修复工具修复了一遍，仍然无果\n\n### 问题截图\n\n![Win10报错](/images/bVbjaD6.jpeg)\n\n如上所示，错误信息提示文件`\\Windows\\System32\\winload.efi`出错，导致我一直陷入找`winload.efi`文件错误的怪圈。\n\n### 问题解决方法\n\n鼓捣大半天，我仍然无法解决此问题，便在[SegmentFault](https://segmentfault.com/q/1010000016923264)上提问，希望藉此找到解答。在此要非常感谢解决了我的问题的答主[冯恒智](https://segmentfault.com/u/fenghengzhi/)，一言点睛。\n\n#### 具体解决方法如下（划重点）：\n\n在PE中使用bootice的bcd编辑功能，打开了Win10所在磁盘中的BCD文件（C:\\EFI\\Microsoft\\Boot\\BCD），发现其中的**【启动设备】**项下的**启动磁盘**和**启动分区**项被置空了，我将其填写完毕后（如下图所示）发现Win10就可以正常启动了，我想这应该是我在安装Fedora时的一些不当操作使得BCD文件被修改的缘故而让Win10无法正常启动（Bootice使用方法可参见[此博客](https://blog.csdn.net/testcs_dn/article/details/47904937)）。\n\n![bootice选项](/images/image-20181106214511931.png)\n\n#### 疑问：\n\n我在安装Fedora时应该说，和Win10所在盘是完全分隔开来的，为何Fedora安装好后会影响到Win10的Boot文件呢？更疑惑的是它只影响了配置中的**启动磁盘**和**启动分区**两项，而其他都未曾影响？待解……\n\n#### 就很玄学（挠头\n\n#### 11月7日更新\n\nSegmentFault上的答主[冯恒智](https://segmentfault.com/u/fenghengzhi/)又回复了我的问题，如下：\n> 并不是因为你编辑过bcd文件而导致启动磁盘和启动分区项被置空了，而是在win10安完后编辑过磁盘（比如分区啊，改盘符啊，调整容量什么的）导致找不到启动磁盘和启动分区，重新指定一下就行了\n","tags":["Win10","Linux","双系统","引导修复"],"categories":["archives"]},{"title":"JavaFX 学习小记","url":"/2018/10/28/JavaFX-学习小记/","content":"# JavaFX小记\n\n## 简介\n\n- JavaFX\n\n  `JavaFX`是由[甲骨文(Oracle)公司](https://zh.wikipedia.org/wiki/%E7%94%B2%E9%AA%A8%E6%96%87%E5%85%AC%E5%8F%B8)推出的一系列的产品和技术，主要应用于创建Rich Internet application([RIAs](https://zh.wikipedia.org/wiki/RIA))，它是一个跨平台的桌面应用程序开发框架。\n\n<!-- more -->\n\n- 典型的MVC架构\n\n  - 定义`Model`，使用`javafx.beans`封装类型定义属性类型\n  - 使用`fxml`文件创建`View`，利用SceneBuilder工具进行布局\n  - 创建`Controller`实现动作操作以及`Model`和`View`的联系\n\n## View\n\n- **创建FXML文件，利用SceneBuilder工具进行布局**\n\n## Model\n\n- **定义`Model`中的`Person`类，使用`Property`和`Bind`**\n\n  `java.beans`包中的对象类型不是标准的Java原语，而是新的封装起来的类，它封装了Java原语并添加了一些额外的功能，`Property`和`Bind`方便我们实现以下功能：当某个属性如`First Name`被改变时，会自动收到通知而修改视图，从而保证视图与数据的同步。当然仅仅声明这种类型是不够的，声明只是为后续操作提供类型前提，还需要进一步操作，可参考[JavaFX文档](https://docs.oracle.com/javase/8/javafx/properties-binding-tutorial/binding.htm)。\n\n  **Person.java**\n\n  ```java\n  package com.tanrui.model;\n\n  import java.time.LocalDate;\n\n  import javafx.beans.property.IntegerProperty;\n  import javafx.beans.property.ObjectProperty;\n  import javafx.beans.property.SimpleIntegerProperty;\n  import javafx.beans.property.SimpleObjectProperty;\n  import javafx.beans.property.SimpleStringProperty;\n  import javafx.beans.property.StringProperty;\n\n  /**\n   * Model class for a Person.\n   */\n  public class Person {\n\n      private final StringProperty firstName;\n      private final StringProperty lastName;\n      private final StringProperty street;\n      private final IntegerProperty postalCode;\n      private final StringProperty city;\n      private final ObjectProperty<LocalDate> birthday;\n\n      /**\n       * Default constructor.\n       */\n      public Person() {\n          this(null, null);\n      }\n\n      /**\n       * Constructor with some initial data.\n       *\n       * @param firstName\n       * @param lastName\n       */\n      public Person(String firstName, String lastName) {\n          this.firstName = new SimpleStringProperty(firstName);\n          this.lastName = new SimpleStringProperty(lastName);\n\n          // Some initial dummy data, just for convenient testing.\n          this.street = new SimpleStringProperty(\"some street\");\n          this.postalCode = new SimpleIntegerProperty(1234);\n          this.city = new SimpleStringProperty(\"some city\");\n          this.birthday = new SimpleObjectProperty<LocalDate>(LocalDate.of(1999, 2, 21));\n      }\n\n      public String getFirstName() {\n          return firstName.get();\n      }\n\n      public void setFirstName(String firstName) {\n          this.firstName.set(firstName);\n      }\n\n      public StringProperty firstNameProperty() {\n          return firstName;\n      }\n\n      public String getLastName() {\n          return lastName.get();\n      }\n\n      public void setLastName(String lastName) {\n          this.lastName.set(lastName);\n      }\n\n      public StringProperty lastNameProperty() {\n          return lastName;\n      }\n\n      public String getStreet() {\n          return street.get();\n      }\n\n      public void setStreet(String street) {\n          this.street.set(street);\n      }\n\n      public StringProperty streetProperty() {\n          return street;\n      }\n\n      public int getPostalCode() {\n          return postalCode.get();\n      }\n\n      public void setPostalCode(int postalCode) {\n          this.postalCode.set(postalCode);\n      }\n\n      public IntegerProperty postalCodeProperty() {\n          return postalCode;\n      }\n\n      public String getCity() {\n          return city.get();\n      }\n\n      public void setCity(String city) {\n          this.city.set(city);\n      }\n\n      public StringProperty cityProperty() {\n          return city;\n      }\n\n      public LocalDate getBirthday() {\n          return birthday.get();\n      }\n\n      public void setBirthday(LocalDate birthday) {\n          this.birthday.set(birthday);\n      }\n\n      public ObjectProperty<LocalDate> birthdayProperty() {\n          return birthday;\n      }\n  }\n  ```\n\n- **使用`ObservableList`管理`Person`**\n\n  前一点所述的<u>**后续**</u>操作便是此处了，JavaFX为了实现上述目的即保持视图和数据的同步，引入了一些新的集合类，这里我们用到的是`ObservableList`，`ObservableList`继承了`List`类、实现了`Observable`接口，其实现视图和数据同步的方法是在声明`ObservableList`时为方法传递一个监听器，此监听器需要会通过监听`personData`的变化同步改变视图中对应的值，可参考[ObservableList文档](https://docs.oracle.com/javase/8/javafx/api/javafx/collections/ObservableList.html)\n\n  **Main.java:**\n\n  ```java\n\n  public class Main extends Application {\n\n      /*......Other variables......*/\n\n      /**\n       *\n       * The data of a observable list of Persons\n       */\n      private ObservableList<Person> personData = FXCollections.observableArrayList();\n\n      public ObservableList<Person> getPersonData() {\n          return personData;\n      }\n\n      public Main(){\n          personData.add(new Person(\"Tan\", \"Rui\"));\n          personData.add(new Person(\"Chen\", \"Chao\"));\n          personData.add(new Person(\"Liang\", \"Chengwei\"));\n          personData.add(new Person(\"Xiao\", \"Xin\"));\n          personData.add(new Person(\"Li\", \"Yang\"));\n          personData.add(new Person(\"Chen\", \"Runqian\"));\n          personData.add(new Person(\"Liang\", \"Yongchao\"));\n          personData.add(new Person(\"Luo\", \"Jihao\"));\n          personData.add(new Person(\"Chen\", \"Zhi\"));\n          personData.add(new Person(\"Fan\", \"Fan\"));\n\n      }\n\n      /* ......Other function..... */\n  }\n  ```\n\n## Controller\n\n### PersonOverviewController.java\n\n```java\npackage com.tanrui.view;\n\nimport javafx.fxml.FXML;\nimport javafx.scene.control.Label;\nimport javafx.scene.control.TableColumn;\nimport javafx.scene.control.TableView;\nimport com.tanrui.Main;\nimport com.tanrui.model.Person;\n\npublic class PersonOverviewController {\n    @FXML\n    private TableView<Person> personTable;\n    @FXML\n    private TableColumn<Person, String> firstNameColumn;\n    @FXML\n    private TableColumn<Person, String> lastNameColumn;\n\n    @FXML\n    private Label firstNameLabel;\n    @FXML\n    private Label lastNameLabel;\n    @FXML\n    private Label streetLabel;\n    @FXML\n    private Label postalCodeLabel;\n    @FXML\n    private Label cityLabel;\n    @FXML\n    private Label birthdayLabel;\n\n    // Reference to the main application.\n    private Main main;\n\n    /**\n     * The constructor.\n     * The constructor is called before the initialize() method.\n     */\n    public PersonOverviewController() {\n    }\n\n    /**\n     * Initializes the controller class. This method is automatically called\n     * after the fxml file has been loaded.\n     */\n    @FXML\n    private void initialize() {\n        // Initialize the person table with the two columns.\n        firstNameColumn.setCellValueFactory(cellData -> cellData.getValue().firstNameProperty());\n        lastNameColumn.setCellValueFactory(cellData -> cellData.getValue().lastNameProperty());\n    }\n\n    /**\n     * Is called by the main application to give a reference back to itself.\n     *\n     * @param main\n     */\n    public void setMain(Main main) {\n        this.main = main;\n\n        // Add observable list data to the table\n        personTable.setItems(main.getPersonData());\n    }\n}\n```\n\n- **`@FXML`注解（Annotation）**\n\n  使用`@FXML`注解可以将操作的属性、方法绑定到`FXML`文件的界面元素，实际上，在属性、方法是非私有的情况下可以不使用`@FXML`注解，但是比起非私有声明，让他们保持私有并用注解标记的方式会更好！\n\n- **`initialize()`方法**\n\n  `initialize()`字面意思可知其是用于初始化对应`FXML`文件中的属性，此方法会在加载`FXML`文件时被自动执行，此时，所有的`FXML`属性都应已被初始化\n\n- **`setCellValueFactory(...)`方法**\n\n  我们对表格列上使用`setCellValueFactory(...)`方法来确定为特定列使用前面`Person`的某个属性。`->`表示使用的是[Lambdas](https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/Lambda-QuickStart/index.html)特性；另外一种方法是使用[PropertyValueFactory](https://docs.oracle.com/javase/8/javafx/api/)(待研究…)。\n\n  这里我们之所以可以使用`cellData -> cellData.getValue().firstNameProperty()`，便是因为之前我们将Person的属性都定义为`javafx.beans`中的封装属性，`firstNameProperty()`等方法都会在声明成`Beans`封装类型时被创建，其遵循了固定的命名规则，这使得我们使用起来特别方便\n\n### 连接Main和PersonOverviewController\n\n- **`showPersonOverview()` 方法**\n\n  **Main.java**\n\n  ```java\n\n      /**\n       * Shows the person overview inside the root layout.\n       */\n      public void showPersonOverview() {\n          try {\n              // Load person overview.\n              FXMLLoader loader = new FXMLLoader();\n              loader.setLocation(Main.class.getResource(\"view/PersonOverview.fxml\"));\n              AnchorPane personOverview = (AnchorPane) loader.load();\n\n              // Set person overview into the center of root layout.\n              rootLayout.setCenter(personOverview);\n\n              // Give the controller access to the main app.\n              PersonOverviewController controller = loader.getController();\n              controller.setMain(this);\n\n          } catch (IOException e) {\n              e.printStackTrace();\n          }\n      }\n  ```\n\n### 将View与Controller绑定\n\n我们还需要为`FXML文件`指定其对应的`Controller`，以及`FXML元素`与`控制器的属性`的对应关系，这是因为FXML文件中的元素只能被对应`Controller`修改更新，若在其他方法中修改会产生运行时错误。例如：在`PersonOverviewController.java`中将某个`Label`返回到`Main.java`中而后在其中修改该`Label`的值，意即在`非FX线程`中执行`FX线程`相关的任务，则会造成当前的线程阻塞，解决方法之一是使用`Platform.runLater()`方法，如下所示，括号中的`FX线程`相关任务便不会阻塞当前进程。\n\n```\nPlatform.runLater(() -> {\n        ………相关FX线程代码………\n});\n```\n\n当然，最好的选择还是讲`FX线程`任务和其他任务区分开来，将特定的`FXML文件`与对应的`Controller`联系起来，当需要建立联系时可通过之前所说的使用`java.beans`、`ObservableList`等方法实现动态更新视图。\n\n- **为`FXML文件`指定`Controller`**\n\n  在Eclipse中好像有图形化界面直接为`FXML文件`选择`Controller`的操作，但是我使用的是IDEA，没有此功能，只能在源代码中指定，如下所示。\n\n  **PersonOverview.fxml**\n\n  ```xml\n  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n  <AnchorPane maxHeight=\"-Infinity\" maxWidth=\"-Infinity\" minHeight=\"-Infinity\" minWidth=\"-Infinity\" prefHeight=\"300.0\" prefWidth=\"600.0\" xmlns=\"http://javafx.com/javafx/8.0.121\" xmlns:fx=\"http://javafx.com/fxml/1\" fx:controller=\"com.tanrui.view.PersonOverviewController\">\n      <children>\n          <? ... 内容省略 ... ?>\n      </children>\n  </AnchorPane>\n  ```\n\n  如上述代码所述，在顶层节点（此处是`AnchorPane`）标签中添加属性如下：`fx:controller=\"com.tanrui.view.PersonOverviewController”`，以此为`FXML文件`指定`Controller`\n\n- 为`FXML元素`指定`fx:id`，使其绑定对应的`控制器属性`\n\n  ![image-20181023205748006](/img/image-20181023205748006.png)\n\n  如图，选定特定元素，在右侧界面找到`Code`->`fx:id`，将其对应的控制器属性填入即可\n\n### Details界面更新\n\n- **`showPersonDetails(Person person)`方法**\n\n  `showPersonDetails(Person person)`方法用于使用Person实例的数据填写标签。\n\n  **PersonOverviewController.java**\n\n  ```java\n  /**\n   * Fills all text fields to show details about the person.\n   * If the specified person is null, all text fields are cleared.\n   *\n   * @param person the person or null\n   */\n  private void showPersonDetails(Person person) {\n      if (person != null) {\n          // Fill the labels with info from the person object.\n          firstNameLabel.setText(person.getFirstName());\n          lastNameLabel.setText(person.getLastName());\n          streetLabel.setText(person.getStreet());\n          postalCodeLabel.setText(Integer.toString(person.getPostalCode()));\n          cityLabel.setText(person.getCity());\n\n          // TODO: We need a way to convert the birthday into a String!\n          // birthdayLabel.setText(...);\n      } else {\n          // Person is null, remove all the text.\n          firstNameLabel.setText(\"\");\n          lastNameLabel.setText(\"\");\n          streetLabel.setText(\"\");\n          postalCodeLabel.setText(\"\");\n          cityLabel.setText(\"\");\n          birthdayLabel.setText(\"\");\n      }\n  }\n  ```\n\n- **监听用户在人员表中的选择**\n\n  **PersonOverviewController.java**\n\n  ```java\n  @FXML\n  private void initialize() {\n      // Initialize the person table with the two columns.\n      firstNameColumn.setCellValueFactory(\n              cellData -> cellData.getValue().firstNameProperty());\n      lastNameColumn.setCellValueFactory(\n              cellData -> cellData.getValue().lastNameProperty());\n\n      // Clear person details.\n      showPersonDetails(null);\n\n      // Listen for selection changes and show the person details when changed.\n      personTable.getSelectionModel().selectedItemProperty().addListener(\n              (observable, oldValue, newValue) -> showPersonDetails(newValue));\n  }\n  ```\n\n### 删除按钮事件\n\n我们的界面已经包含了一个删除的按钮 ，但是并没有为其制定实际的响应操作，因此我们定义一个响应函数，如下：\n\n**PersonOverviewController.java**:\n\n```java\n/**\n     * Called when the user clicks on the delete button.\n     */\n    @FXML\n    private void handleDeletePerson() {\n        int selectedIndex = personTable.getSelectionModel().getSelectedIndex();\n        if (selectedIndex >= 0){\n            personTable.getItems().remove(selectedIndex);\n        }\n        else{\n            new ShowDialog(main.getPrimaryStage(), Alert.AlertType.WARNING, \"No Person Selected\", \"Please select a person in the table.\").ShowSpecificDialog();\n        }\n    }\n```\n\n#### 错误处理\n\n从上述代码可以看到我们使用了条件判断语句来判断`selectedIndex`的值，当其小于0时，正常情况我们应该会让其抛出`ArrayIndexOutOfBoundsException`异常，但是我们想尽量简洁明了的将错误或者警告信息展示给用户，因此这里我们使用了`controlsfx`包，用于弹出各类提示框（可在[ControlsFX](http://fxexperience.com/controlsfx/)官网获取）。\n\n`controlsfx`有两个主要的版本，同时对于不同的版本，二者的用法也不同：\n\n- 对于Java 8，需要下载[ControlsFX 8.40.14](http://fxexperience.com/downloads/controlsfx-8-40-14/)包\n- 对于Java 9及以上，需要下载[ControlsFX 9.0.0](http://fxexperience.com/downloads/controlsfx-9-0-0/)包\n\n我们这里用到的是Java 10，因此使用`ControlsFX 9.0.0`，使用方法如下：\n\n**ShowDialog.java**:\n\n```java\npackage com.tanrui.util;\n\nimport javafx.scene.control.Alert;\nimport javafx.stage.Stage;\n\n/**\n * Util to create and show Dialog.\n *\n * @author Tan Rui\n */\npublic class ShowDialog {\n\n    private Stage stage;\n    private Alert.AlertType type;\n    private String title;\n    private String message;\n\n    public ShowDialog(Stage stage, Alert.AlertType type, String title, String message){\n        this.stage = stage;\n        this.type = type;\n        this.title = title;\n        this.message = message;\n    }\n\n    public void ShowSpecificDialog(){\n        Alert dlg = new Alert(type);\n        dlg.initOwner(stage);\n        dlg.setTitle(title);\n        dlg.getDialogPane().setContentText(message);\n        dlg.show();\n    }\n}\n```\n\n**PersonOverviewController.java**\n\n```java\n/**\n     * Called when the user clicks on the delete button.\n     */\n    @FXML\n    private void handleDeletePerson() {\n        int selectedIndex = personTable.getSelectionModel().getSelectedIndex();\n        if (selectedIndex >= 0){\n            personTable.getItems().remove(selectedIndex);\n        }\n        else{\n            new ShowDialog(main.getPrimaryStage(), Alert.AlertType.WARNING, \"No Person Selected\", \"Please select a person in the table.\").ShowSpecificDialog();\n        }\n    }\n```\n\n### 新建和编辑对话框\n\n> Tips：创建一个新的界面、新的Stage（承载新的View时），步骤一般都是：\n>\n> 1. 创建FXML文件，使用SceneBuilder编辑界面；\n> 2. 创建对应的Controller，对FXML中的元素指定对应的属性。主要是为展示型元素指定数据、为控制型元素指定动作等；\n> 3. 连接FXML文件和Controller文件、连接FXML中的元素和Controller中的属性；\n> 4. 在Main函数中加载该控制器\n\n为之前的`New`和`Edit`按钮添加动作，弹出对话框（新的Stage）。\n\n#### 设计对话框\n\n创建`PersonEditDialog.fxml`，完成弹出对话框的设计：\n\n![image-20181027150559447](/img/image-20181027150559447.png)\n\n#### 创建控制器\n\n为对话框创建控制器`PersonEditDialogController.java`。\n\n**PersonEditDialogController.java：**\n\n```java\npackage com.tanrui.view;\n\nimport com.tanrui.util.ShowDialog;\nimport javafx.fxml.FXML;\nimport javafx.scene.control.Alert;\nimport javafx.scene.control.TextField;\nimport javafx.stage.Stage;\n\nimport com.tanrui.model.Person;\nimport com.tanrui.util.DateUtil;\n\n\n/**\n * Dialog to edit details of a person.\n *\n * @author Marco Jakob\n */\npublic class PersonEditDialogController {\n\n    @FXML\n    private TextField firstNameField;\n    @FXML\n    private TextField lastNameField;\n    @FXML\n    private TextField streetField;\n    @FXML\n    private TextField postalCodeField;\n    @FXML\n    private TextField cityField;\n    @FXML\n    private TextField birthdayField;\n\n\n    private Stage dialogStage;\n    private Person person;\n    private boolean okClicked = false;\n\n    /**\n     * Initializes the controller class. This method is automatically called\n     * after the fxml file has been loaded.\n     */\n    @FXML\n    private void initialize() {\n    }\n\n    /**\n     * Sets the stage of this dialog.\n     *\n     * @param dialogStage\n     */\n    public void setDialogStage(Stage dialogStage) {\n        this.dialogStage = dialogStage;\n    }\n\n    /**\n     * Sets the person to be edited in the dialog.\n     *\n     * @param person\n     */\n    public void setPerson(Person person) {\n        this.person = person;\n\n        firstNameField.setText(person.getFirstName());\n        lastNameField.setText(person.getLastName());\n        streetField.setText(person.getStreet());\n        postalCodeField.setText(Integer.toString(person.getPostalCode()));\n        cityField.setText(person.getCity());\n        birthdayField.setText(DateUtil.format(person.getBirthday()));\n        birthdayField.setPromptText(\"dd.mm.yyyy\");\n    }\n\n    /**\n     * Returns true if the user clicked OK, false otherwise.\n     *\n     * @return\n     */\n    public boolean isOkClicked() {\n        return okClicked;\n    }\n\n    /**\n     * Called when the user clicks ok.\n     */\n    @FXML\n    private void handleOk() {\n        if (isInputValid()) {\n            person.setFirstName(firstNameField.getText());\n            person.setLastName(lastNameField.getText());\n            person.setStreet(streetField.getText());\n            person.setPostalCode(Integer.parseInt(postalCodeField.getText()));\n            person.setCity(cityField.getText());\n            person.setBirthday(DateUtil.parse(birthdayField.getText()));\n\n            okClicked = true;\n            dialogStage.close();\n        }\n    }\n\n    /**\n     * Called when the user clicks cancel.\n     */\n    @FXML\n    private void handleCancel() {\n        dialogStage.close();\n    }\n\n    /**\n     * Validates the user input in the text fields.\n     *\n     * @return true if the input is valid\n     */\n    private boolean isInputValid() {\n        String errorMessage = \"\";\n\n        if (firstNameField.getText() == null || firstNameField.getText().length() == 0) {\n            errorMessage += \"No valid first name!\\n\";\n        }\n        if (lastNameField.getText() == null || lastNameField.getText().length() == 0) {\n            errorMessage += \"No valid last name!\\n\";\n        }\n        if (streetField.getText() == null || streetField.getText().length() == 0) {\n            errorMessage += \"No valid street!\\n\";\n        }\n\n        if (postalCodeField.getText() == null || postalCodeField.getText().length() == 0) {\n            errorMessage += \"No valid postal code!\\n\";\n        } else {\n            try {\n                Integer.parseInt(postalCodeField.getText());\n            } catch (NumberFormatException e) {\n                errorMessage += \"No valid postal code (must be an integer)!\\n\";\n            }\n        }\n\n        if (cityField.getText() == null || cityField.getText().length() == 0) {\n            errorMessage += \"No valid city!\\n\";\n        }\n\n        if (birthdayField.getText() == null || birthdayField.getText().length() == 0) {\n            errorMessage += \"No valid birthday!\\n\";\n        } else {\n            if (!DateUtil.validDate(birthdayField.getText())) {\n                errorMessage += \"No valid birthday. Use the format dd.mm.yyyy!\\n\";\n            }\n        }\n\n        if (errorMessage.length() == 0) {\n            return true;\n        } else {\n            new ShowDialog(dialogStage, Alert.AlertType.ERROR, \"Invalid Fields\", \"Please correct invalid fields\").ShowSpecificDialog();\n            return false;\n        }\n    }\n}\n```\n\n关于该控制器的一些事情应该注意：\n\n1. `setPerson(…)`方法可以从其它类中调用，用来设置编辑的人员。\n2. 当用户点击OK按钮时，调用`handleOK()`方法。首先，通过调用`isInputValid()`方法做一些验证。只有验证成功，Person对象使用输入的数据填充。这些修改将直接应用到Person对象上，传递给`setPerson(…)`。\n3. 布尔值`okClicked`被使用，以便调用者决定用户是否点击OK或者Cancel按钮。\n\n#### 连接视图和控制器\n\n使用已经创建的视图（FXML）和控制器，需要连接到一起。\n\n1. 使用SceneBuilder打开`PersonEditDialog.fxml`文件\n2. 在左边的*Controller*组中选择`PersonEditDialogController`作为控制器类\n3. 设置所有**TextField**的`fx:id`到相应的控制器字段上。\n4. 设置两个按钮的**onAction**到相应的处理方法上。\n\n#### 在Main中部署该控制器\n\n**Main.java:**\n\n```java\n/**\n * Opens a dialog to edit details for the specified person. If the user\n * clicks OK, the changes are saved into the provided person object and true\n * is returned.\n *\n * @param person the person object to be edited\n * @return true if the user clicked OK, false otherwise.\n */\npublic boolean showPersonEditDialog(Person person) {\n    try {\n        // Load the fxml file and create a new stage for the popup dialog.\n        FXMLLoader loader = new FXMLLoader();\n        loader.setLocation(Main.class.getResource(\"view/PersonEditDialog.fxml\"));\n        AnchorPane page = (AnchorPane) loader.load();\n\n        // Create the dialog Stage.\n        Stage dialogStage = new Stage();\n        dialogStage.setTitle(\"Edit Person\");\n        dialogStage.initModality(Modality.WINDOW_MODAL);\n        dialogStage.initOwner(primaryStage);\n        Scene scene = new Scene(page);\n        dialogStage.setScene(scene);\n\n        // Set the person into the controller.\n        PersonEditDialogController controller = loader.getController();\n        controller.setDialogStage(dialogStage);\n        controller.setPerson(person);\n\n        // Show the dialog and wait until the user closes it\n        dialogStage.showAndWait();\n\n        return controller.isOkClicked();\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}\n```\n\n为主界面中`New`和`Edit`按钮创建OnAction方法，这些方法将从`Main`中调用`showPersonEditDialog(…)`方法。\n\n**PersonOverviewController.java:**\n\n```java\n    /**\n     * Called when the user clicks the new button. Opens a dialog to edit\n     * details for a new person.\n     */\n    @FXML\n    private void handleNewPerson() {\n        Person tempPerson = new Person();\n        boolean okClicked = main.showPersonEditDialog(tempPerson);\n        if (okClicked) {\n            main.getPersonData().add(tempPerson);\n        }\n    }\n\n    /**\n     * Called when the user clicks the edit button. Opens a dialog to edit\n     * details for the selected person.\n     */\n    @FXML\n    private void handleEditPerson() {\n        Person selectedPerson = personTable.getSelectionModel().getSelectedItem();\n        if (selectedPerson != null) {\n            boolean okClicked = main.showPersonEditDialog(selectedPerson);\n            if (okClicked) {\n                showPersonDetails(selectedPerson);\n            }\n\n        } else {\n            new ShowDialog(main.getPrimaryStage(), Alert.AlertType.WARNING, \"No Person Selected\", \"Please select a person in the table.\").ShowSpecificDialog();\n        }\n    }\n```\n\n而后在`PersonOverview.fxml`中为New和Edit两个按钮绑定对应的OnAction方法：\n\n![image-20181027164439676](/img/image-20181027164439676.png)\n\n### 数据持久化\n\n我们有很多种方法来实现应用数据的持久化，例如：\n\n- 使用数据库存储\n- 使用Json文件存储\n- 使用XML文件存储\n- ……\n\n这里我们使用XML文件格式存储应用数据。之前的我们应用的数据都只是存在内存中，内存的特性使得关闭应用程序后数据便会丢失，因此我们下面要做的就是：\n\n1. 每次打开应用可加载上一次的用户数据\n2. 用户可选择保存当前数据到指定XML文件\n3. 用户可选择从指定XML文件加载数据\n\n#### 使用Preferences保存应用状态\n\n`Java`提供了`Preferences`类来帮助我们存储用户配置（本例中是XML数据文件的路径，用于下次打开从该文件中加载），`Preferences`类底层对各类操作系统进行了封装（实际上是`Windows系统`、`OS X系统`和`类Unix文件系统`三种），用户配置在`Windows系统`上可能保存在注册表中、在`类Unix文件系统`上可能保存在`/tmp`下的某个隐藏文件中，而对于使用者来说这些实现细节都不必考虑，只需知道`Preferences`类是用来保存用户配置即可。用法如下：\n\n**Main.java:**\n\n```java\n/**\n     * Returns the person file preference, i.e. the file that was last opened.\n     * The preference is read from the OS specific registry. If no such\n     * preference can be found, null is returned.\n     *\n     * @return\n     */\n    public File getPersonFilePath() {\n        Preferences prefs = Preferences.userNodeForPackage(Main.class);\n        String filePath = prefs.get(\"filePath\", null);\n        if (filePath != null) {\n            return new File(filePath);\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Sets the file path of the currently loaded file. The path is persisted in\n     * the OS specific registry.\n     *\n     * @param file the file or null to remove the path\n     */\n    public void setPersonFilePath(File file) {\n        Preferences prefs = Preferences.userNodeForPackage(Main.class);\n        if (file != null) {\n            prefs.put(\"filePath\", file.getPath());\n            // Update the stage title.\n            primaryStage.setTitle(\"AddressApp - \" + file.getName());\n        } else {\n            prefs.remove(\"filePath\");\n            // Update the stage title.\n            primaryStage.setTitle(\"AddressApp\");\n        }\n    }\n```\n\n#### 使用JAXB\n\n`JAXB包`是Java中提供的对数据进行`编列(marshall)`成XML文件以及对XML文件`反编列(unmarshall)`为数据结构的包，`Java SE`中有如下支持类型：`JAXB 2.0`是`JDK 1.6`的组成部分。`JAXB 2.2.3`是`JDK 1.7以上`的组成部分，而实际上在`Java 9`之后就已将`JAXB`包移除，因此使用时需添加额外的lib包，详情可见博客[真正解决方案：java.lang.ClassNotFoundException: javax.xml.bind.JAXBException](https://blog.csdn.net/hadues/article/details/79188793)。\n\n##### JAXB模型类\n\n我们希望持久化的数据应该是`Main`中的`personData`，而`JAXB`有以下要求：\n\n- 使用`@XmlRootElement`定义`XML根元素`的名称\n- 使用`@XmlElement`指定一个`XML元素`，可选\n\n而`Main`中的`personData`是`ObservableList`类型，由于`ObservableList`类型不支持添加注解，因此我们需要创建另外一个能保存`Person`列表同时又能存储为`XML文件`的类，如下。\n\n**PersonListWrapper.java:**\n\n```java\npackage com.tanrui.model;\n\nimport java.util.List;\n\nimport javax.xml.bind.annotation.XmlElement;\nimport javax.xml.bind.annotation.XmlRootElement;\n\n/**\n * Helper class to wrap a list of persons. This is used for saving the\n * list of persons to XML.\n */\n@XmlRootElement(name = \"persons\")\npublic class PersonListWrapper {\n\n    private List<Person> persons;\n\n    @XmlElement(name = \"person\")\n    public List<Person> getPersons() {\n        return persons;\n    }\n\n    public void setPersons(List<Person> persons) {\n        this.persons = persons;\n    }\n}\n```\n\n##### 使用JAXB读写数据到XML文件\n\n我们将读写XML文件的逻辑放到`Main类`中，`Controller`在用到相应的逻辑时，直接调用`Main`中的方法即可。\n\n**Main.java:**\n\n```java\n\n    /**\n     * Loads person data from the specified file. The current person data will\n     * be replaced.\n     *\n     * @param file\n     */\n    public void loadPersonDataFromFile(File file) {\n        try {\n            JAXBContext context = JAXBContext\n                    .newInstance(PersonListWrapper.class);\n            Unmarshaller um = context.createUnmarshaller();\n\n            // Reading XML from the file and unmarshalling.\n            PersonListWrapper wrapper = (PersonListWrapper) um.unmarshal(file);\n\n            personData.clear();\n            personData.addAll(wrapper.getPersons());\n\n            // Save the file path to the registry.\n            setPersonFilePath(file);\n\n        } catch (Exception e) { // catches ANY exception\n            new ShowDialog(this.getPrimaryStage(), Alert.AlertType.ERROR, \"Error\", \"Could not save data to file:\\n\" + file.getPath()).ShowSpecificDialog();\n        }\n    }\n\n    /**\n     * Saves the current person data to the specified file.\n     *\n     * @param file\n     */\n    public void savePersonDataToFile(File file) {\n        try {\n            JAXBContext context = JAXBContext.newInstance(PersonListWrapper.class);\n            Marshaller m = context.createMarshaller();\n            m.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, true);\n\n            // Wrapping our person data.\n            PersonListWrapper wrapper = new PersonListWrapper();\n            wrapper.setPersons(personData);\n\n            // Marshalling and saving XML to the file.\n            m.marshal(wrapper, file);\n\n            // Save the file path to the registry.\n            setPersonFilePath(file);\n        } catch (Exception e) { // catches ANY exception\n            new ShowDialog(this.getPrimaryStage(), Alert.AlertType.ERROR, \"Error\", \"Could not save data to file:\\n\" + file.getPath()).ShowSpecificDialog();\n        }\n    }\n```\n\n`编组(marshall):savePersonDataToFile(…)`和`解组(unmarshall):loadPersonDataFromFile(…)`已准备好，下面在界面中使用它。\n\n#### 创建打开和保存菜单\n\n##### 为File菜单添加子项\n\n![image-20181027232418408](/img/image-20181027232418408.png)\n\n##### 处理菜单相应动作\n\n`Controller`中使用`FileChooser`的方法，`FileChooser`同样封装了不同操作系统的具体实现，使用者仅需调用接口即可。\n\n本类中使用了`FileChooser.ExtensionFilter`，对文件系统中文件进行过滤，保留`.xml`结尾的文件。\n\n当用户选择特定文件而后点击`打开`按钮时，会返回该文件，否则返回`Null`。\n\n```java\npackage com.tanrui.view;\n\nimport com.tanrui.Main;\nimport com.tanrui.util.ShowDialog;\nimport javafx.fxml.FXML;\nimport javafx.scene.control.Alert;\nimport javafx.stage.FileChooser;\n\nimport java.io.File;\n\n/**\n * The controller for the root layout. The root layout provides the basic\n * application layout containing a menu bar and space where other JavaFX\n * elements can be placed.\n */\npublic class RootLayoutController {\n\n    // Reference to the main application\n    private Main main;\n\n    /**\n     * Is called by the main application to give a reference back to itself.\n     *\n     * @param main\n     */\n    public void setMain(Main main) {\n        this.main = main;\n    }\n\n    /**\n     * Creates an empty address book.\n     */\n    @FXML\n    private void handleNew() {\n        main.getPersonData().clear();\n        main.setPersonFilePath(null);\n    }\n\n    /**\n     * Opens a FileChooser to let the user select an address book to load.\n     */\n    @FXML\n    private void handleOpen() {\n        FileChooser fileChooser = new FileChooser();\n\n        // Set extension filter\n        FileChooser.ExtensionFilter extFilter = new FileChooser.ExtensionFilter(\n                \"XML files (*.xml)\", \"*.xml\");\n        fileChooser.getExtensionFilters().add(extFilter);\n\n        // Show save file dialog\n        File file = fileChooser.showOpenDialog(main.getPrimaryStage());\n\n        if (file != null) {\n            main.loadPersonDataFromFile(file);\n        }\n    }\n\n    /**\n     * Saves the file to the person file that is currently open. If there is no\n     * open file, the \"save as\" dialog is shown.\n     */\n    @FXML\n    private void handleSave() {\n        File personFile = main.getPersonFilePath();\n        if (personFile != null) {\n            main.savePersonDataToFile(personFile);\n        } else {\n            handleSaveAs();\n        }\n    }\n\n    /**\n     * Opens a FileChooser to let the user select a file to save to.\n     */\n    @FXML\n    private void handleSaveAs() {\n        FileChooser fileChooser = new FileChooser();\n\n        // Set extension filter\n        FileChooser.ExtensionFilter extFilter = new FileChooser.ExtensionFilter(\n                \"XML files (*.xml)\", \"*.xml\");\n        fileChooser.getExtensionFilters().add(extFilter);\n\n        // Show save file dialog\n        File file = fileChooser.showSaveDialog(main.getPrimaryStage());\n\n        if (file != null) {\n            // Make sure it has the correct extension\n            if (!file.getPath().endsWith(\".xml\")) {\n                file = new File(file.getPath() + \".xml\");\n            }\n            main.savePersonDataToFile(file);\n        }\n    }\n\n    /**\n     * Opens an about dialog.\n     */\n    @FXML\n    private void handleAbout() {\n        new ShowDialog(main.getPrimaryStage(), Alert.AlertType.INFORMATION, \"About\", \"Author: Tan\\\\nWebsite: https://guitoubing.top\").ShowSpecificDialog();\n    }\n\n    /**\n     * Closes the application.\n     */\n    @FXML\n    private void handleExit() {\n        System.exit(0);\n    }\n\n    /**\n     * Opens the birthday statistics.\n     */\n    @FXML\n    private void handleShowBirthdayStatistics() {\n        main.showBirthdayStatistics();\n    }\n}\n```\n\n##### 连接FXML文件和Controller、绑定菜单和对应动作\n\n![image-20181027233726178](/img/image-20181027233726178.png)\n\n![image-20181027233529314](/img/image-20181027233529314.png)\n\n##### 在Main中部署该控制器\n\n**Main.java:**\n\n```java\n /**\n     * Initializes the root layout.\n     */\n    public void initRootLayout() {\n        try {\n            // Load root layout from fxml file.\n            FXMLLoader loader = new FXMLLoader();\n            loader.setLocation(Main.class.getResource(\"view/RootLayout.fxml\"));\n            rootLayout = (BorderPane) loader.load();\n\n            // Show the scene containing the root layout.\n            Scene scene = new Scene(rootLayout);\n            primaryStage.setScene(scene);\n\n            RootLayoutController controller = loader.getController();\n            controller.setMain(this);\n\n            primaryStage.show();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n\n        File file = getPersonFilePath();\n        if (file != null){\n            loadPersonDataFromFile(file);\n        }\n    }\n```\n\n## 参考资料\n\n1. [code.makery —— JavaFX中文教程](https://code.makery.ch/)\n2. [JavaFX Tutorial](https://www.tutorialspoint.com/javafx/)\n3. [真正解决方案：java.lang.ClassNotFoundException: javax.xml.bind.JAXBException](https://blog.csdn.net/hadues/article/details/79188793)\n4. [fxexperience —— ControlFX](http://fxexperience.com/controlsfx/)\n5. [Java SE8 —— Lambda](https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/Lambda-QuickStart/index.html)\n6. …………\n\n## 写在后面\n\n本博主要是在学习[code.makery —— JavaFX中文教程](https://code.makery.ch/)博客中对于JavaFX的教程，跟着博主的项目逻辑和代码自己过了一遍，对一些由于版本不兼容（博主使用的是`JDK 8u40`，我这里使用的是`Java 10 2018-03-20`）造成的问题进行了解决，同时对项目过程中一些功能进行了拓展学习，研究了很多用到的包源码，收获颇多。可点击[JavaFX-Test](http://getme.guitoubing.top/JavaFX_PRE.zip)中获取源码。\n\n希望藉此次`JavaFX`学习开启我的Java源码学习之旅，道阻且长！\n","tags":["Java","JavaFX","Java源码学习之旅"],"categories":["archives"]},{"title":"TimesTen内存数据库课程笔记（更新中）","url":"/2018/09/02/TimesTen内存数据库课程笔记/","content":"# 内存计算与内存数据库\n\n## 第零章\n\nOLTP：行存储（记录：元组），联机事务处理\n\nOLAP：列存储（key-value），联机分析处理\n\n## Timesten操作小记\n\n<!-- more -->\n\n### 平台\n\n> 系统：Red Hat Enterprise Linux Server release 5.7 (Tikanga)\n>\n\n### 创建DSN（Data Source Name）\n\n> 逻辑名，用于标识某一数据库连接\n\n#### 打开数据库配置文件(通常称为`系统ODBC.INI配置文件`)\n\n```sh\n$ cd $TT_HOME/info\n$ gedit sys.odbc.ini\n```\n#### 在数据库DSN列表中添加需要新建的数据库名称\n\n```ini\n# 添加my_ttdb数据库，“=”后面是指该数据库使用某种驱动，如第3行所示\n[ODBC Data Sources]\nmy_ttdb=TimesTen 11.2.2 Driver\nTT_1122=TimesTen 11.2.2 Driver\nsampledb_1122=TimesTen 11.2.2 Driver\ncachedb1_1122=TimesTen 11.2.2 Driver\nrepdb1_1122=TimesTen 11.2.2 Driver\nrepdb2_1122=TimesTen 11.2.2 Driver\nsampledbCS_1122=TimesTen 11.2.2 Client Driver\ncachedb1CS_1122=TimesTen 11.2.2 Client Driver\nrepdb1CS_1122=TimesTen 11.2.2 Client Driver\nrepdb2CS_1122=TimesTen 11.2.2 Client Driver\n```\n\n#### 为2中创建的数据库添加配置，<u>**日志文件与检查点文件应存储在不同磁盘中**</u>\n\n```ini\n# 配置my_ttdb\n[my_ttdb]\n# 数据库监听器驱动位置\nDriver=/home/oracle/TimesTen/tt1122/lib/libtten.so \n# DataStore为检查点文件存储位置\nDataStore=/u02/ttdata/datastores/my_ttdb \n# LogDir为日志文件存储位置\nLogDir=/u03/ttdata/logs\n# 以下两个Size是TimesTen内存数据库的内存分配\nPermSize=40\nTempSize=32\n# 数据库的字符集\nDatabaseCharacterSet=AL32UTF8\n```\n\n> TimesTen的内存分配主要是PermSize和TempSize两块，可先参考博客[**<u>如何更改TimesTen数据库的大小</u>**](https://blog.csdn.net/stevensxiao/article/details/51050831)。\n\n#### 保存配置文件并关闭\n\n### 数据库服务器基本命令\n\n#### 查看服务器状态\n\n```sh\n[oracle@timesten-hol info]$ ttstatus\nTimesTen status report as of Thu Sep 27 04:08:30 2018\n\nDaemon pid 2637 port 53392 instance tt1122\nTimesTen server pid 2646 started on port 53393\n------------------------------------------------------------------------\nAccessible by group oracle\nEnd of report\n```\n\n#### 启动/停止数据库\n\n```sh\n[oracle@timesten-hol info]$ ttdaemonadmin -stop\nTimesTen Daemon stopped.\n[oracle@timesten-hol info]$ ttstatus\nttStatus: Could not connect to the TimesTen daemon.\nIf the TimesTen daemon is not running, please start it\nby running \"ttDaemonAdmin -start\".\n[oracle@timesten-hol info]$ ttdaemonadmin -start\nTimesTen Daemon startup OK.\n[oracle@timesten-hol info]$ ttstatus\nTimesTen status report as of Thu Sep 27 04:10:00 2018\n\nDaemon pid 6522 port 53392 instance tt1122\nTimesTen server pid 6531 started on port 53393\n------------------------------------------------------------------------\nAccessible by group oracle\nEnd of report\n```\n\n### 创建TimesTen内存数据库\n\n> 默认情况下，TimesTen内存数据库在第一次连接到数据库时创建并加载到内存中，并在关闭数据库的最后一个连接时从内存卸载。当然此行为可通过`ttadmin -RAMPolicy`修改，后面会说到。\n>\n> 也就是说，默认情况下（前提是RAM策略为`inUse`，下一节会讲到RAM策略的修改），每次在执行`connect “dsn=ttdb_name”`连接到一个特定的DSN时，都是一个创建TimesTen内存数据库、加载数据到内存中等过程，因此本节的标题是`创建`而不是`连接到`。\n\n#### 连接到特定DSN，创建内存数据库\n\n```sh\n[oracle@timesten-hol info]$ ttisql\n\nCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.\nType ? or \"help\" for help, type \"exit\" to quit ttIsql.\n\nCommand> connect \"dsn=my_ttdb\";\nConnection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n(Default setting AutoCommit=1)\n```\n\n或者直接在ttisql中指定DSN名称：\n\n```sh\n[oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\"\n\nCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.\nType ? or \"help\" for help, type \"exit\" to quit ttIsql.\n\nconnect \"dsn=my_ttdb\";\nConnection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n(Default setting AutoCommit=1)\n[oracle@timesten-hol ~]$ ttisql my_ttdb\n\nCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.\nType ? or \"help\" for help, type \"exit\" to quit ttIsql.\n\nconnect \"DSN=my_ttdb\";\nConnection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n(Default setting AutoCommit=1)\n```\n\n\n\n> **问题：重复运行`connect “dsn=ttdb_name”`命令可以看到命令行中显示了多了连接，这是什么作用呢？**\n>\n> ```sh\n> Command> connect \"dsn=my_ttdb\";\n> Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n> (Default setting AutoCommit=1)\n> Command> connect \"dsn=my_ttdb\";\n> Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n> (Default setting AutoCommit=1)\n> con1: Command> connect \"dsn=my_ttdb\";\n> Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n> (Default setting AutoCommit=1)\n> con2: Command> connect \"dsn=my_ttdb\";\n> Connection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n> (Default setting AutoCommit=1)\n> con3: Command> \n> ```\n\n#### 查看内存数据库的内存分配及容量\n\n```sh\nCommand> dssize\n\n  PERM_ALLOCATED_SIZE:      40960\n  PERM_IN_USE_SIZE:         9453\n  PERM_IN_USE_HIGH_WATER:   9453\n  TEMP_ALLOCATED_SIZE:      32768\n  TEMP_IN_USE_SIZE:         9442\n  TEMP_IN_USE_HIGH_WATER:   9505\n```\n\n#### 使用Host命令可以调用操作系统级别的指令\n\n```sh\nCommand> host ttstatus;\nTimesTen status report as of Thu Sep 27 04:37:28 2018\n\nDaemon pid 6522 port 53392 instance tt1122\nTimesTen server pid 6531 started on port 53393\n------------------------------------------------------------------------\nData store /u01/ttdata/datastores/my_ttdb\nThere are 12 connections to the data store\nShared Memory KEY 0x1200c904 ID 2785297\nPL/SQL Memory KEY 0x1300c904 ID 2818066 Address 0x7fa0000000\nType            PID     Context             Connection Name              ConnID\nProcess         6973    0x0000000000c72c00  my_ttdb                           1\nSubdaemon       6529    0x00000000012d3360  Manager                         142\nSubdaemon       6529    0x000000000132a1e0  Rollback                        141\nSubdaemon       6529    0x000000000140b360  HistGC                          139\nSubdaemon       6529    0x0000000001420070  AsyncMV                         140\nSubdaemon       6529    0x00000000014b4e00  Log Marker                      136\nSubdaemon       6529    0x0000000001509a30  Deadlock Detector               135\nSubdaemon       6529    0x000000000151e620  Flusher                         134\nSubdaemon       6529    0x0000000001533210  Checkpoint                      133\nSubdaemon       6529    0x00000000016286b0  Monitor                         132\nSubdaemon       6529    0x00007f95880208e0  Aging                           138\nSubdaemon       6529    0x00007f958808f900  IndexGC                         137\nReplication policy  : Manual\nCache Agent policy  : Manual\nPL/SQL enabled.\n------------------------------------------------------------------------\nAccessible by group oracle\nEnd of report\n```\n\n### 修改RAM策略\n\n> 上一节讲到每一次的连接到特定的DSN都是新建一个内存数据库的过程，当然这是基于默认RAM策略为`inUse`的情况，下面会讲到当RAM策略设置为`Manual`时创建内存数据库的过程。\n>\n> `Manual`策略适用于当数据库中数据规模巨大，装载到内存中的时间可能很长，从而导致内存数据库效率低下；而`inUse`策略适用于大多数情况，数据规模不是很大，装载到内存中的时间很短或者说在业务需求中可以忽略不计。\n\n#### 查看当前RAM策略\n\n```sh\n[oracle@timesten-hol info]$ ttadmin my_ttdb\nRAM Residence Policy            : inUse\nReplication Agent Policy        : manual\nReplication Manually Started    : False\nCache Agent Policy              : manual\nCache Agent Manually Started    : False\n```\n\n#### 修改RAM策略为手动模式（Manual）\n\n> 手动模式下，创建DSN连接时并不会将数据加载到内存中，需要手动进行数据装载和卸载\n\n```sh\n[oracle@timesten-hol info]$ ttadmin -rampolicy manual my_ttdb\nRAM Residence Policy            : manual\nManually Loaded In RAM          : False\nReplication Agent Policy        : manual\nReplication Manually Started    : False\nCache Agent Policy              : manual\nCache Agent Manually Started    : False\n[oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\";\n\nCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.\nType ? or \"help\" for help, type \"exit\" to quit ttIsql.\n\nconnect \"dsn=my_ttdb\";\n  707: Attempt to connect to a data store that has been manually unloaded from RAM\nThe command failed.\nDone.\n[oracle@timesten-hol info]$ \n```\n\n#### 向内存中装载数据\n\n```sh\n[oracle@timesten-hol info]$ ttadmin -ramload my_ttdb\nRAM Residence Policy            : manual\nManually Loaded In RAM          : True\nReplication Agent Policy        : manual\nReplication Manually Started    : False\nCache Agent Policy              : manual\nCache Agent Manually Started    : False\n[oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\";\n\nCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.\nType ? or \"help\" for help, type \"exit\" to quit ttIsql.\n\nconnect \"dsn=my_ttdb\";\nConnection successful: DSN=my_ttdb;UID=oracle;DataStore=/u02/ttdata/datastores/my_ttdb;DatabaseCharacterSet=AL32UTF8;ConnectionCharacterSet=US7ASCII;DRIVER=/home/oracle/TimesTen/tt1122/lib/libtten.so;LogDir=/u03/ttdata/logs;PermSize=40;TempSize=32;TypeMode=0;\n(Default setting AutoCommit=1)\nCommand> \n```\n\n#### 从内存中卸载数据\n\n```sh\n[oracle@timesten-hol info]$ ttadmin -ramunload my_ttdb\nRAM Residence Policy            : manual\nManually Loaded In RAM          : False\nReplication Agent Policy        : manual\nReplication Manually Started    : False\nCache Agent Policy              : manual\nCache Agent Manually Started    : False\n[oracle@timesten-hol info]$ ttisql \"dsn=my_ttdb\";\n\nCopyright (c) 1996, 2014, Oracle and/or its affiliates. All rights reserved.\nType ? or \"help\" for help, type \"exit\" to quit ttIsql.\n\nconnect \"dsn=my_ttdb\";\n  707: Attempt to connect to a data store that has been manually unloaded from RAM\nThe command failed.\nDone.\n[oracle@timesten-hol info]$ \n```\n\n### 日志和检查点\n\n#### 查看日志文件，**<u>提交之前会预写日志</u>**\n\n```sh\nCommand> host ls -al /u03/ttdata/logs/my*\n-rw-rw---- 1 oracle oracle 18270208 Sep 28 23:00 /u03/ttdata/logs/my_ttdb.log4\n-rw-rw---- 1 oracle oracle 67108864 Sep 27 04:18 /u03/ttdata/logs/my_ttdb.res0\n-rw-rw---- 1 oracle oracle 67108864 Sep 27 04:18 /u03/ttdata/logs/my_ttdb.res1\n-rw-rw---- 1 oracle oracle 67108864 Sep 27 04:18 /u03/ttdata/logs/my_ttdb.res2\n```\n\n#### 查看检查点\n\n```sh\nCommand> host ls -al /u02/ttdata/datastores/my*\n-rw-rw---- 1 oracle oracle 31906840 Sep 28 23:00 /u02/ttdata/datastores/my_ttdb.ds0\n-rw-rw---- 1 oracle oracle 31906840 Sep 28 22:57 /u02/ttdata/datastores/my_ttdb.ds1\n```\n\n#### 手动更新检查点文件\n\n> 非手动状态下检查点会每间隔一段时间执行一次，会将自上次检查点后提交的事务更新到检查点中；检查点文件是非阻塞的，即更新检查点文件时也可执行事务。\n>\n> 如下调用检查点文件：\n\n```plsql\nCommand> call ttckpt;\nCommand> call ttckpt;\n```\n\n### ttisql基本命令——用户操作\n\n#### 创建用户，可在表`sys.all_users`中查找所有的用户信息\n\n```plsql\nCommand> select * from sys.all_users;\n< SYS, 0, 2018-09-27 04:18:18.063030 >\n< TTREP, 2, 2018-09-27 04:18:18.063030 >\n< SYSTEM, 3, 2018-09-27 04:18:18.063030 >\n< GRID, 4, 2018-09-27 04:18:18.063030 >\n< ORACLE, 10, 2018-09-27 04:18:18.063030 >\n< SCOTT, 11, 2018-09-27 05:06:39.267433 >\n6 rows found.\nCommand> create user tthr identified by tthr;\n\nUser created.\n\nCommand> select * from sys.all_users;\n< SYS, 0, 2018-09-27 04:18:18.063030 >\n< TTREP, 2, 2018-09-27 04:18:18.063030 >\n< SYSTEM, 3, 2018-09-27 04:18:18.063030 >\n< GRID, 4, 2018-09-27 04:18:18.063030 >\n< ORACLE, 10, 2018-09-27 04:18:18.063030 >\n< SCOTT, 11, 2018-09-27 05:06:39.267433 >\n< TTHR, 12, 2018-09-28 23:11:57.126074 >\n7 rows found.\n```\n\n#### 给用户分配权限\n\n```plsql\nCommand> grant create session to tthr;\nCommand> grant create table to tthr;\nCommand> grant create view to tthr;\nCommand> grant create sequence to tthr;\n```\n\n#### 查看当前数据库系统内用户权限\n\n```\nCommand> select * from sys.dba_sys_privs;\n< SYS, ADMIN, YES >\n< SYSTEM, ADMIN, YES >\n< ORACLE, ADMIN, YES >\n< SCOTT, CREATE SESSION, NO >\n< SCOTT, CREATE TABLE, NO >\n< TTHR, CREATE SESSION, NO >\n< TTHR, CREATE TABLE, NO >\n< TTHR, CREATE VIEW, NO >\n< TTHR, CREATE SEQUENCE, NO >\n9 rows found.\n```\n\n#### 撤回用户权限\n\n> 以下示例展示了如何从用户撤回权限（赋予`delete any table`权限后再撤回该权限）\n\n```plsql\nCommand> grant delete any table to tthr;\nCommand> select * from sys.dba_sys_privs;\n< SYS, ADMIN, YES >\n< SYSTEM, ADMIN, YES >\n< ORACLE, ADMIN, YES >\n< SCOTT, CREATE SESSION, NO >\n< SCOTT, CREATE TABLE, NO >\n< TTHR, CREATE SESSION, NO >\n< TTHR, DELETE ANY TABLE, NO >\n< TTHR, CREATE TABLE, NO >\n< TTHR, CREATE VIEW, NO >\n< TTHR, CREATE SEQUENCE, NO >\n10 rows found.\nCommand> revoke delete any table from tthr;\nCommand> select * from sys.dba_sys_privs;\n< SYS, ADMIN, YES >\n< SYSTEM, ADMIN, YES >\n< ORACLE, ADMIN, YES >\n< SCOTT, CREATE SESSION, NO >\n< SCOTT, CREATE TABLE, NO >\n< TTHR, CREATE SESSION, NO >\n< TTHR, CREATE TABLE, NO >\n< TTHR, CREATE VIEW, NO >\n< TTHR, CREATE SEQUENCE, NO >\n9 rows found.\n```\n\n### ttisql基本命令——数据库对象操作\n\n#### 关闭自动提交\n\n> 意即每次执行事务后，均需要执行`commit`以提交事务。\n\n```plsql\nCommand> autocommit off;\n```\n\n#### 建表、插入数据\n\n```plsql\nCommand> create table ttemployees\n       > (employee_id NUMBER(6) NOT NULL,\n       > last_name VARCHAR2(10) NOT NULL, hire_date DATE, performance_report CLOB,\n       > PRIMARY KEY (employee_id) )\n       > UNIQUE HASH ON (employee_id) PAGES = 1;\nCommand> insert into ttemployees values (1, 'Smith', '2009-02-23', 'excellent'); \n1 row inserted.\nCommand> insert into ttemployees values (2, 'King', '2005-08-05', 'great');\n1 row inserted.\nCommand> insert into ttemployees values (3, 'Taylor', '2012-01-28', EMPTY_CLOB());\n1 row inserted.\nCommand> commit;\n```\n\n#### 一些命令总结\n\n> - tables and alltables - Lists tables\n> - indexes and allindexes - Lists indexes\n> - views and allviews - Lists views\n> - sequences and allsequences - Lists sequences\n> - synonyms and allsynonyms - Lists synonyms\n> - functions and allfunctions - Lists PL/SQL functions\n> - procedures and allprocedures - Lists PL/SQL procedures\n> - packages and allpackages - Lists PL/SQL packages\n\n### PLSQL编程\n\n#### 创建plsqldb、pls用户、运行sql脚本\n\n```sql\ncall ttOptUpdateStats;\n// 更新统计数据，用于分析生成最优执行计划\n```\n\n#### 使用sql developer连接TimesTen和Oracle\n\n配置如下：\n\n![TimesTen数据库连接配置](/images/image-20181018140355729.png)\n\n![Oracle数据库连接配置](/images/image-20181018140412582.png)\n\n#### plsql语法\n\n> ## What Is a PL/SQL Package?\n>\n> A **package** is a schema object that groups logically related PL/SQL types, items, and subprograms. Packages usually have two parts, a specification and a body, although sometimes the body is unnecessary. The **specification** (**spec** for short) is the interface to your applications; it declares the types, variables, constants, exceptions, cursors, and subprograms available for use. The **body** fully defines cursors and subprograms, and so implements the spec.\n>\n> `包`是一个模式对象，它对逻辑上相关的PL/SQL类型、项和子程序进行分组。包通常有两个部分，`规范`和`主体`，主体不是必要的。`规范`是应用程序的接口：它声明可用的类型、变量、常量、异常、游标和子程序。`主体`将完全定义游标和子程序，以此实现`规范`。\n>\n> As [Figure 9-1](https://docs.oracle.com/cd/B10501_01/appdev.920/a96624/09_packs.htm#5871) shows, you can think of the spec as an operational interface and of the body as a \"black box.\" You can debug, enhance, or replace a package body without changing the interface (package spec) to the package.\n>\n> ![包](/images/image-20181018143452887.png)\n>\n> ——[Oracle PL/SQL Package文档](https://docs.oracle.com/cd/B10501_01/appdev.920/a96624/09_packs.htm#362)\n\n`1_package.sql:`\n\n```plsql\nCREATE OR REPLACE PACKAGE test AS\n\n  -- Declare a record for the desired EMP fields\n  TYPE empRecType IS RECORD (\n    r_empno  EMP.EMPNO%TYPE,\n      -- 使用EMP表中EMPNO的类型\n    r_ename  EMP.ENAME%TYPE,\n    r_salary EMP.SAL%TYPE\n  );\n\n  -- Declare a Ref Cursor type\n  TYPE EmpCurType IS REF CURSOR RETURN empRecType; -- 游标类型需要有返回值\n\n  -- A parameterized cursor，定义\n  \t-- 游标\n  CURSOR low_paid (num PLS_INTEGER) IS\n    SELECT empno \n      FROM emp\n      WHERE rownum <= num\n      ORDER BY sal ASC;\n\t-- 过程(IN表示输入，OUT表示输出)\n  PROCEDURE ddl_dml\n    (myComment IN  VARCHAR2,\n     errCode   OUT PLS_INTEGER, -- 整型\n     errText   OUT VARCHAR2); \n\n\n  PROCEDURE givePayRise\n    (num       IN  PLS_INTEGER,\n     name      OUT EMP.ENAME%TYPE, \n     \t-- name是plsql中的保留字，应该尽量避免使用保留字\n     errCode   OUT PLS_INTEGER,\n     errText   OUT VARCHAR2); \n\n\n  PROCEDURE getCommEmps\n    (empRefCur IN OUT EmpCurType,\n     errCode   OUT PLS_INTEGER,\n     errText   OUT VARCHAR2); \n\n  -- Associative array\n  TYPE sum_multiples IS TABLE OF PLS_INTEGER -- Associative array type\n  INDEX BY PLS_INTEGER; -- indexed by pls_integer\n  \n  FUNCTION get_sum_multiples\n   ( multiple IN PLS_INTEGER,\n     num      IN PLS_INTEGER\n   ) RETURN sum_multiples;\n\nEND test;\n/\n\n\nCREATE OR REPLACE PACKAGE BODY test AS\n\n  PROCEDURE ddl_dml\n    (myComment IN  VARCHAR2,\n     errCode   OUT PLS_INTEGER,\n     errText   OUT VARCHAR2) IS\n\n    sql_str                    VARCHAR2(256);\n    name_already_exists        EXCEPTION;\n    insufficient_privileges    EXCEPTION;\n    PRAGMA EXCEPTION_INIT(name_already_exists,     -0955);\n    PRAGMA EXCEPTION_INIT(insufficient_privileges, -1031);\n    seq_value                  number;\n\n\n  BEGIN\n\n\n    BEGIN\n      sql_str := 'create table foo (COL1 VARCHAR2 (20),COL2 NVARCHAR2 (60))';\n      DBMS_OUTPUT.PUT_LINE(sql_str);\n      execute immediate sql_str;\n    EXCEPTION\n      WHEN name_already_exists THEN\n        DBMS_OUTPUT.PUT_LINE('  Ignore existing table errors');\n      WHEN insufficient_privileges THEN\n        DBMS_OUTPUT.PUT_LINE('  Ignore insufficient privileges errors');\n    END;\n\n    -- Cast num_col1 and char_col values\n    insert into temp values (1, 1, myComment);\n\n    commit;\n\n    errCode := 0;\n    errtext := 'OK';\n\n  EXCEPTION\n  \n    WHEN name_already_exists THEN\n\n      errCode := 0;\n      errtext := 'OK';\n\n    WHEN OTHERS THEN\n\n      errCode  := SQLCODE;\n      errText  := SUBSTR(SQLERRM, 1, 200);\n\n  END ddl_dml;\n\n\n\n  PROCEDURE givePayRise\n    (num       IN  PLS_INTEGER,\n     name      OUT EMP.ENAME%TYPE,\n     errCode   OUT PLS_INTEGER,\n     errText   OUT VARCHAR2) IS\n\n   -- Can use PLSQL collections within TimesTen PLSQL\n   TYPE lowest_paid_type IS TABLE OF emp.empno%TYPE;\n   lowest_paid lowest_paid_type;\n\n   i           PLS_INTEGER; \n   numRows     PLS_INTEGER;\n   lucky_index PLS_INTEGER; \n   lucky_emp   EMP.EMPNO%TYPE; \n\n  BEGIN\n\n    -- Initialize the output variable\n    name := 'Nobody';\n\n    -- Initialize the collection\n    lowest_paid := lowest_paid_type(0, 1, 2, 3, 4, 5, 6, 7, 8, 9);\n    i := 1;\n    \n    -- Constrain the resultset size\n    IF num < 1 OR num > 10 THEN\n\n      -- If bad inputs, default to 5 rows\n      numRows := 5;\n    ELSE\n      numRows := num;\n    END IF;\n\n\n    -- Create the cursor resultset with up to 'numRows' rows\n    OPEN low_paid( numRows );\n\n    LOOP\n\n      -- Get the current empid\n      FETCH low_paid INTO lowest_paid(i);\n\n      EXIT WHEN low_paid%NOTFOUND;\n\n      -- Increment the PLSQL table index\n      i := i + 1;\n\n    END LOOP;\n\n    -- Close the cursor\n    CLOSE low_paid;\n\n\n    -- List the subset of lowest paid employees\n    FOR j in lowest_paid.FIRST .. numRows LOOP\n      DBMS_OUTPUT.PUT_LINE('  Lowest paid empno ' || j || ' is ' || lowest_paid(j) );\n    END LOOP;\n\n    -- Randomly choose one of the lowest paid employees for a 10% pay raise.\n    lucky_index := trunc(dbms_random.value(lowest_paid.FIRST, numRows)); \n    lucky_emp := lowest_paid(lucky_index);\n\n\n    -- Give lucky_emp a 10% pay raise and return their name\n    UPDATE emp\n      SET sal = sal * 1.1\n      WHERE empno = lucky_emp\n      RETURNING ename INTO name;\n\n    COMMIT;\n\n    errCode := 0;\n    errtext := 'OK';\n\n  EXCEPTION\n  \n    WHEN OTHERS THEN\n\n      errCode  := SQLCODE;\n      errText  := SUBSTR(SQLERRM, 1, 200);\n\n  END givePayRise;\n\n\n\n  PROCEDURE getCommEmps\n    (empRefCur IN OUT EmpCurType,\n     errCode   OUT PLS_INTEGER,\n     errText   OUT VARCHAR2) IS\n\n    salesGuy empRecType;\n\n  BEGIN \n\n    DBMS_OUTPUT.PUT_LINE(' ');\n    DBMS_OUTPUT.PUT_LINE('Displaying the refcursor for the sales people');\n\n    -- The refcursor (empRefCur) result was opened before calling this procedure\n    LOOP\n      FETCH empRefCur INTO salesGuy;\n      EXIT WHEN empRefCur%NOTFOUND;\n\n      DBMS_OUTPUT.PUT_LINE(salesGuy.r_ename);\n    END LOOP;\n\n    CLOSE empRefCur;\n\n    errCode := 0;\n    errtext := 'OK';\n\n  EXCEPTION\n\n  \n    WHEN OTHERS THEN\n\n      errCode  := SQLCODE;\n      errText  := SUBSTR(SQLERRM, 1, 200);\n\n  END getCommEmps;\n\n  FUNCTION get_sum_multiples\n   ( multiple IN PLS_INTEGER,\n     num      IN PLS_INTEGER\n   ) RETURN sum_multiples\n   IS\n     s sum_multiples;\n  BEGIN\n    FOR i in 1..num LOOP\n      s(i) := multiple * ((i * (i + 1)) / 2); -- sum of the multiples\n    END LOOP;\n    RETURN s;\n  END get_sum_multiples;\n\nBEGIN  -- package initialization goes here\n  DBMS_OUTPUT.PUT_LINE('Initialized package test');\nEND test;\n/\n```\n\n`2_call_package.sql:`\n\n```plsql\nset serveroutput on;\n\ndeclare\n  errCode      PLS_INTEGER;\n  errtext      VARCHAR2(256);\n  myRefCur     test.EmpCurType; -- 使用test包中定义的类型\n  salesPerson  test.empRecType;\n  name         EMP.ENAME%TYPE;\n  n           PLS_INTEGER := 5; -- number of multiples to sum for display\n  sn          PLS_INTEGER := 10; -- number of multiples to sum\n  m           PLS_INTEGER := 3; -- multiple\n  \n  \nbegin\n\n    dbms_output.put_line(' ');\n    dbms_output.put_line(' ');\n    dbms_output.put_line(' ');\n    dbms_output.put_line('Find some of the lowest paid employees and give a random employee a 10% pay raise');\n    -- Give a lowely paid random employee a 10% pay raise\n    test.givePayRise(5, name, errCode, errText);\n    if errCode != 0 then\n      dbms_output.put_line('Error code = ' || errCode || ' Error Text = ' || errtext);\n    else\n      dbms_output.put_line(name || ' got the 10% payraise');\n    end if;\n\n    -- Open a refcursor\n    OPEN myRefCur FOR\n      SELECT empno, ename, sal\n      FROM emp\n      WHERE comm IS NOT NULL;\n\n    -- display the resultset of the refcursor\n    test.getCommEmps(myRefCur, errCode, errText);\n    if errCode != 0 then\n      dbms_output.put_line('Error code = ' || errCode || ' Error Text = ' || errtext);\n    end if;\n\n    dbms_output.put_line(' ');\n    dbms_output.put_line('Do some DDL and DML in a stored procedure');\n    test.ddl_dml('hi', errCode, errText);\n    if errCode != 0 then\n      dbms_output.put_line('Error code = ' || errCode || ' Error Text = ' || errtext);\n    end if;\n    \n    -- associative arrays\n    dbms_output.put_line(' ');\n    dbms_output.put_line('Use an associative array to compute the sum of multiples');\n    dbms_output.put_line(\n      'Sum of the first ' || TO_CHAR(n) || ' multiples of ' || TO_CHAR(m) \n       || ' is ' ||  TO_CHAR(test.get_sum_multiples (m, sn)(n)));\n    \n\nend;\n/\n```\n\n`3_create_package_workload.sql:`\n\n```plsql\nCREATE OR REPLACE PACKAGE workload AS\n\n  PROCEDURE oltp_read_only (\n    v_id      IN  PLS_INTEGER,\n    v_n       IN  PLS_INTEGER,\n    v_m       IN  PLS_INTEGER,\n    errCode   OUT PLS_INTEGER,\n    errText   OUT VARCHAR2);\n\n  PROCEDURE oltp_read_write (\n    v_id      IN  PLS_INTEGER,\n    v_n       IN  PLS_INTEGER,\n    v_m       IN  PLS_INTEGER,\n    v_c       IN  CHAR,\n    v_p       IN  VARCHAR2,\n    errCode   OUT PLS_INTEGER,\n    errText   OUT VARCHAR2);\n\nEND workload;\n/\n\n\nCREATE OR REPLACE PACKAGE BODY workload AS\n\n  -- Private package variables used for package initialization\n  theErrCode PLS_INTEGER   := 0;\n  theErrText VARCHAR2(256) := 'OK';\n\n  -- Using shared package cursors for efficiency\n  CURSOR range_query (n PLS_INTEGER, m PLS_INTEGER) IS\n     SELECT c \n       FROM sbtest \n       WHERE id BETWEEN n AND m;\n\n  CURSOR range_order_query (n PLS_INTEGER, m PLS_INTEGER) IS\n     SELECT c \n       FROM sbtest \n       WHERE id BETWEEN n AND m\n       ORDER BY c;\n\n  CURSOR range_distinct_query (n PLS_INTEGER, m PLS_INTEGER) IS\n     SELECT DISTINCT c \n       FROM sbtest \n       WHERE id BETWEEN n AND m\n       ORDER BY c;\n\n\n  -- The workload read only workload\n  PROCEDURE oltp_read_only (\n    v_id      IN  PLS_INTEGER,\n    v_n       IN  PLS_INTEGER,\n    v_m       IN  PLS_INTEGER,\n    errCode   OUT PLS_INTEGER,\n    errText   OUT VARCHAR2) IS\n\n    -- Store the result of the column 'c'\n    cValue  char(120);\n\n    -- Store the sum of the rows in (n..m)\n    sumK    number(38,0);\n\n  BEGIN\n\n    errCode := 0;\n    errtext := 'OK';\n\n    -- oltp point query\n    FOR i in 1 .. 10 LOOP\n\n      -- DBMS_OUTPUT.PUT_LINE('oltp point query');\n      SELECT c INTO cValue FROM sbtest WHERE id = v_id;\n      -- DBMS_OUTPUT.PUT_LINE('c = ' || cValue);\n\n    END LOOP;\n\n    -- oltp range query (using a cursor for loop)\n--    DBMS_OUTPUT.PUT_LINE('oltp range query');\n    FOR range_rows IN range_query(v_n, v_m)\n    LOOP\n--      DBMS_OUTPUT.PUT_LINE(range_query%ROWCOUNT || ' c = ' || range_rows.c);\n      null;\n    END LOOP;\n\n    -- olpt range SUM() query\n--    DBMS_OUTPUT.PUT_LINE('oltp range SUM() query');\n    SELECT sum(k) INTO sumK FROM sbtest WHERE id BETWEEN v_n AND v_m;\n--    DBMS_OUTPUT.PUT_LINE('sumK = ' || sumK);\n\n    -- oltp range ORDER BY query (using explicit fetches)\n--    DBMS_OUTPUT.PUT_LINE('oltp range ORDER BY query');\n    OPEN range_order_query(v_n, v_m);\n    LOOP\n      FETCH range_order_query INTO cValue;\n      EXIT WHEN range_order_query%NOTFOUND;\n--      DBMS_OUTPUT.PUT_LINE('c = ' || cValue);\n    END LOOP;\n    CLOSE range_order_query;\n\n    -- oltp range DISTINCT query\n--    DBMS_OUTPUT.PUT_LINE('oltp range DISTINCT query');\n    OPEN range_distinct_query(v_n, v_m);\n    LOOP\n      FETCH range_distinct_query INTO cValue;\n      EXIT WHEN range_distinct_query%NOTFOUND;\n--      DBMS_OUTPUT.PUT_LINE('c = ' || cValue);\n    END LOOP;\n    CLOSE range_distinct_query;\n\n  EXCEPTION\n\n    WHEN NO_DATA_FOUND THEN\n\n      errCode  := 0;\n      errText  := 'OK';\n\n    WHEN OTHERS THEN\n\n      errCode  := SQLCODE;\n      errText  := SUBSTR(SQLERRM, 1, 200);\n\n  END oltp_read_only;\n\n\n  -- The workload read + write workload\n  PROCEDURE oltp_read_write (\n    v_id      IN  PLS_INTEGER,\n    v_n       IN  PLS_INTEGER,\n    v_m       IN  PLS_INTEGER,\n    v_c       IN  CHAR,\n    v_p       IN  VARCHAR2,\n    errCode   OUT PLS_INTEGER,\n    errText   OUT VARCHAR2) IS\n\n    -- Store the result of the column 'c'\n    cValue  char(120);\n\n    -- Store the sum of the rows in (n..m)\n    sumK    number(38,0);\n\n  BEGIN\n\n    errCode := 0;\n    errtext := 'OK';\n\n    -- oltp point query\n    FOR i in 1 .. 10 LOOP\n\n      -- DBMS_OUTPUT.PUT_LINE('oltp point query');\n      SELECT c INTO cValue FROM sbtest WHERE id = v_id;\n      -- DBMS_OUTPUT.PUT_LINE('c = ' || cValue);\n\n    END LOOP;\n\n    -- oltp range query (using a cursor for loop)\n--    DBMS_OUTPUT.PUT_LINE('oltp range query');\n    FOR range_rows IN range_query(v_n, v_m)\n    LOOP\n--      DBMS_OUTPUT.PUT_LINE(range_query%ROWCOUNT || ' c = ' || range_rows.c);\n      null;\n    END LOOP;\n\n    -- olpt range SUM() query\n--    DBMS_OUTPUT.PUT_LINE('oltp range SUM() query');\n    SELECT sum(k) INTO sumK FROM sbtest WHERE id BETWEEN v_n AND v_m;\n--    DBMS_OUTPUT.PUT_LINE('sumK = ' || sumK);\n\n    -- oltp range ORDER BY query (using explict fetches)\n--    DBMS_OUTPUT.PUT_LINE('oltp range ORDER BY query');\n    OPEN range_order_query(v_n, v_m);\n    LOOP\n      FETCH range_order_query INTO cValue;\n      EXIT WHEN range_order_query%NOTFOUND;\n--      DBMS_OUTPUT.PUT_LINE('c = ' || cValue);\n    END LOOP;\n    CLOSE range_order_query;\n\n    -- oltp range DISTINCT query\n--    DBMS_OUTPUT.PUT_LINE('oltp range DISTINCT query');\n    OPEN range_distinct_query(v_n, v_m);\n    LOOP\n      FETCH range_distinct_query INTO cValue;\n      EXIT WHEN range_distinct_query%NOTFOUND;\n--      DBMS_OUTPUT.PUT_LINE('c = ' || cValue);\n    END LOOP;\n    CLOSE range_distinct_query;\n\n    -- oltp UPDATES on index column\n--    DBMS_OUTPUT.PUT_LINE('oltp UPDATES on index column');\n    UPDATE sbtest \n      SET k = k + 1 \n      WHERE id = v_n;\n\n    -- oltp UPDATES on non-index column\n--    DBMS_OUTPUT.PUT_LINE('oltp UPDATES on non-index column');\n    UPDATE sbtest \n      SET c =  v_n\n      WHERE id = v_m; \n\n    -- oltp DELETE query\n--    DBMS_OUTPUT.PUT_LINE('oltp DELETE query');\n    DELETE FROM sbtest \n      WHERE id = v_n;\n\n    -- oltp INSERT query\n--    DBMS_OUTPUT.PUT_LINE('oltp INSERT query');\n    INSERT INTO sbtest (id, k, c, pad)\n      VALUES (v_n, v_m, v_c, v_p);  \n\n    -- Commit the changes\n    COMMIT;\n\n  EXCEPTION\n\n    WHEN NO_DATA_FOUND THEN\n\n      errCode  := 0;\n      errText  := 'OK';\n\n    WHEN OTHERS THEN\n\n      errCode  := SQLCODE;\n      errText  := SUBSTR(SQLERRM, 1, 200);\n\n  END oltp_read_write;\n\nBEGIN  -- package initialization goes here\n\n  -- Run the procedures once to initialize everything\n  oltp_read_only(1, 1, 10, theErrCode, theErrText );\n  oltp_read_write(1, 1, 10, 'abc', 'def', theErrCode, theErrText );\n\n  DBMS_OUTPUT.PUT_LINE('Initialized the workload package');\nEND workload;\n/\n```\n\n`4_call_workload.sql:`\n\n```plsql\nset serveroutput on;\n\ndeclare\n  counter    PLS_INTEGER;\n  errCode    PLS_INTEGER;\n  errtext    VARCHAR2(256);\n  line1      VARCHAR2(256);\n  line2      VARCHAR2(256);\n  someText   sbtest.c%TYPE;\n  moreText   VARCHAR2(256);\n  i          PLS_INTEGER;\n  iterations PLS_INTEGER;\n  startTime  NUMBER;\n  endTime    NUMBER;\n  duration   NUMBER;\nbegin\n\n  -- Initialize the someText string\n  line1 := 'The quick brown foxy did da jumping thing over that lazy doggy. ';\n  line2 := 'Question three, who was scott and who or what was tiger?';\n  someText := line1 || line2;\n  moreText := '';\n \n  -- Initialize the moreText string\n  FOR i in 1 .. 60 LOOP\n    moreText := moreText || 'a';\n  END LOOP;\n  \n  -- Get the start time in centi-seconds\n  startTime := DBMS_UTILITY.GET_TIME();\n\n  iterations := 10000;\n  for counter in 1 .. iterations LOOP\n    workload.oltp_read_only(1, 1, 1100, errCode, errtext);\n    if errCode != 0 then\n      exit;\n    end if;\n  end loop;\n\n  -- Get the end time in centi-seconds\n  endTime := DBMS_UTILITY.GET_TIME();\n  if errCode !=0 then \n    dbms_output.put_line('  ');\n    dbms_output.put_line('Error code = ' || errCode || ' Error Text = ' || errtext);\n  end if;\n  duration := endTime - startTime;\n  IF duration > 0 THEN\n    dbms_output.put_line('  ');\n    dbms_output.put_line('Called workload.oltp_read_only  ' || iterations || ' times. TPS = ' || trunc(iterations / duration * 100, 1) );\n  ELSE\n    dbms_output.put_line('Could not get valid timing info');\n  END IF;\n\n\n  iterations := 10000;\n  for counter in 1 .. iterations LOOP\n    workload.oltp_read_write(1, 1, 1100, someText, moreText, errCode, errtext);\n    if errCode != 0 then\n      exit;\n    end if;\n  end loop;\n\n  -- Get the end time in centi-seconds\n  endTime := DBMS_UTILITY.GET_TIME();\n\n  if errCode !=0 then \n    dbms_output.put_line('  ');\n    dbms_output.put_line('Error code = ' || errCode || ' Error Text = ' || errtext);\n  end if;\n\n  duration := endTime - startTime;\n  IF duration > 0 THEN\n    dbms_output.put_line('Called workload.oltp_read_write ' || iterations || ' times. TPS = ' || trunc(iterations / duration * 100, 1) );\n  ELSE\n    dbms_output.put_line('Could not get valid timing info');\n  END IF;\nend;\n/\n```\n\n","tags":["大三上笔记","TimesTen","内存数据库"],"categories":["archives"]},{"title":"软件工程课程笔记（更新中）","url":"/2018/09/01/软件工程课程笔记/","content":"# 软件工程\n\n## 第一章\n\n## 第二章 软件工程\n\n> 定义软件工程的**<u>框架(Framework)</u>**\n\n### 软件工程的定义\n\n> ##### 软件工程是：\n>\n> （1）将**<u>系统化的(systematic)</u>**、**<u>规范的(disciplined)</u>**、**<u>可量化(quantifiable)</u>**的方法应用于软件的<u>**开发(development)**</u>、<u>**运行(operation)**</u>和<u>**维护(maintenance)**</u>.\n>\n> （2）对（1）中所述**<u>方法(approaches)</u>**的研究.\n\n<!-- more -->\n\n### 软件工程层次图\n\n> 工具-方法-过程-质量关注点\n>\n> ![软件工程层次图]()\n\n#### 软件过程\n\n- 软件过程的定义\n\n> 软件过程是工作产品构建时所执行的一系列活动、动作和任务的集合，一个**<u>活动(activity)</u>**包含多个<u>**动作(action)**</u>，一个动作包含多个<u>**任务(task)**</u>.\n\n#### 过程框架\n\n- <span id=\"GPF\">最经典的过程框架：</span>\n\n需求调研(RE)→需求分析建模(Require Analysis Model)→概要设计(Architecture Design)→详细设计(CLD)→编码(Coding)→单元测试(Unit testing)→整合测试(Integrating testing)→系统测试(System testing)→交付或发布(Delivery or Release)\n\n- 通用的过程框架：\n\n沟通(Communication)→策划(Planning)→建模(Modeling)→构建(Construction)→部署(Deployment)\n\n> **<u>沟通</u>**包含需求调研；\n>\n> <u>**策划**</u>是一个**<u>普适性活动</u>**或者庇护维活动或质量控制维活动(Umbrella activity)，与开发维(devolope demention)或框架活动(framework)不重合\n>\n> **<u>建模</u>**包含需求分析建模、概要设计、详细设计\n>\n> **<u>构建</u>**包含编码、单元测试、整合测试、系统测试\n>\n> **<u>部署</u>**包含发布\n\n- milestone\n\n> milestone是项目管理中用于标记项目时间轴上特定点的工具，用于某一过程活动完成的标志，以使工程能够成功过渡到下一阶段。\n\n#### 普适性活动\n\n包含：\n\n- 软件项目跟踪和控制(Software project tracking and control，以Planning为基础)\n- 风险管理(Risk management)\n\n> 1. 首先进行**<u>风险识别</u>**，得到初始识别的风险表(risk list)，利用以下公式将风险按照RE从高到低排序列出。 \n> ```\n> risk exposure(RE，风险曝光度) = impact(影响度) * productivity(影响比例)\n> ```\n> 2. 制定风险缓解计划(risk mitigation planning)\n> 3. 风险跟踪(risk tranking)：\n>\n>    - 可能风险缓解\n>    - 可能风险真的发生，要有对应的风险处理对策\n\n- 软件质量保证(Software quality assurance)\n\n> 例子：SQA，GitHub的bug检查合并\n\n- 技术评审(Technical review)\n\n> 按照代码逻辑或者代码行进行评审、检查\n\n- 测量(Measurement)\n\n> 定量化，\n\n- 软件配置管理(Software configuration management)\n\n> 在整个软件过程中管理变更所带来的影响\n\n- 可复用管理(Reusability management)\n- 工作产品的准备和生产(Work product preparation and production)\n\n> 工作分解结构(WBS)：\n>\n> ​\t工作分解结构（简称WBS）跟因数分解是一个原理，就是把一个项目，按一定的原则分解，项目分解成任务，任务再分解成一项项工作，再把一项项工作分配到每个人的日常活动中，直到分解不下去为止。即：项目→任务→工作→日常活动。工作分解结构以[可交付成果](https://baike.baidu.com/item/%E5%8F%AF%E4%BA%A4%E4%BB%98%E6%88%90%E6%9E%9C/6780498)为导向，对项目要素进行的分组，它归纳和定义了项目的整个工作范围，每下降一层代表对项目工作的更详细定义。WBS总是处于计划过程的中心，也是制定[进度计划](https://baike.baidu.com/item/%E8%BF%9B%E5%BA%A6%E8%AE%A1%E5%88%92/4805982)、资源需求、成本预算、风险管理计划和采购计划等的重要基础。——百度百科\n\n#### 过程的适应性调整\n\n> 软件工程过程并不是教条的规则，也不要求软件团队机械地执行，而应该是灵活可适应的（根据软件所需解决的问题、项目特点、开发团队和组织文化等进行适应性调整）。\n\n### 软件工程实践\n\n> 具体实施通用框架活动的过程就是软件实践。\n\n#### 实践的精髓\n\n- 理解问题（沟通和分析）—— Understand the problem (communication and analysis)\n\n- 策划解决方案（建模和软件设计）—— Plan a solution (modeling and software design)\n\n  > 包含概要设计建模和分析设计建模，最重要的是概要设计建模（体系结构、数据库设计、接口设计）\n\n- 实施计划（代码生成）—— Carry out the plan (code generation)\n\n  > 就是写代码\n\n- 检查结果的正确性（测试和质量保证）—— Examine the result for accuracy (tesing and quality assurance)\n\n  > 通过设计足够的测试来发现尽可能多的错误\n\n#### 通用原则\n\n- 存在价值（The reason it all exists）\n- 保持简洁（KISS, Keep it simple, stupid）\n- 保持愿景（Maintain the Vision）\n- 关注使用者（What You Produce， Others Will Consume）\n- 面向未来（Be Open To The Future）\n- 提前计划复用（Plan Ahead for Reuse）\n- 认真思考（Think！）\n\n### 软件开发神话\n\n### Exercise: 找到Tools\n\n## 第三章 软件过程结构\n\n### 通用过程模型\n\n![软件过程框架](/images/软件过程框架.png)\n\n### 过程流\n\n- 线性过程流\n\n  >\n\n- 迭代过程流\n\n- 演化过程流\n\n- 并行过程流\n\n### 定义框架活动\n\n### 过程模式\n\n## 第四章 过程模型（Process Models）\n\n### 传统（惯用）过程模型（Prescriptive Process Models）\n\n#### 瀑布模型（Waterfall Model）\n\n> 又称经典生命周期（Classic life cycle）\n\n> 瀑布模型可能会有`反复`的过程，但无`迭代`的过程，但`反复`会使得开发过程产生混乱。\n\n瀑布模型的变种：V模型（V-model），V模型拉直后与<a href=\"#GPF\">Generic Process Framework</a>一致。\n\n![image-20181019142951342](/images/006tNbRwly1fwdiojeitsj31eu1444it.jpg)\n\n箭头表示测试过程与设计过程的关系（相关性）\n\n#### 增量过程模型（Incremental Process Models）\n\n> 增量过程模型没有`迭代`过程，因为其开发过程没有`环`\n\n![image-20181019143931279](/images/006tNbRwly1fwdiyk83baj31ig114aw6.jpg)\n\n特点：\n\n1. 每1个增量交叉并行\n2. 每1个增量都是可以供用户直接使用的系统\n3. 第1个增量往往包含主要的、核心的功能\n\n模型的选择：时间限制、资金限制、技术限制\n\n> 例如项目的99%的需求已经完善，项目需要6个月完成，若时间充足可使用`瀑布模型`，但若甲方所给时间比较少，则可先完成一部分主要的内容，先交付，后来的需求可在后面的增量中开发，这就是`增量模型`的一个例子。\n\n#### 演化过程模型（Evolutionary Process Model）\n\n> 演化模型是`迭代`的过程模型","tags":["大三上笔记","软件工程"],"categories":["archives"]},{"title":"计算机网络课程笔记（更新中）","url":"/2018/09/01/计算机网络课程笔记/","content":"\n# 计算机网络\n\n## 简介\n\n- 网络通信是进程间的通信，进程的表示：\n\n  ```\n  IP:port\t\t//IP为服务器IP地址，port为服务器上的进程号\n  ```\n\n<!-- more -->\n\n- 网络组成：\n\n  - Management\n\n  - Application\n\n  - Hardware\n\n    > Cable：电缆、光纤\n    >\n    > Network Interface Card：网卡\n    >\n    > Switch：交换机\n    >\n    > Router：路由器\n\n## 传播介质（第7章）\n\n### 对传播介质的度量\n\n- 传播延时\n\n  > 信号在介质中往返一次所需的时间\n\n- 信道容量\n\n  > 介质可以支持的最大数据速率\n\n- 频率范围\n\n  > 介质可接受的最大的频率变化范围\n\n- 带宽\n\n  > 每秒所收到的数据量（Bit）\n\n### 奈奎斯特定理\n\n```\nD=2*B*log2K\nK:传输系统使用的信号电平数\nB:模拟带宽\nD:以每秒位元数计算的最大数据速率\n```\n\n### 香农定理\n\n```\nC=B*log2(1+S/N)\nB:硬件带宽\nS/N:信噪比\nC:用每秒位数表示的对信道容量的有效限制\n```\n\n- 分贝(db)和信噪比(S/N)是指数关系\n\n  ```\n  dB=10*log10S/N\n  \n  eg:\n  \tdB = 20 => S/N = 100\n  \tdb = 30 => S/N = 1000\n  ```\n\n- 例子：电话线\n\n  ```\n  Bandwidth = 3000HZ\n  S/N ratio = 30db\n  =>  C = 30Kps\n  ```\n\n## 传输模式（第9章）\n\n### 传输模式分类\n\n- 串行传输\n- 并行传输\n\n### 传输数据\n\n> 例子：Byte 正序(big-endian) && Bit 逆序(little-endian)\n\n#### 串行传输方式\n\n- 异步传输\n\n  > 键盘输入，RS-232异步字符传输\n\n  - RS-232异步字符传输标准\n\n    > 把一串字符串通过铜线进行传输\n    >\n    > S1:把字符用ASCII码表示出来；S2:\n\n    状态机：电压变化表示状态切换\n\n    > 空闲状态：\n    >\n    > ​\t接受”-“：保持空闲状态\n    >\n    > ​\t接受”+“：变成传输状态\n    >\n    > 传输状态：\n    >\n    > ​\t接受”-“：保持传输状态，传1\n    >\n    > ​\t接受“+”：保持传输状态，传0\n    >\n    > 传输的数据前后各需要一位，分别作为起始位(+)、终止位(-)\n    >\n    > 结束按照“翻转”时间确定，传输完成保持负电压\n    >\n    > **最终传输到接收方是9位，多一位<u>校验码</u>**\n\n- 同步传输\n\n  > 以太网\n\n  - 原理同对表一样\n\n    > 实现方法：采用先传输一部分规定好的数据，来检测发送方和接收方是否一致\n\n- 等时传输\n\n  > 利用**<u>缓冲区</u>**实现\n\n#### 标准\n\n- 波特率匹配\n- 例子：传输Z(0x5A)，检测波特率提高一倍\n\n#### 通信信道\n\n- 单工信道\n\n  > Eg：广播、收音机\n\n- 全双工信道\n\n  - 数据线路设备(DCE)和数据终端设备(DTE)\n  - 反接线\n\n- 半双工信道\n\n  > Eg：对讲机\n\n## 调制和调制解调器（第10章）\n\n### 远距离传输\n\n> 考虑：干扰、**<u>信号衰减</u>**\n>\n> 解决方案：**<u>载波</u>**传输\n\n### 载波传输方式\n\n- \n- \n- 连续性好\n- \n\n### 载波改变方式——调制（Modulation）与解调（Demodulation）\n\n```\nS(t)=Asin(2πFt+P)\n// A: Amplitude Modulation(调幅)\n// F: Frequency Modulation(调频，单位时间内波的个数)\n// P: Phase Modulation(调相)\n```\n\n- 调幅\n\n  > 调幅的大小有一定的限制（香农定理的限制）\n\n- 调频\n\n- 调相\n\n### 键控（Shift keying）\n\n### 调制技术的比较\n\n> 调相的效率要高一点，变化一次可传输不止一位（通过相位分隔，例如将2π分为8份，则有8种信号，可传输3位数据）\n\n### 正交调幅(QAM, Quadrature Amplitude Modulation)\n\n> 结合调幅和移相键控，使用同时包含相位和振幅的改变来表示数据，QAM最大可以表示1024个\n>\n> 公式：Y~m~(t) = A~m~sinwt+B~m~coswt，运算为矢量运算\n\n### 调制解调器类型\n\n- 无线猫（RF，Radio Frequency）\n- 光纤猫（optical modems）\n- 拨号猫（Dialup modem）\n  - 拨号调制解调器模式\n    - Calling mode\n    - Answer mode\n\n## 复用与解复用（第11章）\n\n### 分类\n\n#### 频分多路复用FDM\n\n- 多个逻辑信道，实际上只有一个物理信道。\n\n- 防止频道之间干扰，通常有个区间为防护带区间。\n\n- 信号的漂移现象\n\n  > 解决方法：子信道分配\n\n- 分级FDM\n\n- 分布式平铺\n\n#### 波分多路复用WDM\n\n- 是指应用于光纤中的频分复用技术\n\n#### 时分多路复用TDM\n\n- 同步TDM\n  - 问题：空闲时隙\n  - 应用：电话通话\n- 分级TDM\n- 统计TDM\n  - 应用：网络\n- 逆转复用\n  - 将单个高速数字输入被分配到多个低速连接上，传输后再重新复合而形成输入的副本\n\n#### 码分多路复用CDM\n\n- 矢量（Vector）\n\n  > 矢量的运算\n\n- 结论 \n\n## 可靠性和信道编码（第8章）\n\n### 数据传输错误的3个源头\n\n- 干扰\n- 失真\n- 衰减\n\n### 传输差错对数据的影响\n\n- 单个差错\n- 突发差错\n- 擦除（模糊）\n\n### 处理信道差错的两种策略（信道编码）\n\n> 发送数据的同时，发送校验码\n\n- 前向纠错（FEC）\n\n- 自动重传请求（ARQ）\n\n### FEC机制\n\n- 单奇偶检验\n\n  > 奇偶性定义为1的个数，且校验位的添加会使得`码字`始终保持`奇数`或``偶数``，保持奇数就是`奇校验`，保持偶数就是`偶校验`.\n  >\n  > 限制：校验能力有限，出两个错误时便无法校验\n\n- 分组码数学与`（n, k）`表示\n\n- 汉明距离\n\n  > 先计算最小汉明距`d`，而后得出可检查的最大的有效位长度：`E<=d-1`\n\n- 纵横奇偶校验\n\n  > 作用：可以找出错误的位置，并改正错误\n  >\n  > 缺点：效率低下，一般不用\n\n- 校验和\n\n  > 码的长度一般为字节的倍数，进位需加回到原和中\n  >\n  > 优点：\n  >\n  > - 校验和的大小比较小\n  > - 计算很简单\n  > - 开支很低\n  >\n  > 缺点：\n  >\n  > - 对纵向错误无法校验（导致校验和方法一般不用在硬件上）\n  >\n  > **<u>一般情况下，校验和位取的是算数反码，校验时所有数据位相加，得到结果取补码为0则数据正确</u>**\n\n```\nIP包的头部长度：20Bytes\n```\n\n- 循环冗余校验码（CRC码，适宜用在硬件上，例如网卡）\n\n  - 关键特性\n    - 任意长度报文\n    - 出色的检错能力\n    - 快速硬件实现\n\n  - 线性码、循环线性码\n\n    > 线性码是一个码的集合C，且C~1~、C~2~∈C，则C~1~、C~2~∈C的线性组合仍然∈C；\n    >\n    > 循环线性码是指码循环移位后的码仍然属于该集合。\n\n  - 原理\n\n    >\n\n  - 硬件实现\n\n    > 异或门实现基本运算\n\n    - 算法\n\n  - 自动重传请求(ARQ)机制\n\n    > 数据传输成功会发送回执，错误则不发送回执\n\n    ​\t\n\n### OSI Reference Model\n\n> **数据流（Data Flow）：**\n>\n> - Service服务：下一层对上一层提供服务（接口、方法）\n> - Protocol协议\n> - Physical物理\n\n- 物理层（5 7 9 10 11）\n\n- 数据链路层（8）\n\n  > 将一条物理上有差错的传输信道通过通知和管理而变成逻辑上无差错的\n\n- \n\n## 因特网应用与网络编程（第3章）\n\n### 线路交换网络（circuit switched network）\n\n### 包交换网络（packet switched network）\n\n  > 特征：轮流\n\n​\t\n\n  - 异步\n\n  - 不用安装\n\n> 主要区别在于二者的共享性\n\n\n\n## 局域网：分组、帧和拓扑（第13章）\n\n### 以太网的接受方式\n\n  > 广播式：\n  >\n  > - MAC子层拷贝每个包\n  > - LLC子层提取每个包的拷贝\n  > - LLC子层只接受那些单一传播、广播或多路传播的地址相匹配的包\n\n### 帧\n\n  > 帧头、帧尾用于检测传输过程是否发生错误，同时用作`边界` \n  >\n  > `边界`采用两个ASC码中很少使用的字符： \n  >\n  > - SOH（01）头部起始字符\n  > - EOT（04）传输结束字符\n  >\n\n  - #### 此方案的缺陷\n\n    假如使用此两个字符，将会发生接受解析问题\n\n  - #### 解决方案\n\n    > 字填充（ABC可换成“任意”字符，但是效率不同，找一些不太会出现的字符会提高效率）：\n    >\n    > - soh → esc + A\n    > - eot → esc + B\n    > - esc → esc + C\n\n    > 位填充：\n    >\n    > 5个`1`出现了便插入1个`0`，首尾使用`01111110`作为边界\n\n## IEEE MAC子层（第14章）\n\n### 受控介入协议（Control Access Protocols）\n\n#### 轮询\n\n> 方式：\n>\n> - 按循环顺序\n> - 按优先级顺序\n>\n> 算法：\n>\n> ```\n> 目的：\n> \t通过轮询来控制分组的发送\n> 方法：\n> \t控制器不断重复{\n>         选择站点S，发送一个查询报文给S；\n>         等待S发送一个分组来进行响应或跳过；\n> \t}\n> ```\n\n#### 预定\n\n> 算法：\n>\n> ```\n> 目的：\n> \t通过预约来控制分组的发送\n> 方法：\n> \t控制器不断重复{\n>         形成一个需要发送分组的站点列表；\n>         允许列表中的站点发送分组；\n> \t}\n> ```\n\n#### 令牌传递\n\n> `令牌`是一个特殊的`帧`，不管有没有数据都会在环状网络中传输\n>\n> 令牌有两个状态（`空`和`忙`的切换只能由同一个站点切换）：\n>\n> - 空 → 可以发送（数据在传输时转变为`忙令牌`） \n> - 忙 → 无法发送（只能当数据在环网中发送一周时，才能将`忙令牌`转换为`空令牌`）\n\n> 算法：\n>\n> ```\n> 目的：\n> \t通过令牌传递来控制分组的发送\n> 方法：\n> \t网络上的每台计算机重复执行{\n>         等待令牌的到达；\n>         如果本计算机有分组正在等待发送，则发送一个分组；\n>         将令牌发送到下一站；\n> \t}\n> ```\n>\n> ```\n> 1）空令牌传递到下一个节点；\n> 2）节点是否要发送？不发送，转向1）\n> 3）填充帧到令牌中，并置为忙\n> 4）忙令牌传递到下一个节点\n> 5）是否接受节点？是，复制该帧；转向4）\n> 6）节点是否发送节点？是，销毁令牌中的帧，并置空，返回1）\n> 7）返回4）\n> ```\n\n### 随机接入协议（Random Access Protocol）\n\n#### ALOHA\n\n#### CSMA/CD（Collision Detect）\n\n> 以太网中一个网卡数据一旦发送，便不能停下，需等到数据发送完\n>\n> 算法：\n>\n> ```\n> 1）监听网络状态；如果空闲，转向3）\n> 2）等待，返回1）\n> 3）发送，在发送的过程中同时进行碰撞监听\n> 4）一旦发生碰撞，立即停止发送\n> 5）推后一个随机时间，返回1）\n> ```\n\n检测冲突的方法：\n\n- 载波侦听\n- 冲突检测\n- 二进制指数退避\n\n#### CSMA/CA（Collision Avoidance）\n\n> 算法：\n>\n>\n\n## 有限局域网技术（第15章）\n\n### 以太网帧格式\n\n- 以太网帧结构（截自维基百科）\n\n  ![以太网帧格式](/img/image-20181017150353887.png)\n\n> **Question：**(Using 广播 )\n>\n> How does the sender know the target physical address？（注意：网卡无法识别IP地址）\n\n### 地址解析（Address Resolution）\n\n#### 目的地地址解析\n\nSender：\n\n- 发送广播，征询目的节点的物理地址\n\n- 接到目的节点应答，取出目的节点物理地址\n\nAll Receivers：\n\n- 接到广播，取出源节点物理地址,比较主机名是否相同\n\n- 目标节点，匹配，就取出源节点物理地址，以该地址为目的地址，本物理地址为源地址，作询问应答\n\n- 其他节点，因不匹配不需要作回答\n\n### 帧类型（Frame Type）\n\n> 用于区分帧的类型，是ARP包还是IP包（区分协议类型）\n\nIP：0800\n\nARP：0806\n\n### IEEE’s 802.3 Ethernet Frame（一种新的帧格式）\n\n### 网卡 NIC Network Interface Card\n\n> NIC可以直接访问Memory，NIC与CPU仅存在指令关系\n\n过程：\n\n- 发送\n\n  > 1. Before sending data,  CPU forms a packet in memory 发送数据之前，CPU在内存中产生一个数据包\n  > 2. CPU then instructs the NIC to begin transmission CPU给NIC发送`播送`指令\n  > 3. NIC transmits the frame containing the packet\n  > 4. After finishing transmission, NIC uses the computer’s interrupt mechanism to inform the CPU\n\n- 接收\n\n  > 1. The NIC waits for a frame to cross the network\n  > 2. The NIC makes a copy of the frame\n  > 3. The NIC verifies the frame CRC and checks the destination address\n  > 4. If the destination address is correct，the NIC stores a copy of the packet  in memory\n  > 5. The NIC then interrupts the CPU\n  > 6. Otherwise，the NIC discards the frame \n\n### 网卡产品（NIC Evolution）\n\n#### 粗缆（Original Thick Ethernet Wiring）\n\n![image-20181019161433801](/img/image-20181019161433801.png)\n\n> IEEE802.3\n> 10Base5\n>\n> 最大长度：500m（摩天大楼的高度）\n\n组成：\n\n- 网卡（连在设备上）\n- 收发器\n- 电缆\n\n> Terminator（终结器）：将信号能量消耗掉，防止信号反弹造成干扰，原理是电阻\n>\n> Connection Multiplexor（多路连接器）：允许多台计算机连接到单个收发器，且提供与传统收发器完全相同的信号\n\n#### 细缆（Thin Ethernet）\n\n![image-20181019161405925](/img/image-20181019161405925.png)\n\n将前者的三部分组合起来，结构和环网很像，但传输方式仍然是广播式的，Terminator仍然需要。\n\n#### 双绞线以太网（Twisted Pair Ethernet）\n\n![image-20181019161451060](/img/image-20181019161451060.png)\n\n> HUB（集线器）里面包含了主线\n\n### 集成网卡\n\n![image-20181019161615728](/img/image-20181019161615728.png)\n\n- RJ-45：双绞线\n\n- AUI：粗缆\n\n- BNC：细缆\n\n### 双绞线网卡拓扑结构\n\n> Tips：网络上的逻辑上和结构上的拓扑结构可以不同！\n\n物理上：星形结构\n\n逻辑上：总线结构\n\n### 举例：\n\n![image-20181019162644076](/img/image-20181019162644076.png)\n\n\n\n### 布线工程\n\n![image-20181019163053138](/img/image-20181019163053138.png)\n\n## 无线联网技术（第16章）\n\n### 个域网（PAN，802.15）\n\n- 蓝牙\n- 红外\n\n> 蓝牙耗电比较低，红外耗电高\n\n- 紫峰（ZigBee）\n- ISM无线\n\n### 无线局域网（WLAN、WiFi，802.11）\n\n> 为降低信号衰减采用FDM分布式平铺技术（第11章）\n\n> AP，Access Point through the air （Base Station），相当于集线器\n\n#### 类型\n\n- 专门构建型（Ad hoc）\n\n  > 点到点，不通过AP\n\n- 基础结构型（Infrastructure）\n\n  > 通过AP\n\n#### Manet（Mobile Ad-hoc Networks）","tags":["大三上笔记","计算机网络"],"categories":["archives"]},{"title":"dotnet基本配置及EFCore连接Mysql","url":"/2018/06/26/Dotnet/","content":"\n## 前奏部分\n\n- 下载并安装[dotnet core](https://www.microsoft.com/net/learn/get-started/)\n\n- 下载并安装[vscode](https://code.visualstudio.com/)（需要把vscode添加到path中）\n\n<!-- more -->\n\n- vscode中搜索并安装C#插件、NuGet Package Manager插件\n\n  > ![image-20180607144445947](http://getme.guitoubing.top/image-20180607144445947.png)\n\n- 新建项目\n\n  > ```shell\n  > mkdir dotnet\n  > cd dotnet\n  > dotnet new mvc\n  > code .\n  > ```\n\n- commond + shift + p输入nuget add package安装以下依赖包，各个包的Version可在添加时选择\n\n  > ![image-20180607145123118](http://getme.guitoubing.top/image-20180607145223693.png)\n\n  > 添加包时以下代码将自动在dotnet.csproj中添加：\n  > ```xml\n  > <ItemGroup>\n  >     <PackageReference Include=\"Microsoft.AspNetCore.All\" Version=\"2.0.6\"/>\n  >     <PackageReference Include=\"Microsoft.EntityFrameworkCore.Sqlite\" Version=\"2.1.0\"/>\n  >     <PackageReference Include=\"Microsoft.EntityFrameworkCore.Tools\" Version=\"2.1.0\"/>\n  >     <PackageReference Include=\"Microsoft.EntityFrameworkCore.Sqlite.Design\" Version=\"2.0.0-preview1-final\"/>\n  >     <PackageReference Include=\"Microsoft.EntityFrameworkCore.Tools.DotNet\" Version=\"2.1.0-preview1-final\"/>\n  >     <PackageReference Include=\"Pomelo.EntityFrameworkCore.MySql\" Version=\"2.1.0-rc1-final\"/>\n  >     <PackageReference Include=\"Pomelo.EntityFrameworkCore.MySql.Design\" Version=\"1.1.2\"/>\n  > </ItemGroup>\n  > ```\n\n## Model部分\n\n- 连接数据库创建实体：\n\n  在vscode终端中输入以下命令\n\n  ```\n  dotnet ef dbcontext scaffold \"server=localhost;userid=user;pwd=password;port=3306;database=university;sslmode=none;\" Pomelo.EntityFrameworkCore.MySql -o Models\n  ```\n\n- dotnet ef两个问题\n\n  > 问题1：No executable found matching command \"dotnet-ef\"\n  > 解决方法：dotnet.csproj中添加如下行： \n  >\n  > ```XML\n  >  <ItemGroup>\n  > \t<DotNetCliToolReference Include=\"Microsoft.EntityFrameworkCore.Tools.DotNet\" Version=\"2.1.0-preview1-final\"/>\n  > </ItemGroup>\n  > ```\n\n  > 问题2：Version for package `Microsoft.EntityFrameworkCore.Tools.DotNet` could not be resolved.\n  >\n  > 原因：上述配置中Version版本与包引用中的版本不一致，修改上述添加代码的Version即可\n\n  此时将会在Models文件夹下创建所有数据库表的实体，同时会创建一个universityContext.cs实体（university为我数据库名称，自行定义），用于对整个数据库的操作。**至此MVC已完成Model部分**。\n\n## Controller及View部分\n\n- 目前项目Models文件夹下已有DBFirst模式生成的实体文件：\n\n  ![image-20180607150002112](http://getme.guitoubing.top/image-20180607150002112.png)\n\n- 我们选择Student的Model创建C-V视图\n\n  > 这里说明一下，MVC模式中Model顾名思义是数据模型、实体，而View和Controller是相互依存的。一般步骤是先创建StudentController.cs文件，定义其中的路由(URL映射，定义了路由之后可以直接通过URL访问该函数)，如本项目中的StudentController.cs中定义的Index：\n  >\n  > ```C#\n  > public IActionResult Index(){\n  >         return View(_context.Student.ToList());\n  >     }\n  > ```\n  >\n  > 如此定义后，再在Views文件夹下创建对应Controller的文件夹，此处为Student，而在Controller中定义的每一个路由，都要有对应的一个cshtml文件，此处在Student下创建Index.cshtml。简而言之，**View只负责处理布局，Controller只负责处理逻辑。**\n\n  - 创建StudentController.cs\n\n    > ```c#\n    > using System;\n    > using System.Collections.Generic;\n    > using System.Diagnostics;\n    > using System.Linq;\n    > using System.Threading.Tasks;\n    > using Microsoft.AspNetCore.Mvc;\n    > using dotnet.Models;\n    > using dotnet;\n    > \n    > public class StudentController : Controller{\n    >     private universityContext _context;\n    > \n    >     public StudentController(universityContext context){\n    >         _context = context;\n    >     }\n    >     \n    >     public IActionResult Index(){\n    >         return View(_context.Student.ToList());\n    >     }\n    > \n    >     public IActionResult Register(){\n    >         return View();\n    >     }\n    > \n    >     [HttpPost]\n    >     [ValidateAntiForgeryToken]\n    >     public IActionResult Register(Student student){\n    >         if(ModelState.IsValid){\n    >             _context.Student.Add(student);\n    >             _context.SaveChanges();\n    >             return RedirectToAction(\"Index\");\n    >         }\n    >         return View(student);\n    >     }\n    > }\n    > ```\n\n  - 创建Student文件夹，以及对应路由的cshtml\n\n    > - Index.cshtml\n    >\n    > ```html\n    > @{\n    >     ViewData[\"Title\"] = \"学生主页\";\n    > }\n    > \n    > <!-- 此处这个model声明不能忘记 -->\n    > @model IEnumerable<dotnet.Student>\n    > \n    > <table class=\"table\">\n    >     <tr>\n    >         <th>Id</th>\n    >         <th>姓名</th>\n    >         <th>系</th>\n    >         <th>学分</th>\n    >     </tr>\n    >     @foreach (var item in Model){\n    >         <tr>\n    >             <td>\n    >                 @Html.DisplayFor(modelItem => item.Id)\n    >             </td>\n    >             <td>\n    >                 @Html.DisplayFor(modelItem => item.Name)\n    >             </td>\n    >             <td>\n    >                 @Html.DisplayFor(modelItem => item.DeptName)\n    >             </td>\n    >             <td>\n    >                 @Html.DisplayFor(modelItem => item.TotCred)\n    >             </td>\n    >         </tr>\n    >     }\n    > </table>\n    > ```\n    >\n    > - Register.cshtml\n    >\n    > ```html\n    > @model dotnet.Student\n    > \n    > @{\n    >     ViewData[\"Title\"] = \"注册\";\n    > }\n    > \n    > <form asp-controller=\"Student\" asp-action=\"Register\" method=\"POST\">\n    >     <div class=\"form-group\">\n    >         <label asp-for=\"Id\" class=\"col-md-2 control-label\">编号：</label>\n    >         <div class=\"col-md-10\">\n    >             <input class=\"form-control\" asp-for=\"Id\"/>\n    >             <span asp-validation-for=\"Id\" class=\"text-danger\"></span>\n    >         </div>\n    >         <label asp-for=\"Name\" class=\"col-md-2 control-label\">名字：</label>\n    >         <div class=\"col-md-10\">\n    >             <input class=\"form-control\" asp-for=\"Name\"/>\n    >             <span asp-validation-for=\"Name\" class=\"text-danger\"></span>\n    >         </div>\n    >         <label asp-for=\"DeptName\" class=\"col-md-2 control-label\">系：</label>\n    >         <div class=\"col-md-10\">\n    >             <input class=\"form-control\" asp-for=\"DeptName\"/>\n    >             <span asp-validation-for=\"DeptName\" class=\"text-danger\"></span>\n    >         </div>\n    >         <label asp-for=\"TotCred\" class=\"col-md-2 control-label\">学分：</label>\n    >         <div class=\"col-md-10\">\n    >             <input class=\"form-control\" asp-for=\"TotCred\"/>\n    >             <span asp-validation-for=\"TotCred\" class=\"text-danger\"></span>\n    >         </div>\n    >         <div class=\"col-md-offset-2 col-md-10\">\n    >             <input type=\"submit\" value=\"保存\" class=\"btn btn-default\"/>\n    >         </div>\n    >     </div>\n    > </form>\n    > ```\n\n- 关于抛出以下错误的解决方法\n\n  - 错误：\n\n    > ![image-20180607142732374](http://getme.guitoubing.top/image-20180607142732374.png)\n\n  - 解决方法：\n\n    > ![dotnet配置](http://getme.guitoubing.top/dotnet%E9%85%8D%E7%BD%AE.png)\n    >\n    > 注意最下面的Tip：由于我们在Startup.cs中已经添加如下代码：\n    >\n    > ```c#\n    > public void ConfigureServices(IServiceCollection services)\n    >         {\n    >             services.AddDbContext<universityContext>();\n    >             services.AddMvc();\n    >         }\n    > ```\n    >\n    > 即满足条件“already configured outside of the context in Startup.cs”，因此我们需要将上述图片中的if语句注释掉，如下：\n    >\n    > ```c#\n    > //if (!optionsBuilder.IsConfigured){ \n    > optionsBuilder.UseMySql(\"server=localhost;userid=root;pwd=tanrui;port=3306;database=university;sslmode=none;\");\n    > //}\n    > ```\n\n  ## 运行项目\n\n  - 调试的方法\n\n    > - vscode下点按“开始调试”\n    >\n    >   ![image-20180607151747548](http://getme.guitoubing.top/image-20180607151747548.png)\n    >\n    > - 浏览器将会自动跳转至localhost:5000\n    >\n    >   ![image-20180607152008469](http://getme.guitoubing.top/image-20180607152008469.png)\n    >\n    > - 在URL中添加<u>/student</u>或<u>student/index</u>跳转到我们定义的Controller中，一般情况下index路由是可以忽略不写的，此时自动定位到index中：\n    >\n    >   ![image-20180607152229016](http://getme.guitoubing.top/image-20180607152229016.png)\n\n  - 戳这里下载[Asp.net Core开发实战.pdf](http://getme.guitoubing.top/ASP.NET%20Core%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E6%88%98%20,%E5%BC%A0%E5%89%91%E6%A1%A5%20,2017.04%20,Pg319_14181929.pdf)\n","tags":["Dotnet","数据库"],"categories":["archives"]},{"title":"我们梦中见","url":"/2018/06/26/2017-10-14/","content":"\n> “Yeah It’s on. ”\n\n### 26/06/2018\n\n当兵回来用的虚拟主机建的博客，hexo建在本地。前段时间电脑重装了，以前的博客就落满了灰，现迁移过来，换个心情。\n\n### 14/10/2017\n\n（是不是个技博自己心里没点B数？\n\n<!-- more -->\n\n应该说[天明学长](http://donggu.me/)在技术方面给予了很大的支持，为她打call！\n\n说要建站已经是三年前了，那时候在某课网上闲逛看到了关于Linux搭建服务器的视频，学了点，发现，what are you fk saying？后来自己买了本书，噢~ 更™不懂了。然后，就去了号子（？？）。转眼两年过去了，是该重新做人了，该搬的砖还得搬，搬不完还想吃饭？\n\n买的第一个虚拟主机是景安一台国内主机，这个时候还是不知道国内主机和海外主机有啥区别，只知道国内主机便宜，不，新用户免费。于是买了个试了下。配套的买了个top域名¥15.00/月，是贼贵了。绑定域名时发现需要备案，备案就备案吧，流程走下去。一大堆东西拍了照填了表提交上去了想的差不多了吧。结果跟我说非上海本地户口要™居住证或者临时居住证，我哪里去办，户口都没迁过来，想想要不找个备案不怎么严的省份备案下，看了下河南（？？？）以及其他，要么是要本地手机号要么就是居住证，算了，贵国厉害，我买海外。于是买了个HK主机，¥199/年（后来看到阿里云服务器学生价¥10/月+com域名就扇了自己一巴掌，你有钱行了吧）。\n\n### 接下来是干货了（扯淡\n\n然后就是绑定域名了没啥说的。 对于一个毫无前端经验的人来说，有了这些又有啥用，别人进你网站就为了看你在云里面存了多少种子？ 这里又要提到[天明学长](http://donggu.me/)了，在她网站中得知有了个[Hexo](https://hexo.io/)的框架，仿佛看到了未来。至于[Hexo](https://hexo.io/)怎么用，[官方文档](https://hexo.io/zh-cn/docs/index.html)里面都很详尽了，这里讲几点用的时候踩过的坑，以备。\n\n#### _config.YML配置，比较重要的几个地方\n\n##### 路径URL\n\n```\nurl: http://guitoubing.top/\nroot: /\n```\n\n- url和root一定要注意，最后面的“/”千万不要忘了，不然在hexo generate的时候肯定会报错\n- 在generate后要注意public文件夹的位置，public文件夹一般自动创建在当前目录下，我在server后，本地服务器浏览是没有问题的，但是点开public文件夹里面的index就会连不上css，当然上传到服务器之后肯定也是连不上的了，因为root: /这行代码认为你当前工作目录是在根目录下（硬盘根目录或者服务器根目录），有的同学会想那我把root改成我当前位置不就好了，我也试过，此时public里面的index可以正常浏览，但是传到deploy到服务器上就又连不上了，因为服务器里面没有你当前这样的路径呀。这里我用的笨办法，把创建好的public文件夹复制到硬盘根目录下，然后发现本地服务器上index是可以正常显示了，传到服务器上之后也是可以的。\n\n##### [Disqus插件](https://disqus.com/)\n\n```\n# Disqus settings\ndisqus_username: guitoubing\n```\n\n因为多说已经关闭服务了，只能用[Disqus](https://disqus.com/)，而[Disqus](https://disqus.com/)又是需要科学上网才能加载的，所以也没办法了。如果你能科学上网，那只要把这里的disqus_username改成自己注册的账号即可，我用的主题[hexo-theme-huxblog](https://github.com/kaijun/hexo-theme-huxblog/)已经集成了[Disqus](https://disqus.com/)的js代码，所以不需要其他设置，如果用的其他主题/themes/layout里面的ejs文件中添加js代码即可。 \n\n## Analytics\n\n```\n# Analytics settings\n# Baidu Analytics\nba_track_id: bcfce8e737b***********04c164dc96\n# Google Analytics\nga_track_id: 'UA-10*******-1'            # Format: UA-xxxxxx-xx\nga_domain: guitoubing.top\n```\n\n## deploy\n\n```\ndeploy:\n  type: ftpsync\n  host: guitoubing.top\n  user: webmaster@HK******\n  pass: tanrui106\n  remote: /WEB/\n  port: 21\n```\n\n[deploy](https://hexo.io/zh-cn/docs/deployment.html)就是部署到服务器上咯，因为我用的是HK虚拟主机，所以配置如上，这里的各个信息都是你所部署的服务器信息没什么好说的。\n\n## _config.YML配置完成了就可以开始创作咯\n\n```\nhexo new \"blog\" \nhexo g\nhexo s\n```\n\n[Hexo官方文档](https://hexo.io/zh-cn/docs/)都有详细使用方法，不赘述。\n\n## 有几句MMP当讲\n\n```\n古有一商人，于川中收购一批苎麻、小麦、桔子、兽皮，从水路出川。船至半途，水急桨朽，桨折断而顺水去，船夫甚急，问商人： 无桨不得行船，你所携货物中可有长直之物当桨？ 商人安慰他： 莫急，我有桔麻麦皮不知当桨不当桨？\n```\n\n从开始接触hexo到成功deploy到服务器上，算下来该有一下午加一晚上了。应该说两年没接触编程了，那句“程序员写了一段让自己不用再写代码的代码”已经不是笑话，也许是两年之前也啥屁不懂，现在越来越觉得放眼看世界是多重要。当我还熬夜敲着基础代码时，互联网上已经有了其他解决方案，倒不是说基础代码不重要，而是已经有人用基础代码敲出了不用再敲基础代码的代码，那么，吃肉，还是喝汤，看自己选择了。（我选择狗带）\n\n\n\n","tags":["Hexo"],"categories":["life"]},{"title":"404 Not Found 该页无法显示","url":"//404.html"},{"title":"categories","url":"/categories/index.html"},{"title":"tags","url":"/tags/index.html"},{"title":"关于我","url":"/about/index.html","content":"\n## 用心写文，用脚上传\n\n## 每日一问\n\n> 芳芳到底什么时候下班呢？\n\n"}]